{"/home/travis/build/npmtest/node-npmtest-compressjs/test.js":"/* istanbul instrument in package npmtest_compressjs */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireExampleJsFromReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        local.testCase_browser_nullCase = local.testCase_browser_nullCase || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test browsers's null-case handling-behavior-behavior\n         */\n            onError(null, options);\n        };\n\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-compressjs/lib.npmtest_compressjs.js":"/* istanbul instrument in package npmtest_compressjs */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_compressjs = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_compressjs = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-compressjs/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-compressjs && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_compressjs */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_compressjs\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_compressjs.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        // bug-workaround - long $npm_package_buildCustomOrg\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.npmtest_compressjs.rollup.js'] =\n            local.assetsDict['/assets.npmtest_compressjs.rollup.js'] ||\n            local.fs.readFileSync(\n                local.npmtest_compressjs.__dirname + '/lib.npmtest_compressjs.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        /* jslint-ignore-end */\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/main.js":"if (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./lib/freeze','./lib/BitStream','./lib/Stream','./lib/BWT','./lib/Context1Model','./lib/DefSumModel','./lib/FenwickModel','./lib/MTFModel','./lib/NoModel','./lib/Huffman','./lib/RangeCoder','./lib/BWTC','./lib/Bzip2','./lib/Dmc','./lib/Lzjb','./lib/LzjbR','./lib/Lzp3','./lib/PPM','./lib/Simple'], function(freeze,BitStream,Stream,BWT,Context1Model,DefSumModel,FenwickModel,MTFModel,NoModel,Huffman,RangeCoder,BWTC,Bzip2,Dmc,Lzjb,LzjbR,Lzp3,PPM,Simple) {\n    'use strict';\n    return freeze({\n        version: \"0.0.1\",\n        // APIs\n        BitStream: BitStream,\n        Stream: Stream,\n        // transforms\n        BWT: BWT,\n        // models and coder\n        Context1Model: Context1Model,\n        DefSumModel: DefSumModel,\n        FenwickModel: FenwickModel,\n        MTFModel: MTFModel,\n        NoModel: NoModel,\n        Huffman: Huffman,\n        RangeCoder: RangeCoder,\n        // compression methods\n        BWTC: BWTC,\n        Bzip2: Bzip2,\n        Dmc: Dmc,\n        Lzjb: Lzjb,\n        LzjbR: LzjbR,\n        Lzp3: Lzp3,\n        PPM: PPM,\n        Simple: Simple\n    });\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/freeze.js":"if (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine([],function(){\n  'use strict';\n\n  // Object.freeze(), or a thunk if that method is not present in this\n  // JavaScript environment.\n\n  if (Object.freeze) {\n    return Object.freeze;\n  } else {\n    return function(o) { return o; };\n  }\n\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/BitStream.js":"/** Big-Endian Bit Stream, implemented on top of a (normal byte) stream. */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./Stream'],function(Stream) {\n\n    var BitStream = function(stream) {\n        (function() {\n            var bufferByte = 0x100; // private var for readers\n            this.readBit = function() {\n                if ((bufferByte & 0xFF) === 0) {\n                    var ch = stream.readByte();\n                    if (ch === Stream.EOF) {\n                        this._eof = true;\n                        return ch; /* !!! */\n                    }\n                    bufferByte = (ch << 1) | 1;\n                }\n                var bit = (bufferByte & 0x100) ? 1 : 0;\n                bufferByte <<= 1;\n                return bit;\n            };\n            // seekable iff the provided stream is\n            this.seekBit = function(pos) {\n                var n_byte = pos >>> 3;\n                var n_bit = pos - (n_byte*8);\n                this.seek(n_byte);\n                this._eof = false;\n                this.readBits(n_bit);\n            };\n            this.tellBit = function() {\n                var pos = stream.tell() * 8;\n                var b = bufferByte;\n                while ((b & 0xFF) !== 0) {\n                    pos--;\n                    b <<= 1;\n                }\n                return pos;\n            };\n            // implement byte stream interface as well.\n            this.readByte = function() {\n                if ((bufferByte & 0xFF) === 0) {\n                    return stream.readByte();\n                }\n                return this.readBits(8);\n            };\n            this.seek = function(pos) {\n                stream.seek(pos);\n                bufferByte = 0x100;\n            };\n        }).call(this);\n        (function() {\n            var bufferByte = 1; // private var for writers\n            this.writeBit = function(b) {\n                bufferByte <<= 1;\n                if (b) { bufferByte |= 1; }\n                if (bufferByte & 0x100) {\n                    stream.writeByte(bufferByte & 0xFF);\n                    bufferByte = 1;\n                }\n            };\n            // implement byte stream interface as well\n            this.writeByte = function(_byte) {\n                if (bufferByte===1) {\n                    stream.writeByte(_byte);\n                } else {\n                    stream.writeBits(8, _byte);\n                }\n            };\n            this.flush = function() {\n                while (bufferByte !== 1) {\n                    this.writeBit(0);\n                }\n                if (stream.flush) { stream.flush(); }\n            };\n        }).call(this);\n    };\n    // inherit read/write methods from Stream.\n    BitStream.EOF = Stream.EOF;\n    BitStream.prototype = Object.create(Stream.prototype);\n    // bit chunk read/write\n    BitStream.prototype.readBits = function(n) {\n        var i, r = 0, b;\n        if (n > 31) {\n            r = this.readBits(n-16)*0x10000; // fp multiply, not shift\n            return r + this.readBits(16);\n        }\n        for (i = 0; i < n; i++) {\n            r <<= 1; // this could make a negative value if n>31\n            // bits read past EOF are all zeros!\n            if (this.readBit() > 0) { r++; }\n        }\n        return r;\n    };\n    BitStream.prototype.writeBits = function(n, value) {\n        if (n > 32) {\n            var low = (value & 0xFFFF);\n            var high = (value - low) / (0x10000); // fp division, not shift\n            this.writeBits(n-16, high);\n            this.writeBits(16, low);\n            return;\n        }\n        var i;\n        for (i = n-1; i >= 0; i--) {\n            this.writeBit( (value >>> i) & 1 );\n        }\n    };\n\n    return BitStream;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/Stream.js":"/** Abstract Stream interface, for byte-oriented i/o. */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./freeze'],function(freeze) {\n    var EOF = -1;\n\n    var Stream = function() {\n        /* ABSTRACT */\n    };\n    // you must define one of read / readByte for a readable stream\n    Stream.prototype.readByte = function() {\n        var buf = [ 0 ];\n        var len = this.read(buf, 0, 1);\n        if (len===0) { this._eof = true; return EOF; }\n        return buf[0];\n    };\n    Stream.prototype.read = function(buf, bufOffset, length) {\n        var ch, bytesRead = 0;\n        while (bytesRead < length) {\n            ch = this.readByte();\n            if (ch === EOF) { this._eof = true; break; }\n            buf[bufOffset+(bytesRead++)] = ch;\n        }\n        return bytesRead;\n    };\n    // reasonable default implementation of 'eof'\n    Stream.prototype.eof = function() { return !!this._eof; };\n    // not all readable streams are seekable\n    Stream.prototype.seek = function(pos) {\n        throw new Error('Stream is not seekable.');\n    };\n    Stream.prototype.tell = function() {\n        throw new Error('Stream is not seekable.');\n    };\n    // you must define one of write / writeByte for a writable stream\n    Stream.prototype.writeByte = function(_byte) {\n        var buf = [ _byte ];\n        this.write(buf, 0, 1);\n    };\n    Stream.prototype.write = function(buf, bufOffset, length) {\n        var i;\n        for (i=0; i<length; i++) {\n            this.writeByte(buf[bufOffset + i]);\n        }\n        return length;\n    };\n    // flush will happily do nothing if you don't override it.\n    Stream.prototype.flush = function() { };\n\n    // export EOF as a constant.\n    Stream.EOF = EOF;\n\n    return freeze(Stream);\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/BWT.js":"/** Burrows-Wheeler transform, computed with the Induced Sorting Suffix Array\n *  construction mechanism (sais).  Code is a port of:\n *    https://sites.google.com/site/yuta256/sais\n *  which is:\n *    Copyright (c) 2008-2010 Yuta Mori All Rights Reserved.\n *  and licensed under an MIT/X11 license.  I generally looked at both\n *  the C and the Java implementations to guide my work.\n *\n * This JavaScript port is:\n *    Copyright (c) 2013 C. Scott Ananian\n * and licensed under GPLv2; see the README at the top level of this package.\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./freeze', './Util'], function(freeze, Util) {\n    var ASSERT = console.assert.bind(console);\n\n    // we're dispensing with the \"arbitrary alphabet\" stuff of the source\n    // and just using Uint8Arrays.\n\n    /** Find the start or end of each bucket. */\n    var getCounts = function(T, C, n, k) {\n        var i;\n        for (i = 0; i < k; i++) { C[i] = 0; }\n        for (i = 0; i < n; i++) { C[T[i]]++; }\n    };\n    var getBuckets = function(C, B, k, end) {\n        var i, sum = 0;\n        if (end) {\n            for (i = 0; i < k; i++) { sum += C[i]; B[i] = sum; }\n        } else {\n            for (i = 0; i < k; i++) { sum += C[i]; B[i] = sum - C[i]; }\n        }\n    };\n\n    /** Sort all type LMS suffixes */\n    var LMSsort = function(T, SA, C, B, n, k) {\n        var b, i, j;\n        var c0, c1;\n        /* compute SAl */\n        if (C === B) { getCounts(T, C, n, k); }\n        getBuckets(C, B, k, false); /* find starts of buckets */\n        j = n - 1;\n        b = B[c1 = T[j]];\n        j--;\n        SA[b++] = (T[j] < c1) ? ~j : j;\n        for (i = 0; i < n; i++) {\n            if ((j = SA[i]) > 0) {\n                ASSERT(T[j] >= T[j+1]);\n                if ((c0 = T[j]) !== c1) { B[c1] = b; b = B[c1 = c0]; }\n                ASSERT(i < b);\n                j--;\n                SA[b++] = (T[j] < c1) ? ~j : j;\n                SA[i] = 0;\n            } else if (j < 0) {\n                SA[i] = ~j;\n            }\n        }\n        /* compute SAs */\n        if (C === B) { getCounts(T, C, n, k); }\n        getBuckets(C, B, k, 1); /* find ends of buckets */\n        for (i = n-1, b = B[c1 = 0]; i >= 0; i--) {\n            if ((j = SA[i]) > 0) {\n                ASSERT(T[j] <= T[j+1]);\n                if ((c0 = T[j]) !== c1) { B[c1] = b; b = B[c1 = c0]; }\n                ASSERT(b <= i);\n                j--;\n                SA[--b] = (T[j] > c1) ? ~(j+1) : j;\n                SA[i] = 0;\n            }\n        }\n    };\n\n    var LMSpostproc = function(T, SA, n, m) {\n        var i, j, p, q, plen, qlen, name;\n        var c0, c1;\n        var diff;\n\n        /* compact all the sorted substrings into the first m items of SA\n         * 2*m must not be larger than n (provable) */\n        ASSERT(n > 0);\n        for (i = 0; (p = SA[i]) < 0; i++) { SA[i] = ~p; ASSERT((i+1) < n); }\n        if (i < m) {\n            for (j = i, i++; ; i++) {\n                ASSERT(i < n);\n                if ((p = SA[i]) < 0) {\n                    SA[j++] = ~p; SA[i] = 0;\n                    if (j === m) { break; }\n                }\n            }\n        }\n\n        /* store the length of all substrings */\n        c0 = T[i = j = n - 1];\n        do { c1 = c0; } while ( ((--i) >= 0 ) && ((c0=T[i]) >= c1) );\n        for (; i >= 0; ) {\n            do { c1 = c0; } while ( ((--i) >= 0 ) && ((c0=T[i]) <= c1) );\n            if (i >= 0) {\n                SA[m + ((i + 1) >>> 1)] = j - i; j = i + 1;\n                do { c1 = c0; } while ( ((--i) >= 0 ) && ((c0=T[i]) >= c1) );\n            }\n        }\n\n        /* find the lexicographic names of all substrings */\n        for (i = 0, name = 0, q = n, qlen = 0; i < m; i++) {\n            p = SA[i]; plen = SA[m + (p >>> 1)]; diff = true;\n            if ((plen === qlen) && ((q + plen) < n)) {\n                for (j = 0; (j < plen) && (T[p + j] === T[q + j]); ) { j++; }\n                if (j === plen) { diff = false; }\n            }\n            if (diff) { name++; q = p; qlen = plen; }\n            SA[m + (p >>> 1)] = name;\n        }\n\n        return name;\n    };\n\n    /* compute SA and BWT */\n    var induceSA = function(T, SA, C, B, n, k) {\n        var b, i, j;\n        var c0, c1;\n        /* compute SAl */\n        if (C === B) { getCounts(T, C, n, k); }\n        getBuckets(C, B, k, false); /* find starts of buckets */\n        j = n - 1;\n        b = B[c1 = T[j]];\n        SA[b++] = ((j > 0) && (T[j-1] < c1)) ? ~j : j;\n        for (i = 0; i < n; i++) {\n            j = SA[i]; SA[i] = ~j;\n            if (j > 0) {\n                j--;\n                ASSERT( T[j] >= T[j + 1] );\n                if ((c0 = T[j]) !== c1) { B[c1]  = b; b = B[c1=c0]; }\n                ASSERT( i < b );\n                SA[b++] = ((j > 0) && (T[j-1] < c1)) ? ~j : j;\n            }\n        }\n        /* compute SAs */\n        if (C === B) { getCounts(T, C, n, k); }\n        getBuckets(C, B, k, true); /* find ends of buckets */\n        for (i = n-1, b = B[c1 = 0]; i >= 0; i--) {\n            if ((j = SA[i]) > 0) {\n                j--;\n                ASSERT( T[j] <= T[j + 1] );\n                if ((c0 = T[j]) !== c1) { B[c1] = b; b = B[c1 = c0]; }\n                ASSERT( b <= i );\n                SA[--b] = ((j === 0) || (T[j - 1] > c1)) ? ~j : j;\n            } else {\n                SA[i] = ~j;\n            }\n        }\n    };\n\n    var computeBWT = function(T, SA, C, B, n, k) {\n        var b, i, j, pidx = -1;\n        var c0, c1;\n        /* compute SAl */\n        if (C === B) { getCounts(T, C, n, k); }\n        getBuckets(C, B, k, false); /* find starts of buckets */\n        j = n - 1;\n        b = B[c1 = T[j]];\n        SA[b++] = ((j > 0) && (T[j - 1] < c1)) ? ~j : j;\n        for (i = 0; i < n; i++) {\n            if ((j=SA[i]) > 0) {\n                j--;\n                ASSERT( T[j] >= T[j+1] );\n                SA[i] = ~(c0 = T[j]);\n                if (c0 !== c1) { B[c1] = b; b = B[c1 = c0]; }\n                ASSERT( i < b );\n                SA[b++] = ((j > 0) && (T[j - 1] < c1)) ? ~j : j;\n            } else if (j !== 0) {\n                SA[i] = ~j;\n            }\n        }\n        /* compute SAs */\n        if (C === B) { getCounts(T, C, n, k); }\n        getBuckets(C, B, k, true); /* find ends of buckets */\n        for (i = n-1, b = B[c1 = 0]; i >= 0; i--) {\n            if ((j = SA[i]) > 0) {\n                j--;\n                ASSERT( T[j] <= T[j+1] );\n                SA[i] = c0 = T[j];\n                if (c0 !== c1) { B[c1] = b; b = B[c1 = c0]; }\n                ASSERT( b <= i );\n                SA[--b] = ((j > 0) && (T[j-1] > c1)) ? (~T[j-1]) : j;\n            } else if (j !== 0) {\n                SA[i] = ~j;\n            } else {\n                pidx = i;\n            }\n        }\n        return pidx;\n    };\n\n    /* find the suffix array SA of T[0..n-1] in {0..k-1}^n\n       use a working space (excluding T and SA) of at most 2n+O(1) for a\n       constant alphabet */\n    var SA_IS = function(T, SA, fs, n, k, isbwt) {\n        var C, B, RA;\n        var i, j, b, c, m, p, q, name, pidx = 0, newfs;\n        var c0, c1;\n        var flags = 0;\n\n        // allocate temporary storage [CSA]\n        if (k <= 256) {\n            C = Util.makeS32Buffer(k);\n            if (k <= fs) { B = SA.subarray(n + fs - k); flags = 1; }\n            else { B = Util.makeS32Buffer(k); flags = 3; }\n        } else if (k <= fs) {\n            C = SA.subarray(n + fs - k);\n            if (k <= (fs - k)) { B = SA.subarray(n + fs - k * 2); flags = 0; }\n            else if (k <= 1024) { B = Util.makeS32Buffer(k); flags = 2; }\n            else { B = C; flags = 8; }\n        } else {\n            C = B = Util.makeS32Buffer(k);\n            flags = 4 | 8;\n        }\n\n        /* stage 1: reduce the problem by at least 1/2\n           sort all the LMS-substrings */\n        getCounts(T, C, n, k);\n        getBuckets(C, B, k, true); /* find ends of buckets */\n        for (i = 0; i < n; i++) { SA[i] = 0; }\n        b = -1; i = n - 1; j = n; m = 0; c0 = T[n - 1];\n        do { c1 = c0; } while ((--i >= 0) && ((c0 = T[i]) >= c1));\n        for (; i >= 0 ;) {\n            do { c1 = c0; } while ((--i >= 0) && ((c0 = T[i]) <= c1));\n            if ( i >= 0 ) {\n                if ( b >= 0 ) { SA[b] = j; }\n                b = --B[c1];\n                j = i;\n                ++m;\n                do { c1 = c0; } while ((--i >= 0) && ((c0 = T[i]) >= c1));\n            }\n        }\n\n        if (m > 1) {\n            LMSsort(T, SA, C, B, n, k);\n            name = LMSpostproc(T, SA, n, m);\n        } else if (m === 1) {\n            SA[b] = j + 1;\n            name = 1;\n        } else {\n            name = 0;\n        }\n\n        /* stage 2: solve the reduced problem\n           recurse if names are not yet unique */\n        if(name < m) {\n            if((flags & 4) !== 0) { C = null; B = null; }\n            if((flags & 2) !== 0) { B = null; }\n            newfs = (n + fs) - (m * 2);\n            if((flags & (1 | 4 | 8)) === 0) {\n                if((k + name) <= newfs) { newfs -= k; }\n                else { flags |= 8; }\n            }\n            ASSERT( (n >>> 1) <= (newfs + m) );\n            for (i = m + (n >>> 1) - 1, j = m * 2 + newfs - 1; m <= i; i--) {\n                if(SA[i] !== 0) { SA[j--] = SA[i] - 1; }\n            }\n            RA = SA.subarray(m + newfs);\n            SA_IS(RA, SA, newfs, m, name, false);\n            RA = null;\n\n            i = n - 1; j = m * 2 - 1; c0 = T[n - 1];\n            do { c1 = c0; } while ((--i >= 0) && ((c0 = T[i]) >= c1));\n            for (; i >= 0 ;) {\n                do { c1 = c0; } while ((--i >= 0) && ((c0 = T[i]) <= c1));\n                if ( i >= 0 ) {\n                    SA[j--] = i + 1;\n                    do { c1 = c0; } while ((--i >= 0) && ((c0 = T[i]) >= c1));\n                }\n            }\n\n            for (i = 0; i < m; i++) { SA[i] = SA[m + SA[i]]; }\n            if((flags & 4) !== 0) { C = B = Util.makeS32Buffer(k); }\n            if((flags & 2) !== 0) { B = Util.makeS32Buffer(k); }\n        }\n\n        /* stage 3: induce the result for the original problem */\n        if((flags & 8) !== 0) { getCounts(T, C, n, k); }\n        /* put all left-most S characters into their buckets */\n        if (m > 1) {\n            getBuckets(C, B, k, true); /* find ends of buckets */\n            i = m - 1; j = n; p = SA[m - 1]; c1 = T[p];\n            do {\n                q = B[c0 = c1];\n                while (q < j) { SA[--j] = 0; }\n                do {\n                    SA[--j] = p;\n                    if(--i < 0) { break; }\n                    p = SA[i];\n                } while((c1 = T[p]) === c0);\n            } while (i >= 0 );\n            while ( j > 0 ) { SA[--j] = 0; }\n        }\n        if (!isbwt) { induceSA(T, SA, C, B, n, k); }\n        else { pidx = computeBWT(T, SA, C, B, n, k); }\n        C = null; B = null;\n        return pidx;\n    };\n\n    var BWT = Object.create(null);\n    /** SA should be a Int32Array (signed!); T can be any typed array.\n     *  alphabetSize is optional if T is an Uint8Array or Uint16Array. */\n    BWT.suffixsort = function(T, SA, n, alphabetSize) {\n        ASSERT( T && SA && T.length >= n && SA.length >= n );\n        if (n <= 1) {\n            if (n === 1) { SA[0] = 0; }\n            return 0;\n        }\n        if (!alphabetSize) {\n            if (T.BYTES_PER_ELEMENT === 1) { alphabetSize = 256; }\n            else if (T.BYTES_PER_ELEMENT === 2) { alphabetSize = 65536; }\n            else throw new Error('Need to specify alphabetSize');\n        }\n        ASSERT( alphabetSize > 0 );\n        if (T.BYTES_PER_ELEMENT) {\n            ASSERT( alphabetSize <= (1 << (T.BYTES_PER_ELEMENT*8) ) );\n        }\n        return SA_IS(T, SA, 0, n, alphabetSize, false);\n    };\n    /** Burrows-Wheeler Transform.\n        A should be Int32Array (signed!); T can be any typed array.\n        U is the same type as T (it is used for output).\n        alphabetSize is optional if T is an Uint8Array or Uint16Array.\n        ASSUMES STRING IS TERMINATED WITH AN EOF CHARACTER.\n    */\n    BWT.bwtransform = function(T, U, A, n, alphabetSize) {\n        var i, pidx;\n        ASSERT( T && U && A );\n        ASSERT( T.length >= n && U.length >= n && A.length >= n );\n        if (n <= 1) {\n            if (n === 1) { U[0] = T[0]; }\n            return n;\n        }\n        if (!alphabetSize) {\n            if (T.BYTES_PER_ELEMENT === 1) { alphabetSize = 256; }\n            else if (T.BYTES_PER_ELEMENT === 2) { alphabetSize = 65536; }\n            else throw new Error('Need to specify alphabetSize');\n        }\n        ASSERT( alphabetSize > 0 );\n        if (T.BYTES_PER_ELEMENT) {\n            ASSERT( alphabetSize <= (1 << (T.BYTES_PER_ELEMENT*8) ) );\n        }\n        pidx = SA_IS(T, A, 0, n, alphabetSize, true);\n        U[0] = T[n - 1];\n        for (i = 0; i < pidx ; i++) { U[i + 1] = A[i]; }\n        for (i += 1; i < n; i++) { U[i] = A[i]; }\n        return pidx + 1;\n    };\n    /** Reverses transform above. (ASSUMED STRING IS TERMINATED WITH EOF.) */\n    BWT.unbwtransform = function(T, U, LF, n, pidx) {\n        var C = Util.makeU32Buffer(256);\n        var i, t;\n        for (i=0; i<256; i++) { C[i] = 0; }\n        for (i=0; i<n; i++) { LF[i] = C[T[i]]++; }\n        for (i=0, t=0; i<256; i++) { t += C[i]; C[i] = t - C[i]; }\n        for (i=n-1, t=0; i>=0; i--) {\n            t = LF[t] + C[U[i]=T[t]];\n            t += (t<pidx) ? 1 : 0;\n        }\n        C = null;\n    };\n\n    /** Burrows-Wheeler Transform.\n        A should be Int32Array (signed!); T can be any typed array.\n        U is the same type as T (it is used for output).\n        alphabetSize is optional if T is an Uint8Array or Uint16Array.\n        ASSUMES STRING IS CYCLIC.\n        (XXX: this is twice as inefficient as I'd like! [CSA])\n    */\n    BWT.bwtransform2 = function(T, U, n, alphabetSize) {\n        var i, j, pidx = 0;\n        ASSERT( T && U );\n        ASSERT( T.length >= n && U.length >= n );\n        if (n <= 1) {\n            if (n === 1) { U[0] = T[0]; }\n            return 0;\n        }\n        if (!alphabetSize) {\n            if (T.BYTES_PER_ELEMENT === 1) { alphabetSize = 256; }\n            else if (T.BYTES_PER_ELEMENT === 2) { alphabetSize = 65536; }\n            else throw new Error('Need to specify alphabetSize');\n        }\n        ASSERT( alphabetSize > 0 );\n        if (T.BYTES_PER_ELEMENT) {\n            ASSERT( alphabetSize <= (1 << (T.BYTES_PER_ELEMENT*8) ) );\n        }\n        // double length of T\n        var TT;\n        if (T.length >= n*2) {\n            TT = T; // do it in place if possible\n        } else if (alphabetSize <= 256) {\n            TT = Util.makeU8Buffer(n*2);\n        } else if (alphabetSize <= 65536) {\n            TT = Util.makeU16Buffer(n*2);\n        } else {\n            TT = Util.makeU32Buffer(n*2);\n        }\n        if (TT!==T) {\n            for (i=0; i<n; i++) { TT[i] = T[i]; }\n        }\n        for (i=0; i<n; i++) { TT[n+i] = TT[i]; }\n        // sort doubled string\n        var A = Util.makeS32Buffer(n*2);\n        SA_IS(TT, A, 0, n*2, alphabetSize, false);\n        for (i=0, j=0; i<2*n; i++) {\n            var s = A[i];\n            if (s < n) {\n                if (s === 0) { pidx = j; }\n                if (--s < 0) { s = n-1; }\n                U[j++] = T[s];\n            }\n        }\n        ASSERT(j===n);\n        return pidx;\n    };\n\n    return freeze(BWT);\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/Util.js":"/* Some basic utilities, used in a number of places. */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./freeze','./Stream'],function(freeze, Stream) {\n    var Util = Object.create(null);\n\n    var EOF = Stream.EOF;\n\n    /* Take a buffer, array, or stream, and return an input stream. */\n    Util.coerceInputStream = function(input, forceRead) {\n        if (!('readByte' in input)) {\n            var buffer = input;\n            input = new Stream();\n            input.size = buffer.length;\n            input.pos = 0;\n            input.readByte = function() {\n                if (this.pos >= this.size) { return EOF; }\n                return buffer[this.pos++];\n            };\n            input.read = function(buf, bufOffset, length) {\n                var bytesRead = 0;\n                while (bytesRead < length && this.pos < buffer.length) {\n                    buf[bufOffset++] = buffer[this.pos++];\n                    bytesRead++;\n                }\n                return bytesRead;\n            };\n            input.seek = function(pos) { this.pos = pos; };\n            input.tell = function() { return this.pos; };\n            input.eof = function() { return this.pos >= buffer.length; };\n        } else if (forceRead && !('read' in input)) {\n            // wrap input if it doesn't implement read\n            var s = input;\n            input = new Stream();\n            input.readByte = function() {\n                var ch = s.readByte();\n                if (ch === EOF) { this._eof = true; }\n                return ch;\n            };\n            if ('size' in s) { input.size = s.size; }\n            if ('seek' in s) {\n                input.seek = function(pos) {\n                    s.seek(pos); // may throw if s doesn't implement seek\n                    this._eof = false;\n                };\n            }\n            if ('tell' in s) {\n                input.tell = s.tell.bind(s);\n            }\n        }\n        return input;\n    };\n\n    var BufferStream = function(buffer, resizeOk) {\n        this.buffer = buffer;\n        this.resizeOk = resizeOk;\n        this.pos = 0;\n    };\n    BufferStream.prototype = Object.create(Stream.prototype);\n    BufferStream.prototype.writeByte = function(_byte) {\n        if (this.resizeOk && this.pos >= this.buffer.length) {\n            var newBuffer = Util.makeU8Buffer(this.buffer.length * 2);\n            newBuffer.set(this.buffer);\n            this.buffer = newBuffer;\n        }\n        this.buffer[this.pos++] = _byte;\n    };\n    BufferStream.prototype.getBuffer = function() {\n        // trim buffer if needed\n        if (this.pos !== this.buffer.length) {\n            if (!this.resizeOk)\n                throw new TypeError('outputsize does not match decoded input');\n            var newBuffer = Util.makeU8Buffer(this.pos);\n            newBuffer.set(this.buffer.subarray(0, this.pos));\n            this.buffer = newBuffer;\n        }\n        return this.buffer;\n    };\n\n    /* Take a stream (or not) and an (optional) size, and return an\n     * output stream.  Return an object with a 'retval' field equal to\n     * the output stream (if that was given) or else a pointer at the\n     * internal Uint8Array/buffer/array; and a 'stream' field equal to\n     * an output stream to use.\n     */\n    Util.coerceOutputStream = function(output, size) {\n        var r = { stream: output, retval: output };\n        if (output) {\n            if (typeof(output)==='object' && 'writeByte' in output) {\n                return r; /* leave output alone */\n            } else if (typeof(size) === 'number') {\n                console.assert(size >= 0);\n                r.stream = new BufferStream(Util.makeU8Buffer(size), false);\n            } else { // output is a buffer\n                r.stream = new BufferStream(output, false);\n            }\n        } else {\n            r.stream = new BufferStream(Util.makeU8Buffer(16384), true);\n        }\n        Object.defineProperty(r, 'retval', {\n            get: r.stream.getBuffer.bind(r.stream)\n        });\n        return r;\n    };\n\n    Util.compressFileHelper = function(magic, guts, suppressFinalByte) {\n        return function(inStream, outStream, props) {\n            inStream = Util.coerceInputStream(inStream);\n            var o = Util.coerceOutputStream(outStream, outStream);\n            outStream = o.stream;\n\n            // write the magic number to identify this file type\n            // (it better be ASCII, we're not doing utf-8 conversion)\n            var i;\n            for (i=0; i<magic.length; i++) {\n                outStream.writeByte(magic.charCodeAt(i));\n            }\n\n            // if we know the size, write it\n            var fileSize;\n            if ('size' in inStream && inStream.size >= 0) {\n                fileSize = inStream.size;\n            } else {\n                fileSize = -1; // size unknown\n            }\n            if (suppressFinalByte) {\n                var tmpOutput = Util.coerceOutputStream([]);\n                Util.writeUnsignedNumber(tmpOutput.stream, fileSize + 1);\n                tmpOutput = tmpOutput.retval;\n                for (i=0; i<tmpOutput.length-1; i++) {\n                    outStream.writeByte(tmpOutput[i]);\n                }\n                suppressFinalByte = tmpOutput[tmpOutput.length-1];\n            } else {\n                Util.writeUnsignedNumber(outStream, fileSize + 1);\n            }\n\n            // call the guts to do the real compression\n            guts(inStream, outStream, fileSize, props, suppressFinalByte);\n\n            return o.retval;\n        };\n    };\n    Util.decompressFileHelper = function(magic, guts) {\n        return function(inStream, outStream) {\n            inStream = Util.coerceInputStream(inStream);\n\n            // read the magic number to confirm this file type\n            // (it better be ASCII, we're not doing utf-8 conversion)\n            var i;\n            for (i=0; i<magic.length; i++) {\n                if (magic.charCodeAt(i) !== inStream.readByte()) {\n                    throw new Error(\"Bad magic\");\n                }\n            }\n\n            // read the file size & create an appropriate output stream/buffer\n            var fileSize = Util.readUnsignedNumber(inStream) - 1;\n            var o = Util.coerceOutputStream(outStream, fileSize);\n            outStream = o.stream;\n\n            // call the guts to do the real decompression\n            guts(inStream, outStream, fileSize);\n\n            return o.retval;\n        };\n    };\n    // a helper for simple self-test of model encode\n    Util.compressWithModel = function(inStream, fileSize, model) {\n        var inSize = 0;\n        while (inSize !== fileSize) {\n            var ch = inStream.readByte();\n            if (ch === EOF) {\n                model.encode(256); // end of stream;\n                break;\n            }\n            model.encode(ch);\n            inSize++;\n        }\n    };\n    // a helper for simple self-test of model decode\n    Util.decompressWithModel = function(outStream, fileSize, model) {\n        var outSize = 0;\n        while (outSize !== fileSize) {\n            var ch = model.decode();\n            if (ch === 256) {\n                break; // end of stream;\n            }\n            outStream.writeByte(ch);\n            outSize++;\n        }\n    };\n\n    /** Write a number using a self-delimiting big-endian encoding. */\n    Util.writeUnsignedNumber = function(output, n) {\n        console.assert(n >= 0);\n        var bytes = [], i;\n        do {\n            bytes.push(n & 0x7F);\n            // use division instead of shift to allow encoding numbers up to\n            // 2^53\n            n = Math.floor( n / 128 );\n        } while (n !== 0);\n        bytes[0] |= 0x80; // mark end of encoding.\n        for (i=bytes.length-1; i>=0; i--) {\n            output.writeByte(bytes[i]); // write in big-endian order\n        }\n        return output;\n    };\n\n    /** Read a number using a self-delimiting big-endian encoding. */\n    Util.readUnsignedNumber = function(input) {\n        var n = 0, c;\n        while (true) {\n            c = input.readByte();\n            if (c&0x80) { n += (c&0x7F); break; }\n            // using + and * instead of << allows decoding numbers up to 2^53\n            n = (n + c) * 128;\n        }\n        return n;\n    };\n\n    // Compatibility thunks for Buffer/TypedArray constructors.\n\n    var zerofill = function(a) {\n        for (var i = 0, len = a.length; i < len; i++) {\n            a[i] = 0;\n        }\n        return a;\n    };\n\n    var fallbackarray = function(size) {\n        return zerofill(new Array(size));\n    };\n\n    // Node 0.11.6 - 0.11.10ish don't properly zero fill typed arrays.\n    // See https://github.com/joyent/node/issues/6664\n    // Try to detect and workaround the bug.\n    var ensureZeroed = function id(a) { return a; };\n    if ((typeof(process) !== 'undefined') &&\n        Array.prototype.some.call(new Uint32Array(128), function(x) {\n            return x !== 0;\n        })) {\n        //console.warn('Working around broken TypedArray');\n        ensureZeroed = zerofill;\n    }\n\n    /** Portable 8-bit unsigned buffer. */\n    Util.makeU8Buffer = (typeof(Uint8Array) !== 'undefined') ? function(size) {\n        // Uint8Array ought to be  automatically zero-filled\n        return ensureZeroed(new Uint8Array(size));\n    } : (typeof(Buffer) !== 'undefined') ? function(size) {\n        var b = new Buffer(size);\n        b.fill(0);\n        return b;\n    } : fallbackarray;\n\n    /** Portable 16-bit unsigned buffer. */\n    Util.makeU16Buffer = (typeof(Uint16Array) !== 'undefined') ? function(size) {\n        // Uint16Array ought to be  automatically zero-filled\n        return ensureZeroed(new Uint16Array(size));\n    } : fallbackarray;\n\n    /** Portable 32-bit unsigned buffer. */\n    Util.makeU32Buffer = (typeof(Uint32Array) !== 'undefined') ? function(size) {\n        // Uint32Array ought to be  automatically zero-filled\n        return ensureZeroed(new Uint32Array(size));\n    } : fallbackarray;\n\n    /** Portable 32-bit signed buffer. */\n    Util.makeS32Buffer = (typeof(Int32Array) !== 'undefined') ? function(size) {\n        // Int32Array ought to be  automatically zero-filled\n        return ensureZeroed(new Int32Array(size));\n    } : fallbackarray;\n\n    Util.arraycopy = function(dst, src) {\n        console.assert(dst.length >= src.length);\n        for (var i = 0, len = src.length; i < len ; i++) {\n            dst[i] = src[i];\n        }\n        return dst;\n    };\n\n    /** Highest bit set in a byte. */\n    var bytemsb = [\n        0, 1, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n        5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7,\n        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n        7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8 /* 256 */\n    ];\n    console.assert(bytemsb.length===0x100);\n    /** Find last set (most significant bit).\n     *  @return the last bit set in the argument.\n     *          <code>fls(0)==0</code> and <code>fls(1)==1</code>. */\n    var fls = Util.fls = function(v) {\n        console.assert(v>=0);\n        if (v > 0xFFFFFFFF) { // use floating-point mojo\n            return 32 + fls(Math.floor(v / 0x100000000));\n        }\n        if ( (v & 0xFFFF0000) !== 0) {\n            if ( (v & 0xFF000000) !== 0) {\n                return 24 + bytemsb[(v>>>24) & 0xFF];\n            } else {\n                return 16 + bytemsb[v>>>16];\n            }\n        } else if ( (v & 0x0000FF00) !== 0) {\n            return 8 + bytemsb[v>>>8];\n        } else {\n            return bytemsb[v];\n        }\n    };\n    /** Returns ceil(log2(n)) */\n    Util.log2c = function(v) {\n        return (v===0)?-1:fls(v-1);\n    };\n\n    return freeze(Util); // ensure constants are recognized as such.\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/Context1Model.js":"/** A simple context-1 model. */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./BitStream','./Huffman','./Util'], function(BitStream,Huffman,Util) {\n\nvar Context1Model = function(modelFactory, contextSize, alphabetSize) {\n  var i;\n  this.literalModel = [];\n  // even if there's an EOF symbol, we don't need a context for it!\n  for (i=0; i<contextSize; i++) {\n    this.literalModel[i] = modelFactory(alphabetSize);\n  }\n};\nContext1Model.prototype.encode = function(ch, context) {\n  this.literalModel[context].encode(ch);\n};\nContext1Model.prototype.decode = function(context) {\n  return this.literalModel[context].decode();\n};\n\n/** Simple self-test. */\nContext1Model.MAGIC='ctx1';\nContext1Model.compressFile = Util.compressFileHelper(Context1Model.MAGIC, function(inStream, outStream, fileSize, props) {\n  var bitstream = new BitStream(outStream);\n  var alphabetSize = 256;\n  if (fileSize < 0) { alphabetSize++; }\n  var coder = Huffman.factory(bitstream, 8191);\n  var model = new Context1Model(coder, 256, alphabetSize);\n  var lastchar = 0x20;\n  var modelp = {\n    encode: function(symbol) {\n      model.encode(symbol, lastchar);\n      lastchar = symbol;\n    }\n  };\n  Util.compressWithModel(inStream, fileSize, modelp);\n  bitstream.flush();\n});\nContext1Model.decompressFile = Util.decompressFileHelper(Context1Model.MAGIC, function(inStream, outStream, fileSize) {\n  var bitstream = new BitStream(inStream);\n  var alphabetSize = 256;\n  if (fileSize < 0) { alphabetSize++; }\n  var coder = Huffman.factory(bitstream, 8191);\n  var model = new Context1Model(coder, 256, alphabetSize);\n  var lastchar = 0x20;\n  var modelp = {\n    decode: function() {\n      var symbol = model.decode(lastchar);\n      lastchar = symbol;\n      return symbol;\n    }\n  };\n  Util.decompressWithModel(outStream, fileSize, modelp);\n});\n\nreturn Context1Model;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/Huffman.js":"/* Adaptive Huffman code, using Vitter's algorithm ported from\n * vitter.c at http://code.google.com/p/compression-code/downloads/list\n * The original code was placed in the public domain, and so I\n * also place this JavaScript port in the public domain.\n *   -- C. Scott Ananian <cscott@cscott.net>, 2013\n * ps. some truly grotty C code in the originally, faithfully ported to\n *     evil comma-operator-using, assignment-in-if-condition JavaScript.\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./BitStream','./Util'],function(BitStream,Util) {\n//  This code is adapted from Professor Vitter's\n//  article, Design and Analysis of Dynamic Huffman Codes,\n//  which appeared in JACM October 1987\n\n//  A design trade-off has been made to simplify the\n//  code:  a node's block is determined dynamically,\n//  and the implicit tree structure is maintained,\n//  e.g. explicit node numbers are also implicit.\n\n//  Dynamic Huffman table weight ranking\n//  is maintained per Professor Vitter's\n//  invariant (*) for algorithm FGK:\n\n//  leaves precede internal nodes of the\n//  same weight in a non-decreasing ranking\n//  of weights using implicit node numbers:\n\n//  1) leaves slide over internal nodes, internal nodes\n//  swap over groups of leaves, leaves are swapped\n//  into group leader position, but two internal\n//  nodes never change positions relative\n//  to one another.\n\n//  2) weights are incremented by 2:\n//  leaves always have even weight values;\n//  internal nodes always have odd values.\n\n//  3) even node numbers are always right children;\n//  odd numbers are left children in the tree.\n\n//  node 2 * HuffSize - 1 is always the tree root;\n//  node HuffEsc is the escape node;\n\n//  the tree is initialized by creating an\n//  escape node as the root.\n\n//  each new leaf symbol is paired with a new escape\n//  node into the previous escape node in the tree,\n//  until the last symbol which takes over the\n//  tree position of the escape node, and\n//  HuffEsc is left at zero.\n\n//  overall table size: 2 * HuffSize\n\n//  huff_init(alphabet_size, potential symbols used)\n//  huff_encode(next_symbol)\n//  next_symbol = huff_decode()\n\n//  huff_scale(by_bits) -- scale weights and re-balance tree\n\nvar HTable = function(up, down, symbol, weight) {\n    this.up = up; // next node up the tree\n    this.down = down; // pair of down nodes\n    this.symbol = symbol;       // node symbol value\n    this.weight = weight;       // node weight\n};\nHTable.prototype.clone = function() {\n  return new HTable(this.up, this.down, this.symbol, this.weight);\n};\nHTable.prototype.set = function(htable) {\n  this.up = htable.up;\n  this.down = htable.down;\n  this.symbol = htable.symbol;\n  this.weight = htable.weight;\n};\n\n//  initialize an adaptive coder\n//  for alphabet size, and count\n//  of nodes to be used\nvar Huffman = function(size, root, bitstream, max_weight) {\n  var i;\n  //  default: all alphabet symbols are used\n\n  console.assert(size && typeof(size)==='number');\n  if( !root || root > size )\n      root = size;\n\n  //  create the initial escape node\n  //  at the tree root\n\n  if ( root <<= 1 ) {\n      root--;\n  }\n\n  // create root+1 htables (coding table)\n  // XXX this could be views on a backing Uint32 array?\n  this.table = [];\n  for (i=0; i<=root; i++) {\n    this.table[i] = new HTable(0,0,0,0);\n  }\n\n  // this.map => mapping for symbols to nodes\n  this.map = [];\n  // this.size => the alphabet size\n  if( this.size = size ) {\n    for (i=0; i<size; i++) {\n      this.map[i] = 0;\n    }\n  }\n\n  // this.esc  => the current tree height\n  // this.root => the root of the tree\n  this.esc = this.root = root;\n\n  if (bitstream) {\n    this.readBit = bitstream.readBit.bind(bitstream);\n    this.writeBit = bitstream.writeBit.bind(bitstream);\n  }\n  this.max_weight = max_weight; // may be null or undefined\n}\n// factory interface\nHuffman.factory = function(bitstream, max_weight) {\n  return function(size) {\n    return new Huffman(size, size, bitstream, max_weight);\n  };\n};\n\n\n// split escape node to incorporate new symbol\n\nHuffman.prototype.split = function(symbol) {\n  var pair, node;\n\n  //  is the tree already full???\n\n  if( pair = this.esc ) {\n    this.esc--;\n  } else {\n    console.assert(false);\n    return 0;\n  }\n\n  //  if this is the last symbol, it moves into\n  //  the escape node's old position, and\n  //  this.esc is set to zero.\n\n  //  otherwise, the escape node is promoted to\n  //  parent a new escape node and the new symbol.\n\n  if( node = this.esc ) {\n    this.table[pair].down = node;\n    this.table[pair].weight = 1;\n    this.table[node].up = pair;\n    this.esc--;\n  } else {\n    pair = 0;\n    node = 1;\n  }\n\n  //  initialize the new symbol node\n\n  this.table[node].symbol = symbol;\n  this.table[node].weight = 0;\n  this.table[node].down = 0;\n  this.map[symbol] = node;\n\n  //  initialize a new escape node.\n\n  this.table[this.esc].weight = 0;\n  this.table[this.esc].down = 0;\n  this.table[this.esc].up = pair;\n  return node;\n};\n\n//  swap leaf to group leader position\n//  return symbol's new node\n\nHuffman.prototype.leader = function(node) {\n  var weight = this.table[node].weight;\n  var leader = node, prev, symbol;\n\n  while( weight === this.table[leader + 1].weight ) {\n    leader++;\n  }\n\n  if( leader === node ) {\n    return node;\n  }\n\n  // swap the leaf nodes\n\n  symbol = this.table[node].symbol;\n  prev = this.table[leader].symbol;\n\n  this.table[leader].symbol = symbol;\n  this.table[node].symbol = prev;\n  this.map[symbol] = leader;\n  this.map[prev] = node;\n  return leader;\n};\n\n//  slide internal node up over all leaves of equal weight;\n//  or exchange leaf with next smaller weight internal node\n\n//  return node's new position\n\nHuffman.prototype.slide = function(node) {\n  var next = node;\n  var swap;\n\n  swap = this.table[next++].clone();\n\n  // if we're sliding an internal node, find the\n  // highest possible leaf to exchange with\n\n  if( swap.weight & 1 ) {\n    while( swap.weight > this.table[next + 1].weight ) {\n      next++;\n    }\n  }\n\n  //  swap the two nodes\n\n  this.table[node].set(this.table[next]);\n  this.table[next].set(swap);\n\n  this.table[next].up = this.table[node].up;\n  this.table[node].up = swap.up;\n\n  //  repair the symbol map and tree structure\n\n  if( swap.weight & 1 ) {\n    this.table[swap.down].up = next;\n    this.table[swap.down - 1].up = next;\n    this.map[this.table[node].symbol] = node;\n  } else {\n    this.table[this.table[node].down - 1].up = node;\n    this.table[this.table[node].down].up = node;\n    this.map[swap.symbol] = next;\n  }\n\n  return next;\n};\n\n//  increment symbol weight and re balance the tree.\n\nHuffman.prototype.increment = function(node) {\n  var up;\n\n  //  obviate swapping a parent with its child:\n  //    increment the leaf and proceed\n  //    directly to its parent.\n\n  //  otherwise, promote leaf to group leader position in the tree\n\n  if( this.table[node].up === node + 1 ) {\n    this.table[node].weight += 2;\n    node++;\n  } else {\n    node = this.leader (node);\n  }\n\n  //  increase the weight of each node and slide\n  //  over any smaller weights ahead of it\n  //  until reaching the root\n\n  //  internal nodes work upwards from\n  //  their initial positions; while\n  //  symbol nodes slide over first,\n  //  then work up from their final\n  //  positions.\n\n  while( this.table[node].weight += 2, up = this.table[node].up ) {\n    while( this.table[node].weight > this.table[node + 1].weight ) {\n        node = this.slide (node);\n    }\n\n    if( this.table[node].weight & 1 ) {\n        node = up;\n    } else {\n        node = this.table[node].up;\n    }\n  }\n\n  /* Re-scale if necessary. */\n  if (this.max_weight) {\n    if (this.table[this.root].weight >= this.max_weight) {\n      this.scale(1);\n    }\n  }\n};\n\n//  scale all weights and re-balance the tree\n\n//  zero weight nodes are removed from the tree\n//  by sliding them out the left of the rank list\n\nHuffman.prototype.scale = function(bits) {\n  var node = this.esc, weight, prev;\n\n  //  work up the tree from the escape node\n  //  scaling weights by the value of bits\n\n  while( ++node <= this.root ) {\n    //  recompute the weight of internal nodes;\n    //  slide down and out any unused ones\n\n    if( this.table[node].weight & 1 ) {\n      if( weight = this.table[this.table[node].down].weight & ~1 ) {\n        weight += this.table[this.table[node].down - 1].weight | 1;\n      }\n\n      //  remove zero weight leaves by incrementing HuffEsc\n      //  and removing them from the symbol map.  take care\n\n    } else if( !(weight = this.table[node].weight >> bits & ~1) ) {\n      if( this.map[this.table[node].symbol] = 0, this.esc++ ) {\n        this.esc++;\n      }\n    }\n\n    // slide the scaled node back down over any\n    // previous nodes with larger weights\n\n    this.table[node].weight = weight;\n    prev = node;\n\n    while( weight < this.table[--prev].weight ) {\n      this.slide(prev);\n    }\n  }\n\n  // prepare a new escape node\n\n  this.table[this.esc].down = 0;\n};\n\n//  send the bits for an escaped symbol\n\nHuffman.prototype.sendid = function(symbol) {\n  var empty = 0, max;\n\n  //  count the number of empty symbols\n  //  before the symbol in the table\n\n  while( symbol-- ) {\n    if( !this.map[symbol] ) {\n      empty++;\n    }\n  }\n\n  //  send LSB of this count first, using\n  //  as many bits as are required for\n  //  the maximum possible count\n\n  if( max = this.size - Math.floor((this.root - this.esc) / 2) - 1 ) {\n    do {\n      this.writeBit(empty & 1);\n      empty >>= 1;\n    } while( max >>= 1 );\n  }\n};\n\n//  encode the next symbol\n\nHuffman.prototype.encode = function(symbol) {\n  var emit = 1, bit;\n  var up, idx, node;\n\n  if( symbol < this.size ) {\n    node = this.map[symbol];\n  } else {\n    console.assert(false);\n    return;\n  }\n\n  //  for a new symbol, direct the receiver to the escape node\n  //  but refuse input if table is already full.\n\n  if( !(idx = node) ) {\n    if( !(idx = this.esc) ) {\n      return;\n    }\n  }\n\n  //  accumulate the code bits by\n  //  working up the tree from\n  //  the node to the root\n\n  while( up = this.table[idx].up ) {\n    emit <<= 1; emit |= idx & 1; idx = up;\n  }\n\n  //  send the code, root selector bit first\n\n  while( bit = emit & 1, emit >>= 1 ) {\n    this.writeBit(bit);\n  }\n\n  //  send identification and incorporate\n  //  new symbols into the tree\n\n  if( !node ) {\n    this.sendid(symbol);\n    node = this.split(symbol);\n  }\n\n  //  adjust and re-balance the tree\n\n  this.increment(node);\n};\n\n//  read the identification bits\n//  for an escaped symbol\n\nHuffman.prototype.readid = function() {\n  var empty = 0, bit = 1, max, symbol;\n\n  //  receive the symbol, LSB first, reading\n  //  only the number of bits necessary to\n  //  transmit the maximum possible symbol value\n\n  if( max = this.size - Math.floor((this.root - this.esc) / 2) - 1 ) {\n    do {\n      empty |= this.readBit() ? bit : 0;\n      bit <<= 1;\n    } while( max >>= 1 );\n  }\n\n  //  the count is of unmapped symbols\n  //  in the table before the new one\n\n  for( symbol = 0; symbol < this.size; symbol++ ) {\n    if( !this.map[symbol] ) {\n      if( !empty-- ) {\n        return symbol;\n      }\n    }\n  }\n\n  //  oops!  our count is too big, either due\n  //  to a bit error, or a short node count\n  //  given to huff_init.\n\n  console.assert(false);\n  return 0;\n};\n\n//  decode the next symbol\n\nHuffman.prototype.decode = function() {\n  var node = this.root;\n  var symbol, down;\n\n  //  work down the tree from the root\n  //  until reaching either a leaf\n  //  or the escape node.  A one\n  //  bit means go left, a zero\n  //  means go right.\n\n  while( down = this.table[node].down ) {\n    if( this.readBit() ) {\n      node = down - 1;  // the left child precedes the right child\n    } else {\n      node = down;\n    }\n  }\n\n  //  sent to the escape node???\n  //  refuse to add to a full tree\n\n  if( node === this.esc ) {\n    if( this.esc ) {\n      symbol = this.readid ();\n      node = this.split (symbol);\n    } else {\n      console.assert(false);\n      return 0;\n    }\n  } else {\n    symbol = this.table[node].symbol;\n  }\n\n  //  increment weights and re-balance\n  //  the coding tree\n\n  this.increment (node);\n  return symbol;\n};\n\n// stand alone compressor, mostly for testing\nHuffman.MAGIC = 'huff';\nHuffman.compressFile = Util.compressFileHelper(Huffman.MAGIC, function(input, output, size, props) {\n  var bitstream = new BitStream(output);\n\n  var alphabetSize = 256;\n  if (size < 0) { alphabetSize++; }\n  var huff = new Huffman(257, alphabetSize, bitstream, 8191);\n  Util.compressWithModel(input, size, huff);\n  bitstream.flush();\n});\n\n// stand alone decompresser, again for testing\nHuffman.decompressFile = Util.decompressFileHelper(Huffman.MAGIC, function(input, output, size) {\n  var bitstream = new BitStream(input);\n\n  var alphabetSize = 256;\n  if (size < 0) { alphabetSize++; }\n  var huff = new Huffman(257, alphabetSize, bitstream, 8191);\n  Util.decompressWithModel(output, size, huff);\n});\n\nreturn Huffman;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/DefSumModel.js":"/** Deferred-sum model, suitable for small ( ~ 256 ) ranges. */\n// See http://cbloom.com/src/defsum.zip\n//     http://cbloom.com/papers/context.pdf\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./RangeCoder','./Stream','./Util'],function(RangeCoder,Stream,Util){\n\nvar LOG_PROB_TOTAL = 8;\nvar PROB_TOTAL = 1 << LOG_PROB_TOTAL;\nvar MAX_ESCAPE_COUNT = 40;\n\nvar DefSumModel = function(coder, size, isDecoder) {\n  var i;\n  console.assert(size < 300); // not meant for sparse\n  var ESCAPE = this.numSyms = size;\n  this.coder = coder;\n  this.prob = Util.makeU16Buffer(size+2); /* size + ESC + 1 */\n  this.escape = Util.makeU16Buffer(size+1);  /* size + 1*/\n  this.update = Util.makeU16Buffer(size+1); /* size + ESC */\n  this.prob[ESCAPE+1] = PROB_TOTAL;\n  for (i=0; i<=this.numSyms; i++) {\n    this.escape[i] = i;\n  }\n  this.updateCount = 0;\n  this.updateThresh = PROB_TOTAL - Math.floor(PROB_TOTAL / 2);\n  if (!isDecoder) { return; }\n  // extra tables for fast decoding\n  this.probToSym = Util.makeU16Buffer(PROB_TOTAL);\n  this.escProbToSym = Util.makeU16Buffer(this.numSyms);\n  for (i=0; i<PROB_TOTAL; i++) {\n    this.probToSym[i] = ESCAPE;\n  }\n  for (i=0; i<this.numSyms; i++) {\n    this.escProbToSym[i] = i;\n  }\n};\nDefSumModel.factory = function(coder, isDecoder) {\n  return function(size) { return new DefSumModel(coder, size, isDecoder); };\n};\nDefSumModel.prototype._update = function(symbol, isDecoder) {\n  if (symbol === this.numSyms) {\n    // some special cases for the escape character\n    if (this.update[symbol] >= MAX_ESCAPE_COUNT) { return; } // hard limit\n    // don't let an escape character trigger an update, because then the\n    // escaped character might find itself unescaped after the tables have\n    // been updated!\n    if (this.updateCount >= (this.updateThresh - 1)) { return; }\n  }\n  this.update[symbol]++;\n  this.updateCount++;\n  // is it time to transfer the updated probabilities?\n  if (this.updateCount < this.updateThresh) {\n    return; //defer update\n  }\n  var cumProb, cumEscProb, odd, i, j, k;\n  this.escape[0] = this.prob[0] = cumProb = cumEscProb = odd = 0;\n  for (i=0; i < this.numSyms+1; i++) {\n    var newProb = ((this.prob[i+1]-this.prob[i]) >>> 1) + this.update[i];\n    if (newProb) {\n      // live 'un\n      this.prob[i] = cumProb;\n      cumProb += newProb;\n      if (newProb & 1) { odd++; }\n      this.escape[i] = cumEscProb;\n    } else {\n      // this symbol will escape\n      this.prob[i] = cumProb;\n      this.escape[i] = cumEscProb;\n      cumEscProb++;\n    }\n  }\n  this.prob[i] = cumProb;\n  console.assert(cumProb === PROB_TOTAL);\n  /* how many updates will be required after current probs are halved? */\n  this.updateThresh = PROB_TOTAL - Math.floor((cumProb-odd) / 2);\n  /* reset the update table */\n  for (i=0; i < (this.numSyms + 1); i++) {\n    this.update[i] = 0;\n  }\n  this.update[this.numSyms] = 1; // ensure that escape never goes away\n  this.updateCount = 1;\n  /* compute decode table, if this is a decoder */\n  if (!isDecoder) { return; }\n  for (i=0, j=0, k=0; i<(this.numSyms+1); i++) {\n    var probLimit = this.prob[i+1];\n    for (; j<probLimit; j++) {\n      this.probToSym[j] = i;\n    }\n    var escProbLimit = this.escape[i+1];\n    for (; k<escProbLimit; k++) {\n      this.escProbToSym[k] = i;\n    }\n  }\n};\nDefSumModel.prototype.encode = function(symbol) {\n  var lt_f = this.prob[symbol];\n  var sy_f = this.prob[symbol+1] - lt_f;\n  console.assert(this.prob[this.numSyms+1] === PROB_TOTAL);\n  if (sy_f) {\n    this.coder.encodeShift(sy_f, lt_f, LOG_PROB_TOTAL);\n    return this._update(symbol);\n  }\n  // escape!\n  console.assert(symbol !== this.numSyms); // catch infinite recursion\n  this.encode(this.numSyms); // guaranteed non-zero probability\n  // code symbol as literal, taking advantage of reduced escape range.\n  lt_f = this.escape[symbol];\n  sy_f = this.escape[symbol+1] - lt_f;\n  var tot_f = this.escape[this.numSyms];\n  this.coder.encodeFreq(sy_f, lt_f, tot_f);\n  return this._update(symbol);\n};\nDefSumModel.prototype.decode = function() {\n  var prob = this.coder.decodeCulShift(LOG_PROB_TOTAL);\n  var symbol = this.probToSym[prob];\n  var lt_f = this.prob[symbol];\n  var sy_f = this.prob[symbol+1] - lt_f;\n  this.coder.decodeUpdate(sy_f, lt_f, PROB_TOTAL);\n  this._update(symbol, true);\n  if (symbol !== this.numSyms) {\n    return symbol;\n  }\n  // escape!\n  var tot_f = this.escape[this.numSyms];\n  prob = this.coder.decodeCulFreq(tot_f);\n  symbol = this.escProbToSym[prob];\n  lt_f = this.escape[symbol];\n  sy_f = this.escape[symbol+1] - lt_f;\n  this.coder.decodeUpdate(sy_f, lt_f, tot_f);\n  this._update(symbol, true);\n  return symbol;\n};\n\nDefSumModel.MAGIC='dfsm';\n/** Simple order-0 compressor, as self-test. */\nDefSumModel.compressFile = Util.compressFileHelper(DefSumModel.MAGIC, function(inStream, outStream, fileSize, props, finalByte) {\n  var range = new RangeCoder(outStream);\n  range.encodeStart(finalByte, 1);\n  var model = new DefSumModel(range, (fileSize<0) ? 257 : 256);\n  Util.compressWithModel(inStream, fileSize, model);\n  range.encodeFinish();\n},true);\n/** Simple order-0 decompresser, as self-test. */\nDefSumModel.decompressFile = Util.decompressFileHelper(DefSumModel.MAGIC, function(inStream, outStream, fileSize) {\n  var range = new RangeCoder(inStream);\n  range.decodeStart(true/*already read the final byte*/);\n  var model = new DefSumModel(range, (fileSize<0) ? 257 : 256, true);\n  Util.decompressWithModel(outStream, fileSize, model);\n  range.decodeFinish();\n});\n\nreturn DefSumModel;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/RangeCoder.js":"/* Range Coder.  Inspired by rangecod.c from rngcod13.zip from\n *    http://www.compressconsult.com/rangecoder/\n * This JavaScript version is:\n *    Copyright (c) 2013 C. Scott Ananian.\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine([],function(){\n\n    // Uses 32-bit integer math.  Hopefully the JavaScript runtime figures\n    // that out. ;)\n    // see https://github.com/kripken/emscripten/wiki/LLVM-Types-in-JavaScript\n    // for some hints on doing 32-bit unsigned match in JavaScript.\n    // One key is the use of \">>>0\" to change a signed result to unsigned.\n    var CODE_BITS = 32;\n    var Top_value = Math.pow(2, CODE_BITS-1);\n    var SHIFT_BITS = (CODE_BITS - 9);\n    var EXTRA_BITS = ((CODE_BITS-2) % 8 + 1);\n    var Bottom_value = (Top_value >>> 8);\n\n    var MAX_INT = Math.pow(2, CODE_BITS) - 1;\n\n    /* it is highly recommended that the total frequency count is less  */\n    /* than 1 << 19 to minimize rounding effects.                       */\n    /* the total frequency count MUST be less than 1<<23                */\n\n\n    var RangeCoder = function(stream) {\n        this.low = 0; /* low end of interval */\n        this.range = Top_value; /* length of interval */\n        this.buffer = 0; /* buffer for input/output */\n        this.help = 0; /* bytes_to_follow / intermediate value */\n        this.bytecount = 0; /* counter for output bytes */\n        this.stream = stream;\n    };\n\n    /* Do the normalization before we need a defined state, instead of\n     * after messing it up.  This simplifies starting and ending. */\n    var enc_normalize = function(rc, outputStream) {\n        while (rc.range <= Bottom_value) { /* do we need renormalization? */\n            if (rc.low < (0xFF << SHIFT_BITS)) {//no carry possible, so output\n                outputStream.writeByte(rc.buffer);\n                for (; rc.help; rc.help--)\n                    outputStream.writeByte(0xFF);\n                rc.buffer = (rc.low >>> SHIFT_BITS) & 0xFF;\n            } else if (rc.low & Top_value) { /* carry now, no future carry */\n                outputStream.writeByte(rc.buffer+1);\n                for (; rc.help; rc.help--)\n                    outputStream.writeByte(0x00);\n                rc.buffer = (rc.low >>> SHIFT_BITS) & 0xFF;\n            } else {\n                rc.help++;\n                if (rc.help > MAX_INT)\n                    throw new Error(\"Too many bytes outstanding, \"+\n                                    \"file too large!\");\n            }\n            rc.range = (rc.range << 8) >>> 0;/*ensure result remains positive*/\n            rc.low = ((rc.low << 8) & (Top_value - 1)) >>> 0; /* unsigned */\n            rc.bytecount++;\n        }\n    };\n\n    /* Start the encoder                                         */\n    /* c is written as the first byte in the datastream.\n     * one could do w/o, but then you have an additional if per output byte */\n    RangeCoder.prototype.encodeStart = function(c, initlength) {\n        this.low = 0;\n        this.range = Top_value;\n        this.buffer = c;\n        this.help = 0;\n        this.bytecount = initlength;\n    };\n\n   /* Encode a symbol using frequencies                         */\n    /* rc is the range coder to be used                          */\n    /* sy_f is the interval length (frequency of the symbol)     */\n    /* lt_f is the lower end (frequency sum of < symbols)        */\n    /* tot_f is the total interval length (total frequency sum)  */\n    /* or (faster): tot_f = (code_value)1<<shift                             */\n    RangeCoder.prototype.encodeFreq = function(sy_f, lt_f, tot_f) {\n        enc_normalize(this, this.stream);\n        var r = (this.range / tot_f) >>> 0; // note coercion to integer\n        var tmp = r * lt_f;\n        this.low += tmp;\n        if ((lt_f + sy_f) < tot_f) {\n            this.range = r * sy_f;\n        } else {\n            this.range -= tmp;\n        }\n    };\n    RangeCoder.prototype.encodeShift = function(sy_f, lt_f, shift) {\n        enc_normalize(this, this.stream);\n        var r = this.range >>> shift;\n        var tmp = r * lt_f;\n        this.low += tmp;\n        if ((lt_f + sy_f) >>> shift) {\n            this.range -= tmp;\n        } else {\n            this.range = r * sy_f;\n        }\n    };\n    /* Encode a bit w/o modelling. */\n    RangeCoder.prototype.encodeBit = function(b) {\n        this.encodeShift(1, b?1:0, 1);\n    };\n    /* Encode a byte w/o modelling. */\n    RangeCoder.prototype.encodeByte = function(b) {\n        this.encodeShift(1, b, 8);\n    };\n    /* Encode a short w/o modelling. */\n    RangeCoder.prototype.encodeShort = function(s) {\n        this.encodeShift(1, s, 16);\n    };\n\n    /* Finish encoding                                           */\n    /* returns number of bytes written                           */\n    RangeCoder.prototype.encodeFinish = function() {\n        var outputStream = this.stream;\n        enc_normalize(this, outputStream);\n        this.bytecount += 5;\n        var tmp = this.low >>> SHIFT_BITS;\n        if ((this.low & (Bottom_value-1)) >= ((this.bytecount&0xFFFFFF)>>>1)) {\n            tmp++;\n        }\n        if (tmp > 0xFF) { /* we have a carry */\n            outputStream.writeByte(this.buffer + 1);\n            for (; this.help; this.help--)\n                outputStream.writeByte(0x00);\n        } else { /* no carry */\n            outputStream.writeByte(this.buffer);\n            for (; this.help; this.help--)\n                outputStream.writeByte(0xFF);\n        }\n        outputStream.writeByte(tmp & 0xFF);\n        // XXX: i'm pretty sure these could be three arbitrary bytes\n        //      they are consumed by the decoder at the end\n        outputStream.writeByte((this.bytecount >>> 16) & 0xFF);\n        outputStream.writeByte((this.bytecount >>>  8) & 0xFF);\n        outputStream.writeByte((this.bytecount       ) & 0xFF);\n        return this.bytecount;\n    };\n\n    /* Start the decoder; you need to provide the *second* byte from the\n     * datastream. (The first byte was provided to startEncoding and is\n     * ignored by the decoder.)\n     */\n    RangeCoder.prototype.decodeStart = function(skipInitialRead) {\n        var c = skipInitialRead ? 0 : this.stream.readByte();\n        if (typeof(c) !== 'number' || c < 0) {\n            return c; // EOF\n        }\n        this.buffer = this.stream.readByte();\n        this.low = this.buffer >>> (8 - EXTRA_BITS);\n        this.range = 1 << EXTRA_BITS;\n        return c;\n    };\n\n    var dec_normalize = function(rc, inputStream) {\n        while (rc.range <= Bottom_value) {\n            rc.low = (rc.low << 8) | ((rc.buffer << EXTRA_BITS) & 0xFF);\n            /* rc.low could be negative here; don't fix it quite yet */\n            rc.buffer = inputStream.readByte();\n            rc.low |= rc.buffer >>> (8-EXTRA_BITS);\n            rc.low = rc.low >>> 0; /* fix it now */\n            rc.range = (rc.range << 8) >>> 0; /* ensure stays positive */\n        }\n    };\n\n    /* Calculate cumulative frequency for next symbol. Does NO update!*/\n    /* rc is the range coder to be used                          */\n    /* tot_f is the total frequency                              */\n    /* or: totf is (code_value)1<<shift                                      */\n    /* returns the <= cumulative frequency                         */\n    RangeCoder.prototype.decodeCulFreq = function(tot_f) {\n        dec_normalize(this, this.stream);\n        this.help = (this.range / tot_f) >>> 0; // note coercion to integer\n        var tmp = (this.low / this.help) >>> 0; // again\n        return (tmp >= tot_f ? tot_f-1 : tmp);\n    };\n    RangeCoder.prototype.decodeCulShift = function(shift) {\n        dec_normalize(this, this.stream);\n        this.help = this.range >>> shift;\n        var tmp = (this.low / this.help) >>> 0; // coercion to unsigned\n        // shift is less than 31, so shift below will remain positive\n        return ((tmp>>>shift) ? (1<<shift)-1 : tmp);\n    };\n\n    /* Update decoding state                                     */\n    /* rc is the range coder to be used                          */\n    /* sy_f is the interval length (frequency of the symbol)     */\n    /* lt_f is the lower end (frequency sum of < symbols)        */\n    /* tot_f is the total interval length (total frequency sum)  */\n    RangeCoder.prototype.decodeUpdate = function(sy_f, lt_f, tot_f) {\n        var tmp = this.help * lt_f; // should not overflow!\n        this.low -= tmp;\n        if (lt_f + sy_f < tot_f) {\n            this.range = (this.help * sy_f);\n        } else {\n            this.range -= tmp;\n        }\n    };\n\n    /* Decode a bit w/o modelling. */\n    RangeCoder.prototype.decodeBit = function() {\n        var tmp = this.decodeCulShift(1);\n        this.decodeUpdate(1, tmp, 1<<1);\n        return tmp;\n    };\n    /* decode a byte w/o modelling */\n    RangeCoder.prototype.decodeByte = function() {\n        var tmp = this.decodeCulShift(8);\n        this.decodeUpdate(1, tmp, 1<<8);\n        return tmp;\n    };\n    /* decode a short w/o modelling */\n    RangeCoder.prototype.decodeShort = function() {\n        var tmp = this.decodeCulShift(16);\n        this.decodeUpdate(1, tmp, 1<<16);\n        return tmp;\n    };\n\n    /* Finish decoding */\n    RangeCoder.prototype.decodeFinish = function() {\n        /* normalize to use up all bytes */\n        dec_normalize(this, this.stream);\n    };\n\n    /** Utility functions */\n\n    // bitstream interface\n    RangeCoder.prototype.writeBit = RangeCoder.prototype.encodeBit;\n    RangeCoder.prototype.readBit = RangeCoder.prototype.decodeBit;\n\n    // stream interface\n    RangeCoder.prototype.writeByte = RangeCoder.prototype.encodeByte;\n    RangeCoder.prototype.readByte = RangeCoder.prototype.decodeByte;\n\n    return RangeCoder;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/FenwickModel.js":"/** Range coding model based on Fenwick trees for O(ln N) query/update. */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./RangeCoder','./Stream','./Util'],function(RangeCoder,Stream,Util){\n\n/** We store two probabilities in a U32, so max prob is going to be 0xFFFF */\nvar DEFAULT_MAX_PROB = 0xFF00;\nvar DEFAULT_INCREMENT= 0x0100;\n\nvar ESC_MASK = 0x0000FFFF, ESC_SHIFT = 0;\nvar SYM_MASK = 0xFFFF0000, SYM_SHIFT = 16;\nvar SCALE_MASK=0xFFFEFFFE;\n\nvar FenwickModel = function(coder, size, max_prob, increment) {\n    this.coder = coder;\n    this.numSyms = size + 1; // save space for an escape symbol\n    this.tree = Util.makeU32Buffer(this.numSyms*2);\n    this.increment = (+increment) || DEFAULT_INCREMENT;\n    this.max_prob = (+max_prob) || DEFAULT_MAX_PROB;\n    // sanity-check to prevent overflow.\n    console.assert((this.max_prob + (this.increment-1)) <= 0xFFFF);\n    console.assert(size <= 0xFFFF);\n    // record escape probability as 1.\n    var i;\n    for (i=0; i<size; i++) {\n        this.tree[this.numSyms + i] = // escape prob=1, sym prob = 0\n            (1 << ESC_SHIFT) | (0 << SYM_SHIFT);\n    }\n    this.tree[this.numSyms + i] = // escape prob = 0, sym prob = 1\n        (0 << ESC_SHIFT) | (this.increment << SYM_SHIFT);\n    this._sumTree();\n    // probability sums are in this.tree[1].  this.tree[0] is unused.\n};\nFenwickModel.factory = function(coder, max_prob, increment) {\n    return function(size) {\n        return new FenwickModel(coder, size, max_prob, increment);\n    };\n};\nFenwickModel.prototype.clone = function() {\n    var newModel = new FenwickModel(this.coder, this.size,\n                                    this.max_prob, this.increment);\n    var i;\n    for (i=1; i<this.tree.length; i++) {\n        newModel.tree[i] = this.tree[i];\n    }\n    return newModel;\n};\nFenwickModel.prototype.encode = function(symbol) {\n    var i = this.numSyms + symbol;\n    var sy_f = this.tree[i];\n    var mask = SYM_MASK, shift = SYM_SHIFT;\n    var update = (this.increment << SYM_SHIFT);\n\n    if ((sy_f & SYM_MASK) === 0) { // escape!\n        this.encode(this.numSyms-1);\n        mask = ESC_MASK;\n        update -= (1<<ESC_SHIFT); // not going to escape no mo'\n        shift = ESC_SHIFT;\n    } else if (symbol === (this.numSyms-1) &&\n               ((this.tree[1] & ESC_MASK) >>> ESC_SHIFT) === 1) {\n        // this is the last escape, zero it out\n        update = -this.tree[i];\n    }\n    // sum up the proper lt_f\n    var lt_f = 0;\n    while (i > 1) {\n        var isRight = (i & 1);\n        var parent = (i >>> 1);\n        // if we're the right child, we need to\n        // add the prob from the left child\n        if (isRight) {\n            lt_f += this.tree[2*parent];\n        }\n        // update sums\n        this.tree[i] += update; // increase sym / decrease esc\n        i = parent;\n    }\n    var tot_f = this.tree[1];\n    this.tree[1] += update; // update prob in root\n    sy_f = (sy_f & mask) >>> shift;\n    lt_f = (lt_f & mask) >>> shift;\n    tot_f =(tot_f& mask) >>> shift;\n    this.coder.encodeFreq(sy_f, lt_f, tot_f);\n    // rescale?\n    if ((( this.tree[1] & SYM_MASK ) >>> SYM_SHIFT) >= this.max_prob) {\n        this._rescale();\n    }\n};\nFenwickModel.prototype._decode = function(isEscape) {\n    var mask = SYM_MASK, shift = SYM_SHIFT;\n    var update = (this.increment << SYM_SHIFT);\n    if (isEscape) {\n        mask = ESC_MASK;\n        update -= (1 << ESC_SHIFT);\n        shift = ESC_SHIFT;\n    }\n    var tot_f = (this.tree[1] & mask) >>> shift;\n    var prob = this.coder.decodeCulFreq(tot_f);\n    // travel down the tree looking for this\n    var i = 1, lt_f = 0;\n    while (i < this.numSyms) {\n        this.tree[i] += update;\n        // look at probability in left child.\n        var leftProb = (this.tree[2*i] & mask) >>> shift;\n        i *= 2;\n        if ((prob-lt_f) >= leftProb) {\n            lt_f += leftProb;\n            i++; // take the right child.\n        }\n    }\n    var symbol = i - this.numSyms;\n    var sy_f = (this.tree[i] & mask) >>> shift;\n    this.tree[i] += update;\n    this.coder.decodeUpdate(sy_f, lt_f, tot_f);\n    // was this the last escape?\n    if (symbol === (this.numSyms-1) &&\n        ((this.tree[1] & ESC_MASK) >>> ESC_SHIFT) === 1) {\n        update = -this.tree[i]; // zero it out\n        while (i >= 1) {\n            this.tree[i] += update;\n            i = (i >>> 1); // parent\n        }\n    }\n    // rescale?\n    if ((( this.tree[1] & SYM_MASK ) >>> SYM_SHIFT) >= this.max_prob) {\n        this._rescale();\n    }\n    return symbol;\n};\nFenwickModel.prototype.decode = function() {\n    var symbol = this._decode(false); // not escape\n    if (symbol === (this.numSyms-1)) {\n        // this was an escape!\n        symbol = this._decode(true); // an escape!\n    }\n    return symbol;\n};\nFenwickModel.prototype._rescale = function() {\n    var i, prob, noEscape = true;\n    // scale symbols (possible causing them to escape)\n    for (i=0; i < this.numSyms-1; i++) {\n        prob = this.tree[this.numSyms + i];\n        if ((prob & ESC_MASK) !== 0) {\n            // this symbol escapes\n            noEscape = false;\n            continue;\n        }\n        prob = (prob & SCALE_MASK) >>> 1;\n        if (prob === 0) {\n            // this symbol newly escapes\n            prob = (1 << ESC_SHIFT);\n            noEscape = false;\n        }\n        this.tree[this.numSyms + i] = prob;\n    }\n    // scale the escape symbol\n    prob = this.tree[this.numSyms + i];\n    prob = (prob & SCALE_MASK) >>> 1;\n    // prob should be zero if there are no escaping symbols, otherwise\n    // it must be at least 1.\n    if (noEscape) { prob = 0; }\n    else if (prob === 0) { prob = (1 << SYM_SHIFT); }\n    this.tree[this.numSyms + i] = prob;\n    // sum it all up afresh\n    this._sumTree();\n};\nFenwickModel.prototype._sumTree = function() {\n    var i;\n    // sum it all. (we know we won't overflow)\n    for (i=this.numSyms - 1; i > 0; i--) {\n        this.tree[i] = this.tree[2*i] + this.tree[2*i + 1];\n    }\n};\n\nFenwickModel.MAGIC = 'fenw';\n/** Simple order-0 compressor, as self-test. */\nFenwickModel.compressFile = Util.compressFileHelper(FenwickModel.MAGIC, function(inStream, outStream, fileSize, props, finalByte) {\n    var range = new RangeCoder(outStream);\n    range.encodeStart(finalByte, 1);\n    var model = new FenwickModel(range, (fileSize<0) ? 257 : 256);\n    Util.compressWithModel(inStream, fileSize, model);\n    range.encodeFinish();\n}, true);\n\n/** Simple order-0 decompresser, as self-test. */\nFenwickModel.decompressFile = Util.decompressFileHelper(FenwickModel.MAGIC, function(inStream, outStream, fileSize) {\n    var range = new RangeCoder(inStream);\n    range.decodeStart(true/*already read the final byte*/);\n    var model = new FenwickModel(range, (fileSize<0) ? 257 : 256);\n    Util.decompressWithModel(outStream, fileSize, model);\n    range.decodeFinish();\n});\n\nreturn FenwickModel;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/MTFModel.js":"/** Simple range coding model w/ escape, suitable for sparse symbol sets.\n *  Uses a move-to-front list, which is simple and relatively performant,\n *  but slows down a lot if you want to try to model escapes more precisely\n *  (which is why this feature is disabled by default).\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./RangeCoder','./Stream','./Util'],function(RangeCoder,Stream,Util){\n\nvar DEFAULT_MAX_PROB = 0xFF00;\nvar DEFAULT_INCREMENT= 0x0100;\n\nvar NUMERIC_SORT = function(a, b) { return a - b; };\n\nvar MTFModel = function(coder, size, max_prob, increment, betterEscape) {\n    this.coder = coder;\n    this.increment = (+increment) || DEFAULT_INCREMENT;\n    this.max_prob = (+max_prob) || DEFAULT_MAX_PROB;\n    console.assert((this.max_prob + (this.increment-1)) <= 0xFFFF);\n    this.sym = Util.makeU16Buffer(size+1);\n    this.prob= Util.makeU16Buffer(size+2);\n    this.sym[0] = size; // escape code\n    this.prob[0]= 0;\n    this.seenSyms = 1;\n    // total probability always found in this.prob[this.seenSyms]\n    this.prob[this.seenSyms] = this.increment;\n    this.numSyms = size;\n    if (betterEscape) {\n        this.sortedSeen = [size];\n    }\n};\nMTFModel.factory = function(coder, max_prob, increment, betterEscape) {\n    return function(size) {\n        return new MTFModel(coder, size, max_prob, increment, betterEscape);\n    };\n};\nMTFModel.prototype.clone = function() {\n    var newModel = new MTFModel(this.coder, this.numSyms, this.max_prob,\n                                this.increment, !!this.sortedSeen);\n    var i;\n    for (i=0; i<this.seenSyms; i++) {\n        newModel.sym[i] = this.sym[i];\n        newModel.prob[i] = this.prob[i];\n    }\n    newModel.prob[i] = this.prob[i]; // total probability\n    newModel.seenSyms = this.seenSyms;\n    if (this.sortedSeen) {\n        newModel.sortedSeen = this.sortedSeen.slice(0);\n    }\n    return newModel;\n};\nMTFModel.prototype._update = function(symbol, index, sy_f) {\n    var j, tot_f;\n    // move this symbol to the end\n    for (j=index; j<this.seenSyms-1; j++) {\n        this.sym[j] = this.sym[j+1];\n        this.prob[j] = this.prob[j+1] - sy_f;\n    }\n    if (index < this.seenSyms) {\n        this.sym[j] = symbol;\n        this.prob[j] = this.prob[j+1] - sy_f;\n        // increase frequency for this symbol, and total freq at same time\n        this.prob[this.seenSyms] = tot_f =\n            this.prob[this.seenSyms] + this.increment;\n        if (symbol === this.numSyms && this.seenSyms >= this.numSyms) {\n            // this is the last time we'll see an escape! remove it.\n            tot_f = this.prob[--this.seenSyms];\n            if (this.sortedSeen) { this.sortedSeen.length--; }\n        }\n    } else { // add to the end\n        tot_f = this.prob[this.seenSyms];\n        this.sym[index] = symbol;\n        this.prob[index] = tot_f;\n        tot_f += this.increment;\n        this.prob[++this.seenSyms] = tot_f;\n        if (this.sortedSeen) {\n            this.sortedSeen.push(symbol);\n            // hopefully sort is very fast on a mostly-sorted array\n            this.sortedSeen.sort(NUMERIC_SORT);\n        }\n    }\n    if (tot_f >= this.max_prob) { this._rescale(); }\n    return;\n};\nMTFModel.prototype._rescale = function() {\n    var i, j, total=0;\n    var noEscape = true;\n    if (this.sortedSeen) { this.sortedSeen.length = 0; }\n    for(i=0, j=0; i<this.seenSyms; i++) {\n        var sym = this.sym[i];\n        var sy_f = this.prob[i+1] - this.prob[i];\n        sy_f >>>= 1;\n        if (sy_f > 0) {\n            if (sym === this.numSyms) {\n                noEscape = false;\n            }\n            this.sym[j] = sym;\n            this.prob[j++] = total;\n            total += sy_f;\n            if (this.sortedSeen) { this.sortedSeen.push(sym); }\n        }\n    }\n    this.prob[j] = total;\n    this.seenSyms = j;\n    if (this.sortedSeen) {\n        this.sortedSeen.sort(NUMERIC_SORT);\n    }\n    // don't allow escape to go to zero prob if we still need it\n    if (noEscape && this.seenSyms < this.numSyms) {\n        // NOTE this adds this.increment to escape freq; the FenwickModel\n        //      just adds one.\n        this._update(this.numSyms/*escape*/, this.seenSyms/*at end*/);\n    }\n};\nMTFModel.prototype.decode = function() {\n    var tot_f = this.prob[this.seenSyms];\n    var prob = this.coder.decodeCulFreq(tot_f);\n    // we're expecting to find the probability near the \"most recent\" side\n    // of our array\n    var i;\n    for (i=this.seenSyms-1; i>=0; i--) {\n        if (this.prob[i] <= prob /*&& prob < this.prob[i+1]*/)\n            break;\n    }\n    console.assert(i>=0);\n    var symbol = this.sym[i];\n    var lt_f = this.prob[i];\n    var sy_f = this.prob[i + 1] - lt_f;\n    this.coder.decodeUpdate(sy_f, lt_f, tot_f);\n    this._update(symbol, i, sy_f);\n    if (symbol === this.numSyms) {\n        /* this is an escape */\n        /* decode the literal */\n        sy_f = 1;\n        tot_f = this.numSyms;\n        if (this.sortedSeen) {\n            // do a slower, but more precise decoding of the literal\n            // by excluding the already-seen symbols.\n            var seen = this.sortedSeen;\n            tot_f = this.numSyms - this.seenSyms;\n            if (seen[seen.length-1] === this.numSyms) { tot_f++; }\n            symbol = lt_f = this.coder.decodeCulFreq(tot_f);\n            for (i=0; i < seen.length && seen[i] <= symbol ; i++) {\n                symbol++;\n            }\n        } else {\n            symbol = lt_f = this.coder.decodeCulFreq(tot_f);\n        }\n        this.coder.decodeUpdate(sy_f, lt_f, tot_f);\n        this._update(symbol, this.seenSyms);\n    }\n    return symbol;\n};\nMTFModel.prototype.encode = function(symbol) {\n    // look for symbol, from most-recent to oldest\n    var i, sy_f, lt_f, tot_f;\n    for (i=this.seenSyms-1; i>=0; i--) {\n        if (symbol === this.sym[i]) {\n            // ok, found it.\n            lt_f = this.prob[i];\n            sy_f = this.prob[i + 1] - lt_f;\n            tot_f = this.prob[this.seenSyms];\n            this.coder.encodeFreq(sy_f, lt_f, tot_f);\n            return this._update(symbol, i, sy_f);\n        }\n    }\n    // couldn't find this symbol.  encode as escape.\n    console.assert(symbol !== this.numSyms); // catch infinite recursion\n    this.encode(this.numSyms); // guaranteed to be found in the table.\n    // code symbol as literal\n    sy_f = 1;\n    lt_f = symbol;\n    tot_f = this.numSyms;\n    if (this.sortedSeen) {\n        // do a slower, but more precise encoding of the literal\n        // by excluding the already-seen symbols.\n        var seen = this.sortedSeen;\n        tot_f -= this.seenSyms;\n        if (seen[seen.length-1] === this.numSyms) { tot_f++; }\n        for (i=0; i < seen.length && seen[i] < symbol; i++) {\n            lt_f--;\n        }\n    }\n    this.coder.encodeFreq(sy_f, lt_f, tot_f);\n    // now add symbol to the end.\n    return this._update(symbol, this.seenSyms);\n};\n\nMTFModel.MAGIC = 'mtfm';\n/** Simple order-0 compressor, as self-test. */\nMTFModel.compressFile = Util.compressFileHelper(MTFModel.MAGIC, function(inStream, outStream, fileSize, props, finalByte) {\n  var range = new RangeCoder(outStream);\n  range.encodeStart(finalByte, 1);\n  var model = new MTFModel(range, (fileSize<0) ? 257 : 256);\n  Util.compressWithModel(inStream, fileSize, model);\n  range.encodeFinish();\n}, true);\n\n/** Simple order-0 decompresser, as self-test. */\nMTFModel.decompressFile = Util.decompressFileHelper(MTFModel.MAGIC, function(inStream, outStream, fileSize) {\n  var range = new RangeCoder(inStream);\n  range.decodeStart(true/*we already read the 'free' byte*/);\n  var model = new MTFModel(range, (fileSize<0) ? 257 : 256);\n  Util.decompressWithModel(outStream, fileSize, model);\n  range.decodeFinish();\n});\n\nreturn MTFModel;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/NoModel.js":"/** Simple \"lack of model\" -- just encode the bits directly.\n *  Useful especially with sparse spaces or Huffman coders where there's\n *  no obvious prediction to be made that will pay for itself.\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./BitStream','./Util'],function(BitStream,Util) {\n\nvar NoModel = function(bitstream, size) {\n  this.bitstream = bitstream;\n  this.bits = Util.fls(size-1);\n};\nNoModel.factory = function(bitstream) {\n  return function(size) { return new NoModel(bitstream, size); };\n};\nNoModel.prototype.encode = function(symbol) {\n  var i;\n  for (i=this.bits-1; i>=0; i--) {\n    var b = (symbol >>> i) & 1;\n    this.bitstream.writeBit(b);\n  }\n};\nNoModel.prototype.decode = function() {\n  var i, r = 0;\n  for (i=this.bits-1; i>=0; i--) {\n    r <<= 1;\n    if (this.bitstream.readBit()) r++;\n  }\n  return r;\n};\n\n/** Brain-dead self-test. */\nNoModel.MAGIC = 'nomo';\nNoModel.compressFile = Util.compressFileHelper(NoModel.MAGIC, function(inStream, outStream, fileSize, props) {\n    var bitstream = new BitStream(outStream);\n    var model = new NoModel(bitstream, (fileSize<0) ? 257 : 256);\n    Util.compressWithModel(inStream, fileSize, model);\n    bitstream.flush();\n});\nNoModel.decompressFile = Util.decompressFileHelper(NoModel.MAGIC, function(inStream, outStream, fileSize) {\n    var bitstream = new BitStream(inStream);\n    var model = new NoModel(bitstream, (fileSize<0) ? 257 : 256);\n    Util.decompressWithModel(outStream, fileSize, model);\n});\n\nreturn NoModel;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/BWTC.js":"/* A simple bzip-like BWT compressor with a range encoder; written as a\n * self-test of the BWT package. */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./freeze','./BWT','./DefSumModel','./FenwickModel','./LogDistanceModel','./NoModel','./RangeCoder','./Stream','./Util'], function(freeze, BWT, DefSumModel, FenwickModel, LogDistanceModel, NoModel, RangeCoder, Stream, Util) {\n    var EOF = Stream.EOF;\n\n    var F_PROB_MAX  = 0xFF00;\n    var F_PROB_INCR = 0x0100;\n\n    BWTC = Object.create(null);\n    BWTC.MAGIC = \"bwtc\";\n    BWTC.compressFile = Util.compressFileHelper(BWTC.MAGIC, function(input, output, size, props, finalByte) {\n        var encoder = new RangeCoder(output);\n        encoder.encodeStart(finalByte, 1);\n\n        var blockSize = 9;\n        if (typeof(props)==='number' && props >= 1 && props <= 9) {\n            blockSize = props;\n        }\n        encoder.encodeByte(blockSize);\n        var fast = (blockSize <= 5);\n        blockSize *= 100000;\n\n        var block = Util.makeU8Buffer(blockSize);\n        var readBlock = function() {\n            var pos;\n            for (pos=0; pos < blockSize; ) {\n                var ch = input.readByte();\n                if (ch < 0) { break; }\n                block[pos++] = ch;\n            }\n            return pos;\n        };\n        var U = Util.makeU8Buffer(blockSize);\n        var A = Util.makeS32Buffer(blockSize);\n        var M = Util.makeU8Buffer(256); // move to front array\n        var bitModelFactory = NoModel.factory(encoder);\n        var lenModel = new LogDistanceModel(blockSize, 0,\n                                            bitModelFactory,\n                                            bitModelFactory);\n        var length, b, c, pidx, i, j;\n        do {\n            length = readBlock();\n            if (length === 0) { break; }\n            // indicate that there's another block comin'\n            // and encode the length of the block if necessary\n            if (length === block.length) {\n                encoder.encodeFreq(1, 0, 3); // \"full size block\"\n                b = block;\n            } else {\n                encoder.encodeFreq(1, 1, 3); // \"short block\"\n                lenModel.encode(length);\n                b = block.subarray(0, length);\n            }\n            pidx = BWT.bwtransform(b, U, A, length, 256);\n            lenModel.encode(pidx); // starting index\n            // encode the alphabet subset used\n            var useTree = Util.makeU16Buffer(512);\n            for (i=0; i<length; i++) {\n                c = U[i];\n                useTree[256+c] = 1;\n            }\n            for (i=255; i>0; i--) { // sum all the way up the tree\n                useTree[i] = useTree[2*i] + useTree[2*i + 1];\n            }\n            useTree[0] = 1; // sentinel\n            for (i=1; i<512; i++) {\n                var parent = i>>>1;\n                var full = 1 << (9-Util.fls(i));\n                if (useTree[parent] === 0 || useTree[parent] === (full*2)) {\n                    /* already known full/empty */\n                } else if (i >= 256) {\n                    encoder.encodeBit(useTree[i]); // leaf node\n                } else {\n                    var v = useTree[i];\n                    v = (v===0) ? 0 : (v===full) ? 2 : 1;\n                    encoder.encodeFreq(1, v, 3);\n                }\n            }\n            // remap symbols to this subset\n            var alphabetSize = 0;\n            for (i=0; i<256; i++) {\n                if (useTree[256+i]) { // symbol in use\n                    M[alphabetSize++] = i;\n                }\n            }\n            useTree = null;\n            // MTF encoding of U\n            for (i=0; i<length; i++) {\n                c = U[i];\n                for (j=0; j<alphabetSize; j++) {\n                    if (M[j] === c) {\n                        break;\n                    }\n                }\n                console.assert(j<alphabetSize);\n                U[i] = j;\n                // move to front\n                for (; j>0; j--) {\n                    M[j] = M[j-1];\n                }\n                M[0] = c;\n            }\n            // RLE/range encoding\n            var model = new FenwickModel(encoder, alphabetSize+1,\n                                         F_PROB_MAX, F_PROB_INCR);\n            if (fast) { model = new DefSumModel(encoder, alphabetSize+1); }\n            var runLength = 0;\n            var emitLastRun = function() {\n                // binary encode runs of zeros\n                while (runLength !== 0) {\n                    if (runLength&1) {\n                        model.encode(0); // RUNA\n                        runLength-=1;\n                    } else {\n                        model.encode(1); // RUNB\n                        runLength-=2;\n                    }\n                    runLength >>>= 1;\n                }\n            };\n            for (i=0; i<length; i++) {\n                c = U[i];\n                if (c === 0) {\n                    runLength++;\n                } else {\n                    emitLastRun();\n                    model.encode(c+1);\n                    // reset for next\n                    runLength = 0;\n                }\n            }\n            emitLastRun();\n            // done with this block!\n        } while (length === block.length);\n\n        encoder.encodeFreq(1, 2, 3); // \"no more blocks\"\n        encoder.encodeFinish();\n    }, true);\n\n    BWTC.decompressFile = Util.decompressFileHelper(BWTC.MAGIC, function(input, output, size) {\n        var decoder = new RangeCoder(input);\n        decoder.decodeStart(true/* already read the extra byte */);\n        var blockSize = decoder.decodeByte();\n        console.assert(blockSize >= 1 && blockSize <= 9);\n        var fast = (blockSize <= 5);\n        blockSize *= 100000;\n\n        var block = Util.makeU8Buffer(blockSize);\n        var U = Util.makeU8Buffer(blockSize);\n        var A = Util.makeS32Buffer(blockSize);\n        var M = Util.makeU8Buffer(256); // move to front array\n        var bitModelFactory = NoModel.factory(decoder);\n        var lenModel = new LogDistanceModel(blockSize, 0,\n                                            bitModelFactory,\n                                            bitModelFactory);\n        var b, length, i, j, c;\n        while (true) {\n            var blockIndicator = decoder.decodeCulFreq(3);\n            decoder.decodeUpdate(1, blockIndicator, 3);\n            if (blockIndicator === 0) { // full-length block\n                length = blockSize;\n                b = block;\n            } else if (blockIndicator === 1) { // short block\n                length = lenModel.decode();\n                b = block.subarray(0, length);\n            } else if (blockIndicator === 2) { // all done, no more blocks\n                break;\n            }\n            // read starting index for unBWT\n            var pidx = lenModel.decode();\n            // decode the alphabet subset used\n            var useTree = Util.makeU16Buffer(512);\n            useTree[0] = 1; // sentinel\n            for (i=1; i<512; i++) {\n                var parent = i>>>1;\n                var full = 1 << (9-Util.fls(i));\n                if (useTree[parent] === 0 || useTree[parent] === (full*2)) {\n                    /* already known full/empty */\n                    useTree[i] = useTree[parent] >>> 1;\n                } else if (i >= 256) {\n                    useTree[i] = decoder.decodeBit(); // leaf node\n                } else {\n                    var v = decoder.decodeCulFreq(3);\n                    decoder.decodeUpdate(1, v, 3);\n                    useTree[i] = (v===2) ? full : v;\n                }\n            }\n            // remap symbols to this subset\n            var alphabetSize = 0;\n            for (i=0; i<256; i++) {\n                if (useTree[256+i]) { // symbol in use\n                    M[alphabetSize++] = i;\n                }\n            }\n            useTree = null;\n            // RLE/range decoding\n            var model = new FenwickModel(decoder, alphabetSize+1,\n                                         F_PROB_MAX, F_PROB_INCR);\n            if (fast) { model = new DefSumModel(decoder, alphabetSize+1, true);}\n            var val = 1; // repeat count\n            for (i=0; i<length; ) {\n                c = model.decode();\n                if (c===0) {\n                    for (j=0; j<val; j++) { b[i++] = 0; }\n                    val *= 2;\n                } else if (c===1) {\n                    for (j=0; j<val; j++) { b[i++] = 0; b[i++] = 0; }\n                    val *= 2;\n                } else {\n                    val = 1;\n                    b[i++] = c-1;\n                }\n            }\n            // MTF decode\n            for (i=0; i<length; i++) {\n                j = b[i];\n                b[i] = c = M[j];\n                // move to front\n                for (; j>0; j--) {\n                    M[j] = M[j-1];\n                }\n                M[0] = c;\n            }\n            // unBWT\n            BWT.unbwtransform(block, U, A, length, pidx);\n            // emit!\n            output.write(U, 0, length);\n        }\n        decoder.decodeFinish();\n    });\n\n    return BWTC;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/LogDistanceModel.js":"/** Simple (log n)(n) distance model. */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./Util'],function(Util){\n\n    // lengthBitsModelFactory will be called with arguments 2, 4, 8, 16, etc\n    // and must return an appropriate model or coder.\n    var LogDistanceModel = function(size, extraStates,\n                                    lgDistanceModelFactory,\n                                    lengthBitsModelFactory) {\n        var i;\n        var bits = Util.fls(size-1);\n        this.extraStates = +extraStates || 0;\n        this.lgDistanceModel = lgDistanceModelFactory(1 + bits + extraStates);\n        // this.distanceModel[n] used for distances which are n-bits long,\n        // but only n-1 bits are encoded: the top bit is known to be one.\n        this.distanceModel = [];\n        for (i=2 ; i <= bits; i++) {\n            var numBits = i - 1;\n            this.distanceModel[i] = lengthBitsModelFactory(1<<numBits);\n        }\n    };\n    /* you can give this model arguments between 0 and (size-1), or else\n       a negative argument which is one of the 'extra states'. */\n    LogDistanceModel.prototype.encode = function(distance) {\n        if (distance < 2) { // small distance or an 'extra state'\n            this.lgDistanceModel.encode(distance + this.extraStates);\n            return;\n        }\n        var lgDistance = Util.fls(distance);\n        console.assert(distance & (1<<(lgDistance-1))); // top bit is set\n        console.assert(lgDistance >= 2);\n        this.lgDistanceModel.encode(lgDistance + this.extraStates);\n        // now encode the rest of the bits.\n        var rest = distance & ((1 << (lgDistance-1)) - 1);\n        this.distanceModel[lgDistance].encode(rest);\n    };\n    LogDistanceModel.prototype.decode = function() {\n        var lgDistance = this.lgDistanceModel.decode() - this.extraStates;\n        if (lgDistance < 2) {\n            return lgDistance; // this is a small distance or an 'extra state'\n        }\n        var rest = this.distanceModel[lgDistance].decode();\n        return (1 << (lgDistance-1)) + rest;\n    };\n    return LogDistanceModel;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/Bzip2.js":"/*\nAn implementation of Bzip2 de/compression, including the ability to\nseek within bzip2 data.\n\nCopyright (C) 2013 C. Scott Ananian\nCopyright (C) 2012 Eli Skeggs\nCopyright (C) 2011 Kevin Kwok\n\nThis library is free software; you can redistribute it and/or\nmodify it under the terms of the GNU Lesser General Public\nLicense as published by the Free Software Foundation; either\nversion 2.1 of the License, or (at your option) any later version.\n\nThis library is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\nLesser General Public License for more details.\n\nYou should have received a copy of the GNU Lesser General Public\nLicense along with this library; if not, see\nhttp://www.gnu.org/licenses/lgpl-2.1.html\n\nAdapted from node-bzip, copyright 2012 Eli Skeggs.\nAdapted from bzip2.js, copyright 2011 Kevin Kwok (antimatter15@gmail.com).\n\nBased on micro-bunzip by Rob Landley (rob@landley.net).\n\nBased on bzip2 decompression code by Julian R Seward (jseward@acm.org),\nwhich also acknowledges contributions by Mike Burrows, David Wheeler,\nPeter Fenwick, Alistair Moffat, Radford Neal, Ian H. Witten,\nRobert Sedgewick, and Jon L. Bentley.\n\nBWT implementation based on work by Yuta Mori; see BWT.js for details.\n\nbzip2 compression code inspired by https://code.google.com/p/jbzip2\n*/\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./freeze','./BitStream','./BWT','./CRC32','./HuffmanAllocator','./Stream','./Util'], function(freeze, BitStream, BWT, CRC32, HuffmanAllocator, Stream, Util) {\n\nvar MAX_HUFCODE_BITS = 20;\nvar MAX_SYMBOLS = 258;\nvar SYMBOL_RUNA = 0;\nvar SYMBOL_RUNB = 1;\nvar MIN_GROUPS = 2;\nvar MAX_GROUPS = 6;\nvar GROUP_SIZE = 50;\n\nvar WHOLEPI = 0x314159265359; // 48-bit integer\nvar SQRTPI =  0x177245385090; // 48-bit integer\n\nvar EOF = Stream.EOF;\n\nvar mtf = function(array, index) {\n  var src = array[index], i;\n  for (i = index; i > 0; i--) {\n    array[i] = array[i-1];\n  }\n  array[0] = src;\n  return src;\n};\n\nvar Err = {\n  OK: 0,\n  LAST_BLOCK: -1,\n  NOT_BZIP_DATA: -2,\n  UNEXPECTED_INPUT_EOF: -3,\n  UNEXPECTED_OUTPUT_EOF: -4,\n  DATA_ERROR: -5,\n  OUT_OF_MEMORY: -6,\n  OBSOLETE_INPUT: -7,\n  END_OF_BLOCK: -8\n};\nvar ErrorMessages = {};\nErrorMessages[Err.LAST_BLOCK] =            \"Bad file checksum\";\nErrorMessages[Err.NOT_BZIP_DATA] =         \"Not bzip data\";\nErrorMessages[Err.UNEXPECTED_INPUT_EOF] =  \"Unexpected input EOF\";\nErrorMessages[Err.UNEXPECTED_OUTPUT_EOF] = \"Unexpected output EOF\";\nErrorMessages[Err.DATA_ERROR] =            \"Data error\";\nErrorMessages[Err.OUT_OF_MEMORY] =         \"Out of memory\";\nErrorMessages[Err.OBSOLETE_INPUT] = \"Obsolete (pre 0.9.5) bzip format not supported.\";\n\nvar _throw = function(status, optDetail) {\n  var msg = ErrorMessages[status] || 'unknown error';\n  if (optDetail) { msg += ': '+optDetail; }\n  var e = new TypeError(msg);\n  e.errorCode = status;\n  throw e;\n};\n\nvar Bunzip = function(inputStream, outputStream) {\n  this.writePos = this.writeCurrent = this.writeCount = 0;\n\n  this._start_bunzip(inputStream, outputStream);\n};\nBunzip.prototype._init_block = function() {\n  var moreBlocks = this._get_next_block();\n  if ( !moreBlocks ) {\n    this.writeCount = -1;\n    return false; /* no more blocks */\n  }\n  this.blockCRC = new CRC32();\n  return true;\n};\n/* XXX micro-bunzip uses (inputStream, inputBuffer, len) as arguments */\nBunzip.prototype._start_bunzip = function(inputStream, outputStream) {\n  /* Ensure that file starts with \"BZh['1'-'9'].\" */\n  var buf = Util.makeU8Buffer(4);\n  if (inputStream.read(buf, 0, 4) !== 4 ||\n      String.fromCharCode(buf[0], buf[1], buf[2]) !== 'BZh')\n    _throw(Err.NOT_BZIP_DATA, 'bad magic');\n\n  var level = buf[3] - 0x30;\n  if (level < 1 || level > 9)\n    _throw(Err.NOT_BZIP_DATA, 'level out of range');\n\n  this.reader = new BitStream(inputStream);\n\n  /* Fourth byte (ascii '1'-'9'), indicates block size in units of 100k of\n     uncompressed data.  Allocate intermediate buffer for block. */\n  this.dbufSize = 100000 * level;\n  this.nextoutput = 0;\n  this.outputStream = outputStream;\n  this.streamCRC = 0;\n};\nBunzip.prototype._get_next_block = function() {\n  var i, j, k;\n  var reader = this.reader;\n  // this is get_next_block() function from micro-bunzip:\n  /* Read in header signature and CRC, then validate signature.\n     (last block signature means CRC is for whole file, return now) */\n  var h = reader.readBits(48);\n  if (h === SQRTPI) { // last block\n    return false; /* no more blocks */\n  }\n  if (h !== WHOLEPI)\n    _throw(Err.NOT_BZIP_DATA);\n  this.targetBlockCRC = reader.readBits(32);\n  this.streamCRC = (this.targetBlockCRC ^\n                    ((this.streamCRC << 1) | (this.streamCRC>>>31))) >>> 0;\n  /* We can add support for blockRandomised if anybody complains.  There was\n     some code for this in busybox 1.0.0-pre3, but nobody ever noticed that\n     it didn't actually work. */\n  if (reader.readBits(1))\n    _throw(Err.OBSOLETE_INPUT);\n  var origPointer = reader.readBits(24);\n  if (origPointer > this.dbufSize)\n    _throw(Err.DATA_ERROR, 'initial position out of bounds');\n  /* mapping table: if some byte values are never used (encoding things\n     like ASCII text), the compression code removes the gaps to have fewer\n     symbols to deal with, and writes a sparse bitfield indicating which\n     values were present.  We make a translation table to convert the symbols\n     back to the corresponding bytes. */\n  var t = reader.readBits(16);\n  var symToByte = Util.makeU8Buffer(256), symTotal = 0;\n  for (i = 0; i < 16; i++) {\n    if (t & (1 << (0xF - i))) {\n      var o = i * 16;\n      k = reader.readBits(16);\n      for (j = 0; j < 16; j++)\n        if (k & (1 << (0xF - j)))\n          symToByte[symTotal++] = o + j;\n    }\n  }\n\n  /* How many different Huffman coding groups does this block use? */\n  var groupCount = reader.readBits(3);\n  if (groupCount < MIN_GROUPS || groupCount > MAX_GROUPS)\n    _throw(Err.DATA_ERROR);\n  /* nSelectors: Every GROUP_SIZE many symbols we select a new Huffman coding\n     group.  Read in the group selector list, which is stored as MTF encoded\n     bit runs.  (MTF=Move To Front, as each value is used it's moved to the\n     start of the list.) */\n  var nSelectors = reader.readBits(15);\n  if (nSelectors === 0)\n    _throw(Err.DATA_ERROR);\n\n  var mtfSymbol = Util.makeU8Buffer(256);\n  for (i = 0; i < groupCount; i++)\n    mtfSymbol[i] = i;\n\n  var selectors = Util.makeU8Buffer(nSelectors); // was 32768...\n\n  for (i = 0; i < nSelectors; i++) {\n    /* Get next value */\n    for (j = 0; reader.readBits(1); j++)\n      if (j >= groupCount) _throw(Err.DATA_ERROR);\n    /* Decode MTF to get the next selector */\n    selectors[i] = mtf(mtfSymbol, j);\n  }\n\n  /* Read the Huffman coding tables for each group, which code for symTotal\n     literal symbols, plus two run symbols (RUNA, RUNB) */\n  var symCount = symTotal + 2;\n  var groups = [], hufGroup;\n  for (j = 0; j < groupCount; j++) {\n    var length = Util.makeU8Buffer(symCount), temp = Util.makeU16Buffer(MAX_HUFCODE_BITS + 1);\n    /* Read Huffman code lengths for each symbol.  They're stored in\n       a way similar to MTF; record a starting value for the first symbol,\n       and an offset from the previous value for every symbol after that. */\n    t = reader.readBits(5); // lengths\n    for (i = 0; i < symCount; i++) {\n      for (;;) {\n        if (t < 1 || t > MAX_HUFCODE_BITS) _throw(Err.DATA_ERROR);\n        /* If first bit is 0, stop.  Else second bit indicates whether\n           to increment or decrement the value. */\n        if(!reader.readBits(1))\n          break;\n        if(!reader.readBits(1))\n          t++;\n        else\n          t--;\n      }\n      length[i] = t;\n    }\n\n    /* Find largest and smallest lengths in this group */\n    var minLen,  maxLen;\n    minLen = maxLen = length[0];\n    for (i = 1; i < symCount; i++) {\n      if (length[i] > maxLen)\n        maxLen = length[i];\n      else if (length[i] < minLen)\n        minLen = length[i];\n    }\n\n    /* Calculate permute[], base[], and limit[] tables from length[].\n     *\n     * permute[] is the lookup table for converting Huffman coded symbols\n     * into decoded symbols.  base[] is the amount to subtract from the\n     * value of a Huffman symbol of a given length when using permute[].\n     *\n     * limit[] indicates the largest numerical value a symbol with a given\n     * number of bits can have.  This is how the Huffman codes can vary in\n     * length: each code with a value>limit[length] needs another bit.\n     */\n    hufGroup = {};\n    groups.push(hufGroup);\n    hufGroup.permute = Util.makeU16Buffer(MAX_SYMBOLS);\n    hufGroup.limit = Util.makeU32Buffer(MAX_HUFCODE_BITS + 2);\n    hufGroup.base = Util.makeU32Buffer(MAX_HUFCODE_BITS + 1);\n    hufGroup.minLen = minLen;\n    hufGroup.maxLen = maxLen;\n    /* Calculate permute[].  Concurrently, initialize temp[] and limit[]. */\n    var pp = 0;\n    for (i = minLen; i <= maxLen; i++) {\n      temp[i] = hufGroup.limit[i] = 0;\n      for (t = 0; t < symCount; t++)\n        if (length[t] === i)\n          hufGroup.permute[pp++] = t;\n    }\n    /* Count symbols coded for at each bit length */\n    for (i = 0; i < symCount; i++)\n      temp[length[i]]++;\n    /* Calculate limit[] (the largest symbol-coding value at each bit\n     * length, which is (previous limit<<1)+symbols at this level), and\n     * base[] (number of symbols to ignore at each bit length, which is\n     * limit minus the cumulative count of symbols coded for already). */\n    pp = t = 0;\n    for (i = minLen; i < maxLen; i++) {\n      pp += temp[i];\n      /* We read the largest possible symbol size and then unget bits\n         after determining how many we need, and those extra bits could\n         be set to anything.  (They're noise from future symbols.)  At\n         each level we're really only interested in the first few bits,\n         so here we set all the trailing to-be-ignored bits to 1 so they\n         don't affect the value>limit[length] comparison. */\n      hufGroup.limit[i] = pp - 1;\n      pp <<= 1;\n      t += temp[i];\n      hufGroup.base[i + 1] = pp - t;\n    }\n    hufGroup.limit[maxLen + 1] = Number.MAX_VALUE; /* Sentinel value for reading next sym. */\n    hufGroup.limit[maxLen] = pp + temp[maxLen] - 1;\n    hufGroup.base[minLen] = 0;\n  }\n  /* We've finished reading and digesting the block header.  Now read this\n     block's Huffman coded symbols from the file and undo the Huffman coding\n     and run length encoding, saving the result into dbuf[dbufCount++]=uc */\n\n  /* Initialize symbol occurrence counters and symbol Move To Front table */\n  var byteCount = Util.makeU32Buffer(256);\n  for (i = 0; i < 256; i++)\n    mtfSymbol[i] = i;\n  /* Loop through compressed symbols. */\n  var runPos = 0, dbufCount = 0, selector = 0, uc;\n  var dbuf = this.dbuf = Util.makeU32Buffer(this.dbufSize);\n  symCount = 0;\n  for (;;) {\n    /* Determine which Huffman coding group to use. */\n    if (!(symCount--)) {\n      symCount = GROUP_SIZE - 1;\n      if (selector >= nSelectors) { _throw(Err.DATA_ERROR); }\n      hufGroup = groups[selectors[selector++]];\n    }\n    /* Read next Huffman-coded symbol. */\n    i = hufGroup.minLen;\n    j = reader.readBits(i);\n    for (;;i++) {\n      if (i > hufGroup.maxLen) { _throw(Err.DATA_ERROR); }\n      if (j <= hufGroup.limit[i])\n        break;\n      j = (j << 1) | reader.readBits(1);\n    }\n    /* Huffman decode value to get nextSym (with bounds checking) */\n    j -= hufGroup.base[i];\n    if (j < 0 || j >= MAX_SYMBOLS) { _throw(Err.DATA_ERROR); }\n    var nextSym = hufGroup.permute[j];\n    /* We have now decoded the symbol, which indicates either a new literal\n       byte, or a repeated run of the most recent literal byte.  First,\n       check if nextSym indicates a repeated run, and if so loop collecting\n       how many times to repeat the last literal. */\n    if (nextSym === SYMBOL_RUNA || nextSym === SYMBOL_RUNB) {\n      /* If this is the start of a new run, zero out counter */\n      if (!runPos){\n        runPos = 1;\n        t = 0;\n      }\n      /* Neat trick that saves 1 symbol: instead of or-ing 0 or 1 at\n         each bit position, add 1 or 2 instead.  For example,\n         1011 is 1<<0 + 1<<1 + 2<<2.  1010 is 2<<0 + 2<<1 + 1<<2.\n         You can make any bit pattern that way using 1 less symbol than\n         the basic or 0/1 method (except all bits 0, which would use no\n         symbols, but a run of length 0 doesn't mean anything in this\n         context).  Thus space is saved. */\n      if (nextSym === SYMBOL_RUNA)\n        t += runPos;\n      else\n        t += 2 * runPos;\n      runPos <<= 1;\n      continue;\n    }\n    /* When we hit the first non-run symbol after a run, we now know\n       how many times to repeat the last literal, so append that many\n       copies to our buffer of decoded symbols (dbuf) now.  (The last\n       literal used is the one at the head of the mtfSymbol array.) */\n    if (runPos){\n      runPos = 0;\n      if (dbufCount + t > this.dbufSize) { _throw(Err.DATA_ERROR); }\n      uc = symToByte[mtfSymbol[0]];\n      byteCount[uc] += t;\n      while (t--)\n        dbuf[dbufCount++] = uc;\n    }\n    /* Is this the terminating symbol? */\n    if (nextSym > symTotal)\n      break;\n    /* At this point, nextSym indicates a new literal character.  Subtract\n       one to get the position in the MTF array at which this literal is\n       currently to be found.  (Note that the result can't be -1 or 0,\n       because 0 and 1 are RUNA and RUNB.  But another instance of the\n       first symbol in the MTF array, position 0, would have been handled\n       as part of a run above.  Therefore 1 unused MTF position minus\n       2 non-literal nextSym values equals -1.) */\n    if (dbufCount >= this.dbufSize) { _throw(Err.DATA_ERROR); }\n    i = nextSym - 1;\n    uc = mtf(mtfSymbol, i);\n    uc = symToByte[uc];\n    /* We have our literal byte.  Save it into dbuf. */\n    byteCount[uc]++;\n    dbuf[dbufCount++] = uc;\n  }\n  /* At this point, we've read all the Huffman-coded symbols (and repeated\n     runs) for this block from the input stream, and decoded them into the\n     intermediate buffer.  There are dbufCount many decoded bytes in dbuf[].\n     Now undo the Burrows-Wheeler transform on dbuf.\n     See http://dogma.net/markn/articles/bwt/bwt.htm\n  */\n  if (origPointer < 0 || origPointer >= dbufCount) { _throw(Err.DATA_ERROR); }\n  /* Turn byteCount into cumulative occurrence counts of 0 to n-1. */\n  j = 0;\n  for (i = 0; i < 256; i++) {\n    k = j + byteCount[i];\n    byteCount[i] = j;\n    j = k;\n  }\n  /* Figure out what order dbuf would be in if we sorted it. */\n  for (i = 0; i < dbufCount; i++) {\n    uc = dbuf[i] & 0xff;\n    dbuf[byteCount[uc]] |= (i << 8);\n    byteCount[uc]++;\n  }\n  /* Decode first byte by hand to initialize \"previous\" byte.  Note that it\n     doesn't get output, and if the first three characters are identical\n     it doesn't qualify as a run (hence writeRunCountdown=5). */\n  var pos = 0, current = 0, run = 0;\n  if (dbufCount) {\n    pos = dbuf[origPointer];\n    current = (pos & 0xff);\n    pos >>= 8;\n    run = -1;\n  }\n  this.writePos = pos;\n  this.writeCurrent = current;\n  this.writeCount = dbufCount;\n  this.writeRun = run;\n\n  return true; /* more blocks to come */\n};\n/* Undo burrows-wheeler transform on intermediate buffer to produce output.\n   If start_bunzip was initialized with out_fd=-1, then up to len bytes of\n   data are written to outbuf.  Return value is number of bytes written or\n   error (all errors are negative numbers).  If out_fd!=-1, outbuf and len\n   are ignored, data is written to out_fd and return is RETVAL_OK or error.\n*/\nBunzip.prototype._read_bunzip = function(outputBuffer, len) {\n    var copies, previous, outbyte;\n    /* james@jamestaylor.org: writeCount goes to -1 when the buffer is fully\n       decoded, which results in this returning RETVAL_LAST_BLOCK, also\n       equal to -1... Confusing, I'm returning 0 here to indicate no\n       bytes written into the buffer */\n  if (this.writeCount < 0) { return 0; }\n\n  var gotcount = 0;\n  var dbuf = this.dbuf, pos = this.writePos, current = this.writeCurrent;\n  var dbufCount = this.writeCount, outputsize = this.outputsize;\n  var run = this.writeRun;\n\n  while (dbufCount) {\n    dbufCount--;\n    previous = current;\n    pos = dbuf[pos];\n    current = pos & 0xff;\n    pos >>= 8;\n    if (run++ === 3){\n      copies = current;\n      outbyte = previous;\n      current = -1;\n    } else {\n      copies = 1;\n      outbyte = current;\n    }\n    this.blockCRC.updateCRCRun(outbyte, copies);\n    while (copies--) {\n      this.outputStream.writeByte(outbyte);\n      this.nextoutput++;\n    }\n    if (current != previous)\n      run = 0;\n  }\n  this.writeCount = dbufCount;\n  // check CRC\n  if (this.blockCRC.getCRC() !== this.targetBlockCRC) {\n    _throw(Err.DATA_ERROR, \"Bad block CRC \"+\n           \"(got \"+this.blockCRC.getCRC().toString(16)+\n           \" expected \"+this.targetBlockCRC.toString(16)+\")\");\n  }\n  return this.nextoutput;\n};\n\n/* Static helper functions */\nBunzip.Err = Err;\n// 'input' can be a stream or a buffer\n// 'output' can be a stream or a buffer or a number (buffer size)\nBunzip.decode = function(input, output, multistream) {\n  // make a stream from a buffer, if necessary\n  var inputStream = Util.coerceInputStream(input);\n  var o = Util.coerceOutputStream(output, output);\n  var outputStream = o.stream;\n\n  var bz = new Bunzip(inputStream, outputStream);\n  while (true) {\n    if ('eof' in inputStream && inputStream.eof()) break;\n    if (bz._init_block()) {\n      bz._read_bunzip();\n    } else {\n      var targetStreamCRC = bz.reader.readBits(32);\n      if (targetStreamCRC !== bz.streamCRC) {\n        _throw(Err.DATA_ERROR, \"Bad stream CRC \"+\n               \"(got \"+bz.streamCRC.toString(16)+\n               \" expected \"+targetStreamCRC.toString(16)+\")\");\n      }\n      if (multistream &&\n          'eof' in inputStream &&\n          !inputStream.eof()) {\n        // note that start_bunzip will also resync the bit reader to next byte\n        bz._start_bunzip(inputStream, outputStream);\n      } else break;\n    }\n  }\n  return o.retval;\n};\nBunzip.decodeBlock = function(input, pos, output) {\n  // make a stream from a buffer, if necessary\n  var inputStream = Util.coerceInputStream(input);\n  var o = Util.coerceOutputStream(output, output);\n  var outputStream = o.stream;\n  var bz = new Bunzip(inputStream, outputStream);\n  bz.reader.seekBit(pos);\n  /* Fill the decode buffer for the block */\n  var moreBlocks = bz._get_next_block();\n  if (moreBlocks) {\n    /* Init the CRC for writing */\n    bz.blockCRC = new CRC32();\n\n    /* Zero this so the current byte from before the seek is not written */\n    bz.writeCopies = 0;\n\n    /* Decompress the block and write to stdout */\n    bz._read_bunzip();\n    // XXX keep writing?\n  }\n  return o.retval;\n};\n/* Reads bzip2 file from stream or buffer `input`, and invoke\n * `callback(position, size)` once for each bzip2 block,\n * where position gives the starting position (in *bits*)\n * and size gives uncompressed size of the block (in *bytes*). */\nBunzip.table = function(input, callback, multistream) {\n  // make a stream from a buffer, if necessary\n  var inputStream = new Stream();\n  inputStream.delegate = Util.coerceInputStream(input);\n  inputStream.pos = 0;\n  inputStream.readByte = function() {\n    this.pos++;\n    return this.delegate.readByte();\n  };\n  inputStream.tell = function() { return this.pos; };\n  if (inputStream.delegate.eof) {\n    inputStream.eof = inputStream.delegate.eof.bind(inputStream.delegate);\n  }\n  var outputStream = new Stream();\n  outputStream.pos = 0;\n  outputStream.writeByte = function() { this.pos++; };\n\n  var bz = new Bunzip(inputStream, outputStream);\n  var blockSize = bz.dbufSize;\n  while (true) {\n    if ('eof' in inputStream && inputStream.eof()) break;\n\n    var position = bz.reader.tellBit();\n\n    if (bz._init_block()) {\n      var start = outputStream.pos;\n      bz._read_bunzip();\n      callback(position, outputStream.pos - start);\n    } else {\n      var crc = bz.reader.readBits(32); // (but we ignore the crc)\n      if (multistream &&\n          'eof' in inputStream &&\n          !inputStream.eof()) {\n        // note that start_bunzip will also resync the bit reader to next byte\n        bz._start_bunzip(inputStream, outputStream);\n        console.assert(bz.dbufSize === blockSize,\n                       \"shouldn't change block size within multistream file\");\n      } else break;\n    }\n  }\n};\n\n// create a Huffman tree from the table of frequencies\nvar StaticHuffman = function(freq, alphabetSize) {\n  // As in BZip2HuffmanStageEncoder.java (from jbzip2):\n  // The Huffman allocator needs its input symbol frequencies to be\n  // sorted, but we need to return code lengths in the same order as\n  // the corresponding frequencies are passed in.\n  // The symbol frequency and index are merged into a single array of\n  // integers - frequency in the high 23 bits, index in the low 9\n  // bits.\n  //     2^23 = 8,388,608 which is higher than the maximum possible\n  //            frequency for one symbol in a block\n  //     2^9 = 512 which is higher than the maximum possible\n  //            alphabet size (== 258)\n  // Sorting this array simultaneously sorts the frequencies and\n  // leaves a lookup that can be used to cheaply invert the sort\n  var i, mergedFreq = [];\n  for (i=0; i<alphabetSize; i++) {\n    mergedFreq[i] = (freq[i] << 9) | i;\n  }\n  mergedFreq.sort(function(a,b) { return a-b; });\n  var sortedFreq = mergedFreq.map(function(v) { return v>>>9; });\n  // allocate code lengths in place. (result in sortedFreq array)\n  HuffmanAllocator.allocateHuffmanCodeLengths(sortedFreq, MAX_HUFCODE_BITS);\n  // reverse the sort to put codes & code lengths in order of input symbols\n  this.codeLengths = Util.makeU8Buffer(alphabetSize);\n  for (i=0; i<alphabetSize; i++) {\n    var sym = mergedFreq[i] & 0x1FF;\n    this.codeLengths[sym] = sortedFreq[i];\n  }\n};\n// compute canonical Huffman codes, given code lengths\nStaticHuffman.prototype.computeCanonical = function() {\n  var alphabetSize = this.codeLengths.length;\n  // merge arrays; sort first by length then by symbol.\n  var i, merged = [];\n  for (i=0; i<alphabetSize; i++) {\n    merged[i] = (this.codeLengths[i] << 9) | i;\n  }\n  merged.sort(function(a,b) { return a-b; });\n  // use sorted lengths to assign codes\n  this.code = Util.makeU32Buffer(alphabetSize);\n  var code = 0, prevLen = 0;\n  for (i=0; i<alphabetSize; i++) {\n    var curLen = merged[i] >>> 9;\n    var sym = merged[i] & 0x1FF;\n    console.assert(prevLen <= curLen);\n    code <<= (curLen - prevLen);\n    this.code[sym] = code++;\n    prevLen = curLen;\n  }\n};\n// compute the cost of encoding the given range of symbols w/ this Huffman code\nStaticHuffman.prototype.cost = function(array, offset, length) {\n  var i, cost = 0;\n  for (i=0; i<length; i++) {\n    cost += this.codeLengths[array[offset+i]];\n  }\n  return cost;\n};\n// emit the bit lengths used by this Huffman code\nStaticHuffman.prototype.emit = function(outStream) {\n  // write the starting length\n  var i, currentLength = this.codeLengths[0];\n  outStream.writeBits(5, currentLength);\n  for (i=0; i<this.codeLengths.length; i++) {\n    var codeLength = this.codeLengths[i];\n    var value, delta;\n    console.assert(codeLength > 0 && codeLength <= MAX_HUFCODE_BITS);\n    if (currentLength < codeLength) {\n      value = 2; delta = codeLength - currentLength;\n    } else {\n      value = 3; delta = currentLength - codeLength;\n    }\n    while (delta-- > 0) {\n      outStream.writeBits(2, value);\n    }\n    outStream.writeBit(0);\n    currentLength = codeLength;\n  }\n};\n// encode the given symbol with this Huffman code\nStaticHuffman.prototype.encode = function(outStream, symbol) {\n  outStream.writeBits(this.codeLengths[symbol], this.code[symbol]);\n};\n\n// read a block for bzip2 compression.\nvar readBlock = function(inStream, block, length, crc) {\n  var pos = 0;\n  var lastChar = -1;\n  var runLength = 0;\n  while (pos < length) {\n    if (runLength===4) {\n      block[pos++] = 0;\n      if (pos >= length) { break; }\n    }\n    var ch = inStream.readByte();\n    if (ch === EOF) {\n      break;\n    }\n    crc.updateCRC(ch);\n    if (ch !== lastChar) {\n      lastChar = ch;\n      runLength = 1;\n    } else {\n      runLength++;\n      if (runLength > 4) {\n        if (runLength < 256) {\n          block[pos-1]++;\n          continue;\n        } else {\n          runLength = 1;\n        }\n      }\n    }\n    block[pos++] = ch;\n  }\n  return pos;\n};\n\n// divide the input into groups at most GROUP_SIZE symbols long.\n// assign each group to the Huffman table which compresses it best.\nvar assignSelectors = function(selectors, groups, input) {\n  var i, j, k;\n  for (i=0, k=0; i<input.length; i+=GROUP_SIZE) {\n    var groupSize = Math.min(GROUP_SIZE, input.length - i);\n    var best = 0, bestCost = groups[0].cost(input, i, groupSize);\n    for (j=1; j<groups.length; j++) {\n      var groupCost = groups[j].cost(input, i, groupSize);\n      if (groupCost < bestCost) {\n        best = j; bestCost = groupCost;\n      }\n    }\n    selectors[k++] = best;\n  }\n};\nvar optimizeHuffmanGroups = function(groups, targetGroups, input,\n                                     selectors, alphabetSize) {\n  // until we've got \"targetGroups\" Huffman codes, pick the Huffman code which\n  // matches the largest # of groups and split it by picking the groups\n  // which require more than the median number of bits to encode.\n  // then recompute frequencies and reassign Huffman codes.\n  var i, j, k, groupCounts = [];\n  while (groups.length < targetGroups) {\n    assignSelectors(selectors, groups, input);\n    // which code gets used the most?\n    for (i=0; i<groups.length; i++) { groupCounts[i] = 0; }\n    for (i=0; i<selectors.length; i++) {\n      groupCounts[selectors[i]]++;\n    }\n    var which = groupCounts.indexOf(Math.max.apply(Math, groupCounts));\n    // ok, let's look at the size of those blocks\n    var splits = [];\n    for (i=0, j=0; i<selectors.length; i++) {\n      if (selectors[i] !== which) { continue; }\n      var start = i*GROUP_SIZE;\n      var end = Math.min(start + GROUP_SIZE, input.length);\n      splits.push({index: i, cost:groups[which].cost(input, start, end-start)});\n    }\n    // find the median.  there are O(n) algorithms to do this, but we'll\n    // be lazy and use a full O(n ln n) sort.\n    splits.sort(function(s1, s2) { return s1.cost - s2.cost; });\n    // assign the groups in the top half to the \"new\" selector\n    for (i=(splits.length>>>1); i<splits.length; i++) {\n      selectors[splits[i].index] = groups.length;\n    }\n    groups.push(null);\n    // recompute frequencies\n    var freq = [], f;\n    for (i=0; i<groups.length; i++) {\n      f = freq[i] = [];\n      for (j=0; j<alphabetSize; j++) { f[j] = 0; }\n    }\n    for (i=0, j=0; i<input.length; ) {\n      f = freq[selectors[j++]];\n      for (k=0; k<GROUP_SIZE && i<input.length; k++) {\n        f[input[i++]]++;\n      }\n    }\n    // reconstruct Huffman codes\n    for (i=0; i<groups.length; i++) {\n      groups[i] = new StaticHuffman(freq[i], alphabetSize);\n    }\n  }\n};\n\nvar compressBlock = function(block, length, outStream) {\n  var c, i, j, k;\n  // do BWT transform\n  var U = Util.makeU8Buffer(length);\n  var pidx = BWT.bwtransform2(block, U, length, 256);\n  outStream.writeBit(0); // not randomized\n  outStream.writeBits(24, pidx);\n  // track values used; write bitmap\n  var used = [], compact = [];\n  for (i=0; i<length; i++) {\n    c = block[i];\n    used[c] = true;\n    compact[c>>>4] = true;\n  }\n  for (i=0; i<16; i++) {\n    outStream.writeBit(!!compact[i]);\n  }\n  for (i=0; i<16; i++) {\n    if (compact[i]) {\n      for (j=0; j<16; j++) {\n        outStream.writeBit(!!used[(i<<4)|j]);\n      }\n    }\n  }\n  var alphabetSize = 0;\n  for (i=0; i<256; i++) {\n    if (used[i]) {\n      alphabetSize++;\n    }\n  }\n  // now MTF and RLE/2 encoding, while tracking symbol statistics.\n  // output can be one longer than length, because we include the\n  // end-of-block character at the end. Similarly, we need a U16\n  // array because the end-of-block character can be 256.\n  var A = Util.makeU16Buffer(length+1);\n  var endOfBlock = alphabetSize + 1;\n  var freq = [];\n  for (i=0; i<=endOfBlock; i++) { freq[i] = 0; }\n  var M = Util.makeU8Buffer(alphabetSize);\n  for (i=0, j=0; i<256; i++) {\n    if (used[i]) { M[j++] = i; }\n  }\n  used = null; compact = null;\n  var pos = 0, runLength = 0;\n  var emit = function(c) {\n    A[pos++] = c;\n    freq[c]++;\n  };\n  var emitLastRun = function() {\n    while (runLength !== 0) {\n      if (runLength & 1) {\n        emit(0); // RUNA\n        runLength -= 1;\n      } else {\n        emit(1); // RUNB\n        runLength -= 2;\n      }\n      runLength >>>= 1;\n    }\n  };\n  for (i=0; i<U.length; i++) {\n    c = U[i];\n    // look for C in M\n    for (j=0; j<alphabetSize; j++) {\n      if (M[j]===c) { break; }\n    }\n    console.assert(j!==alphabetSize);\n    // shift MTF array\n    mtf(M, j);\n    // emit j\n    if (j===0) {\n      runLength++;\n    } else {\n      emitLastRun();\n      emit(j+1);\n      runLength = 0;\n    }\n  }\n  emitLastRun();\n  emit(endOfBlock); // end of block symbol\n  A = A.subarray(0, pos);\n  // now A[0...pos) has the encoded output, and freq[0-alphabetSize] has the\n  // frequencies.  Use these to construct Huffman tables.\n  // the canonical bzip2 encoder does some complicated optimization\n  // to attempt to select the best tables.  We're going to simplify things:\n  // (unless the block is very short) we're always going to create MAX_GROUPS\n  // tables; 1 based on global frequencies, and the rest based on dividing the\n  // block into MAX_GROUPS-1 pieces.\n  var groups = [];\n  var targetGroups; // how many Huffman groups should we create?\n  // look at length of MTF-encoded block to pick a good number of groups\n  if (pos >= 2400) { targetGroups = 6; }\n  else if (pos >= 1200) { targetGroups = 5; }\n  else if (pos >= 600) { targetGroups = 4; }\n  else if (pos >= 200) { targetGroups = 3; }\n  else { targetGroups = 2; }\n  // start with two Huffman groups: one with the global frequencies, and\n  // a second with a flat frequency distribution (which is also the smallest\n  // possible Huffman table to encode, which is handy to prevent excessive\n  // bloat if the input file size is very small)\n  groups.push(new StaticHuffman(freq, endOfBlock+1));\n  for (i=0; i<=endOfBlock; i++) { freq[i] = 1; }\n  groups.push(new StaticHuffman(freq, endOfBlock+1));\n  freq = null;\n  // Now optimize the Huffman groups!  this is a black art.\n  // we probably don't want to waste too much time on it, though.\n  var selectors = Util.makeU8Buffer(Math.ceil(pos / GROUP_SIZE));\n  optimizeHuffmanGroups(groups, targetGroups, A, selectors, endOfBlock+1);\n  assignSelectors(selectors, groups, A);\n\n  // okay, let's start writing out our Huffman tables\n  console.assert(groups.length >= MIN_GROUPS && groups.length <= MAX_GROUPS);\n  outStream.writeBits(3, groups.length);\n  // and write out the best selector for each group\n  outStream.writeBits(15, selectors.length);\n  for (i=0; i<groups.length; i++) { M[i] = i; } // initialize MTF table.\n  for (i=0; i<selectors.length; i++) {\n    var s = selectors[i];\n    // find selector in MTF list\n    for (j=0; j<groups.length; j++) { if (M[j]===s) { break; } }\n    console.assert(j<groups.length);\n    mtf(M, j);\n    // emit 'j' as a unary number\n    for (;j>0; j--) {\n      outStream.writeBit(1);\n    }\n    outStream.writeBit(0);\n  }\n  // okay, now emit the Huffman tables in order.\n  for (i=0; i<groups.length; i++) {\n    groups[i].emit(outStream);\n    groups[i].computeCanonical(); // get ready for next step while we're at it\n  }\n  // okay, now (finally!) emit the actual data!\n  for (i=0, k=0; i<pos; ) {\n    var huff = groups[selectors[k++]];\n    for (j=0; j<GROUP_SIZE && i<pos; j++) {\n      huff.encode(outStream, A[i++]);\n    }\n  }\n  // done.\n};\n\nvar Bzip2 = Object.create(null);\nBzip2.compressFile = function(inStream, outStream, props) {\n  inStream = Util.coerceInputStream(inStream);\n  var o = Util.coerceOutputStream(outStream, outStream);\n  outStream = new BitStream(o.stream);\n\n  var blockSizeMultiplier = 9;\n  if (typeof(props)==='number') {\n    blockSizeMultiplier = props;\n  }\n  if (blockSizeMultiplier < 1 || blockSizeMultiplier > 9) {\n    throw new Error('Invalid block size multiplier');\n  }\n\n  var blockSize = blockSizeMultiplier * 100000;\n  // the C implementation always writes at least length-19 characters,\n  // but it reads ahead enough that if the last character written was part\n  // of a run, it writes out the full run.\n  // That's really annoying to implement.\n  // So instead just subtract 19 from the blockSize; in most cases (unless\n  // there's a run at the end of the block) this will yield block divisions\n  // matching the C implementation.\n  blockSize -= 19;\n\n  // write file magic\n  outStream.writeByte('B'.charCodeAt(0));\n  outStream.writeByte('Z'.charCodeAt(0));\n  outStream.writeByte('h'.charCodeAt(0)); // Huffman-coded bzip\n  outStream.writeByte('0'.charCodeAt(0) + blockSizeMultiplier);\n\n  // allocate a buffer for the block\n  var block = Util.makeU8Buffer(blockSize);\n  var streamCRC = 0;\n  var length;\n\n  do {\n    var crc = new CRC32();\n    length = readBlock(inStream, block, blockSize, crc);\n    if (length > 0) {\n      streamCRC = (((streamCRC << 1) | (streamCRC>>>31)) ^ crc.getCRC()) >>> 0;\n      outStream.writeBits(48, WHOLEPI);\n      outStream.writeBits(32, crc.getCRC());\n      compressBlock(block, length, outStream);\n    }\n  } while (length === blockSize);\n\n  // finish up\n  outStream.writeBits(48, SQRTPI);\n  outStream.writeBits(32, streamCRC);\n  outStream.flush(); // get the last bits flushed out\n  return o.retval;\n};\n\nBzip2.decompressFile = Bunzip.decode;\nBzip2.decompressBlock = Bunzip.decodeBlock;\nBzip2.table = Bunzip.table;\n\nreturn Bzip2;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/CRC32.js":"/* CRC32, used in Bzip2 implementation.\n * This is a port of CRC32.java from the jbzip2 implementation at\n *   https://code.google.com/p/jbzip2\n * which is:\n *   Copyright (c) 2011 Matthew Francis\n *\n *   Permission is hereby granted, free of charge, to any person\n *   obtaining a copy of this software and associated documentation\n *   files (the \"Software\"), to deal in the Software without\n *   restriction, including without limitation the rights to use,\n *   copy, modify, merge, publish, distribute, sublicense, and/or sell\n *   copies of the Software, and to permit persons to whom the\n *   Software is furnished to do so, subject to the following\n *   conditions:\n *\n *   The above copyright notice and this permission notice shall be\n *   included in all copies or substantial portions of the Software.\n *\n *   THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n *   EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n *   OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n *   NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n *   HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n *   WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n *   FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n *   OTHER DEALINGS IN THE SOFTWARE.\n * This JavaScript implementation is:\n *   Copyright (c) 2013 C. Scott Ananian\n * with the same licensing terms as Matthew Francis' original implementation.\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./Util'], function(Util) {\n\n  /**\n   * A static CRC lookup table\n   */\n    var crc32Lookup = Util.arraycopy(Util.makeU32Buffer(256), [\n    0x00000000, 0x04c11db7, 0x09823b6e, 0x0d4326d9, 0x130476dc, 0x17c56b6b, 0x1a864db2, 0x1e475005,\n    0x2608edb8, 0x22c9f00f, 0x2f8ad6d6, 0x2b4bcb61, 0x350c9b64, 0x31cd86d3, 0x3c8ea00a, 0x384fbdbd,\n    0x4c11db70, 0x48d0c6c7, 0x4593e01e, 0x4152fda9, 0x5f15adac, 0x5bd4b01b, 0x569796c2, 0x52568b75,\n    0x6a1936c8, 0x6ed82b7f, 0x639b0da6, 0x675a1011, 0x791d4014, 0x7ddc5da3, 0x709f7b7a, 0x745e66cd,\n    0x9823b6e0, 0x9ce2ab57, 0x91a18d8e, 0x95609039, 0x8b27c03c, 0x8fe6dd8b, 0x82a5fb52, 0x8664e6e5,\n    0xbe2b5b58, 0xbaea46ef, 0xb7a96036, 0xb3687d81, 0xad2f2d84, 0xa9ee3033, 0xa4ad16ea, 0xa06c0b5d,\n    0xd4326d90, 0xd0f37027, 0xddb056fe, 0xd9714b49, 0xc7361b4c, 0xc3f706fb, 0xceb42022, 0xca753d95,\n    0xf23a8028, 0xf6fb9d9f, 0xfbb8bb46, 0xff79a6f1, 0xe13ef6f4, 0xe5ffeb43, 0xe8bccd9a, 0xec7dd02d,\n    0x34867077, 0x30476dc0, 0x3d044b19, 0x39c556ae, 0x278206ab, 0x23431b1c, 0x2e003dc5, 0x2ac12072,\n    0x128e9dcf, 0x164f8078, 0x1b0ca6a1, 0x1fcdbb16, 0x018aeb13, 0x054bf6a4, 0x0808d07d, 0x0cc9cdca,\n    0x7897ab07, 0x7c56b6b0, 0x71159069, 0x75d48dde, 0x6b93dddb, 0x6f52c06c, 0x6211e6b5, 0x66d0fb02,\n    0x5e9f46bf, 0x5a5e5b08, 0x571d7dd1, 0x53dc6066, 0x4d9b3063, 0x495a2dd4, 0x44190b0d, 0x40d816ba,\n    0xaca5c697, 0xa864db20, 0xa527fdf9, 0xa1e6e04e, 0xbfa1b04b, 0xbb60adfc, 0xb6238b25, 0xb2e29692,\n    0x8aad2b2f, 0x8e6c3698, 0x832f1041, 0x87ee0df6, 0x99a95df3, 0x9d684044, 0x902b669d, 0x94ea7b2a,\n    0xe0b41de7, 0xe4750050, 0xe9362689, 0xedf73b3e, 0xf3b06b3b, 0xf771768c, 0xfa325055, 0xfef34de2,\n    0xc6bcf05f, 0xc27dede8, 0xcf3ecb31, 0xcbffd686, 0xd5b88683, 0xd1799b34, 0xdc3abded, 0xd8fba05a,\n    0x690ce0ee, 0x6dcdfd59, 0x608edb80, 0x644fc637, 0x7a089632, 0x7ec98b85, 0x738aad5c, 0x774bb0eb,\n    0x4f040d56, 0x4bc510e1, 0x46863638, 0x42472b8f, 0x5c007b8a, 0x58c1663d, 0x558240e4, 0x51435d53,\n    0x251d3b9e, 0x21dc2629, 0x2c9f00f0, 0x285e1d47, 0x36194d42, 0x32d850f5, 0x3f9b762c, 0x3b5a6b9b,\n    0x0315d626, 0x07d4cb91, 0x0a97ed48, 0x0e56f0ff, 0x1011a0fa, 0x14d0bd4d, 0x19939b94, 0x1d528623,\n    0xf12f560e, 0xf5ee4bb9, 0xf8ad6d60, 0xfc6c70d7, 0xe22b20d2, 0xe6ea3d65, 0xeba91bbc, 0xef68060b,\n    0xd727bbb6, 0xd3e6a601, 0xdea580d8, 0xda649d6f, 0xc423cd6a, 0xc0e2d0dd, 0xcda1f604, 0xc960ebb3,\n    0xbd3e8d7e, 0xb9ff90c9, 0xb4bcb610, 0xb07daba7, 0xae3afba2, 0xaafbe615, 0xa7b8c0cc, 0xa379dd7b,\n    0x9b3660c6, 0x9ff77d71, 0x92b45ba8, 0x9675461f, 0x8832161a, 0x8cf30bad, 0x81b02d74, 0x857130c3,\n    0x5d8a9099, 0x594b8d2e, 0x5408abf7, 0x50c9b640, 0x4e8ee645, 0x4a4ffbf2, 0x470cdd2b, 0x43cdc09c,\n    0x7b827d21, 0x7f436096, 0x7200464f, 0x76c15bf8, 0x68860bfd, 0x6c47164a, 0x61043093, 0x65c52d24,\n    0x119b4be9, 0x155a565e, 0x18197087, 0x1cd86d30, 0x029f3d35, 0x065e2082, 0x0b1d065b, 0x0fdc1bec,\n    0x3793a651, 0x3352bbe6, 0x3e119d3f, 0x3ad08088, 0x2497d08d, 0x2056cd3a, 0x2d15ebe3, 0x29d4f654,\n    0xc5a92679, 0xc1683bce, 0xcc2b1d17, 0xc8ea00a0, 0xd6ad50a5, 0xd26c4d12, 0xdf2f6bcb, 0xdbee767c,\n    0xe3a1cbc1, 0xe760d676, 0xea23f0af, 0xeee2ed18, 0xf0a5bd1d, 0xf464a0aa, 0xf9278673, 0xfde69bc4,\n    0x89b8fd09, 0x8d79e0be, 0x803ac667, 0x84fbdbd0, 0x9abc8bd5, 0x9e7d9662, 0x933eb0bb, 0x97ffad0c,\n    0xafb010b1, 0xab710d06, 0xa6322bdf, 0xa2f33668, 0xbcb4666d, 0xb8757bda, 0xb5365d03, 0xb1f740b4\n  ]);\n\n  var CRC32 = function() {\n    /**\n     * The current CRC\n     */\n    var crc = 0xffffffff;\n\n    /**\n     * @return The current CRC\n     */\n    this.getCRC = function() {\n      return (~crc) >>> 0; // return an unsigned value\n    };\n\n    /**\n     * Update the CRC with a single byte\n     * @param value The value to update the CRC with\n     */\n    this.updateCRC = function(value) {\n      crc = (crc << 8) ^ crc32Lookup[((crc >>> 24) ^ value) & 0xff];\n    };\n\n    /**\n     * Update the CRC with a sequence of identical bytes\n     * @param value The value to update the CRC with\n     * @param count The number of bytes\n     */\n    this.updateCRCRun = function(value, count) {\n      while (count-- > 0) {\n        crc = (crc << 8) ^ crc32Lookup[((crc >>> 24) ^ value) & 0xff];\n      }\n    };\n  };\n  return CRC32;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/HuffmanAllocator.js":"/**\n * An in-place, length restricted Canonical Huffman code length allocator\n *\n * Based on the algorithm proposed by R. L. Milidi, A. A. Pessoa and\n * E. S. Laber in \"In-place Length-Restricted Prefix Coding\" (see:\n * http://www-di.inf.puc-rio.br/~laber/public/spire98.ps) and\n * incorporating additional ideas from the implementation of \"shcodec\"\n * by Simakov Alexander (see: http://webcenter.ru/~xander/)\n *\n * This JavaScript implementation ported from HuffmanAllocator.java from\n *   https://code.google.com/p/jbzip2\n * which is:\n *\n *   Copyright (c) 2011 Matthew Francis\n *\n *   Permission is hereby granted, free of charge, to any person\n *   obtaining a copy of this software and associated documentation\n *   files (the \"Software\"), to deal in the Software without\n *   restriction, including without limitation the rights to use,\n *   copy, modify, merge, publish, distribute, sublicense, and/or sell\n *   copies of the Software, and to permit persons to whom the\n *   Software is furnished to do so, subject to the following\n *   conditions:\n *\n *   The above copyright notice and this permission notice shall be\n *   included in all copies or substantial portions of the Software.\n *\n *   THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n *   EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n *   OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n *   NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n *   HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n *   WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n *   FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n *   OTHER DEALINGS IN THE SOFTWARE.\n *\n * This JavaScript implementation is:\n *   Copyright (c) 2013 C. Scott Ananian\n * with the same licensing terms as Matthew Francis' original implementation.\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./freeze','./Util'], function(freeze, Util) {\n\n  /**\n   * FIRST() function\n   * @param array The code length array\n   * @param i The input position\n   * @param nodesToMove The number of internal nodes to be relocated\n   * @return The smallest {@code k} such that {@code nodesToMove <= k <= i} and\n   *         {@code i <= (array[k] % array.length)}\n   */\n  var first = function(array, i, nodesToMove) {\n    var length = array.length;\n    var limit = i;\n    var k = array.length - 2;\n\n    while ((i >= nodesToMove) && ((array[i] % length) > limit)) {\n      k = i;\n      i -= (limit - i + 1);\n    }\n    i = Math.max (nodesToMove - 1, i);\n\n    while (k > (i + 1)) {\n      var temp = (i + k) >> 1;\n      if ((array[temp] % length) > limit) {\n        k = temp;\n      } else {\n        i = temp;\n      }\n    }\n\n    return k;\n  };\n\n  /**\n   * Fills the code array with extended parent pointers\n   * @param array The code length array\n   */\n  var setExtendedParentPointers = function(array) {\n    var length = array.length;\n\n    array[0] += array[1];\n\n    var headNode, tailNode, topNode, temp;\n    for (headNode = 0, tailNode = 1, topNode = 2;\n         tailNode < (length - 1);\n         tailNode++) {\n      if ((topNode >= length) || (array[headNode] < array[topNode])) {\n        temp = array[headNode];\n        array[headNode++] = tailNode;\n      } else {\n        temp = array[topNode++];\n      }\n\n      if ((topNode >= length) ||\n          ((headNode < tailNode) && (array[headNode] < array[topNode]))) {\n        temp += array[headNode];\n        array[headNode++] = tailNode + length;\n      } else {\n        temp += array[topNode++];\n      }\n\n      array[tailNode] = temp;\n    }\n  };\n\n  /**\n   * Finds the number of nodes to relocate in order to achieve a given code\n   * length limit\n   * @param array The code length array\n   * @param maximumLength The maximum bit length for the generated codes\n   * @return The number of nodes to relocate\n   */\n  var findNodesToRelocate = function(array, maximumLength) {\n    var currentNode = array.length - 2;\n    var currentDepth;\n    for (currentDepth = 1;\n         (currentDepth < (maximumLength - 1)) && (currentNode > 1);\n         currentDepth++) {\n      currentNode =  first (array, currentNode - 1, 0);\n    }\n\n    return currentNode;\n  };\n\n\n  /**\n   * A final allocation pass with no code length limit\n   * @param array The code length array\n   */\n  var allocateNodeLengths = function(array) {\n    var firstNode = array.length - 2;\n    var nextNode = array.length - 1;\n    var currentDepth, availableNodes, lastNode, i;\n\n    for (currentDepth = 1, availableNodes = 2;\n         availableNodes > 0;\n         currentDepth++) {\n      lastNode = firstNode;\n      firstNode = first (array, lastNode - 1, 0);\n\n      for (i = availableNodes - (lastNode - firstNode); i > 0; i--) {\n        array[nextNode--] = currentDepth;\n      }\n\n      availableNodes = (lastNode - firstNode) << 1;\n    }\n  };\n\n  /**\n   * A final allocation pass that relocates nodes in order to achieve a\n   * maximum code length limit\n   * @param array The code length array\n   * @param nodesToMove The number of internal nodes to be relocated\n   * @param insertDepth The depth at which to insert relocated nodes\n   */\n  var allocateNodeLengthsWithRelocation = function(array, nodesToMove,\n                                                   insertDepth) {\n    var firstNode = array.length - 2;\n    var nextNode = array.length - 1;\n    var currentDepth = (insertDepth == 1) ? 2 : 1;\n    var nodesLeftToMove = (insertDepth == 1) ? nodesToMove - 2 : nodesToMove;\n    var availableNodes, lastNode, offset, i;\n\n    for (availableNodes = currentDepth << 1;\n         availableNodes > 0;\n         currentDepth++) {\n      lastNode = firstNode;\n      firstNode = (firstNode <= nodesToMove) ? firstNode : first (array, lastNode - 1, nodesToMove);\n\n      offset = 0;\n      if (currentDepth >= insertDepth) {\n        offset = Math.min (nodesLeftToMove, 1 << (currentDepth - insertDepth));\n      } else if (currentDepth == (insertDepth - 1)) {\n        offset = 1;\n        if ((array[firstNode]) == lastNode) {\n          firstNode++;\n        }\n      }\n\n      for (i = availableNodes - (lastNode - firstNode + offset); i > 0; i--) {\n        array[nextNode--] = currentDepth;\n      }\n\n      nodesLeftToMove -= offset;\n      availableNodes = (lastNode - firstNode + offset) << 1;\n    }\n  };\n\n  /**\n   * Allocates Canonical Huffman code lengths in place based on a sorted\n   * frequency array\n   * @param array On input, a sorted array of symbol frequencies; On output,\n   *              an array of Canonical Huffman code lengths\n   * @param maximumLength The maximum code length. Must be at least\n   *                      {@code ceil(log2(array.length))}\n   */\n  // public\n  var allocateHuffmanCodeLengths = function(array, maximumLength) {\n    switch (array.length) {\n    case 2:\n      array[1] = 1;\n    case 1:\n      array[0] = 1;\n      return;\n    }\n\n    /* Pass 1 : Set extended parent pointers */\n    setExtendedParentPointers (array);\n\n    /* Pass 2 : Find number of nodes to relocate in order to achieve\n     *          maximum code length */\n    var nodesToRelocate = findNodesToRelocate (array, maximumLength);\n\n    /* Pass 3 : Generate code lengths */\n    if ((array[0] % array.length) >= nodesToRelocate) {\n      allocateNodeLengths (array);\n    } else {\n      var insertDepth = maximumLength - (Util.fls(nodesToRelocate - 1));\n      allocateNodeLengthsWithRelocation (array, nodesToRelocate, insertDepth);\n    }\n  };\n\n  return freeze({\n    allocateHuffmanCodeLengths: allocateHuffmanCodeLengths\n  });\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/Dmc.js":"/**\n * Implementation of Dynamic Markov Compression, using byte-oriented\n * nodes/transitions.\n *\n * Currently no model-shrinking is done, so be careful trying to use\n * this on large inputs!\n *\n * Notes for the future / TO DO:\n *\n * Add node merging to Dmc:\n *  - once (total states traversed / total node count) exceeds a certain value\n *    - find the median node w/rt total visits\n *    - combine all nodes w/ less visits into a single node, with transitions\n *      to node[0] - node[255] (initial context-1 states)\n *      - initially transition counts are zero?  or summed from components?\n *        needs to be summed so kirchoff principle holds\n *    - halve the edge counts of all nodes, to provide for adaptation\n *      - enforce property that all nodes point \"higher\" except for\n *        links to nodes 0-255.  So we can resum all nodes in one pass,\n *        after resetting all node.sum to zero. X YES because we know\n *        what the total sum must be, so we can arrange to scale to maintain\n *        proper sum. XXX what about node 0-255? XXX maybe just clear all\n *        edge counts XXX\n *\n * Fix buglet: ensure that kirchoff principle *exactly* holds by\n * paying attention to rounding when we distribute edge counts.  track\n * highest edge and give (desiredSum - newSum) extra counts to that\n * outgoing edge? add one to each nonzero edge until all gone?\n *\n * Split 'to' nodes when to.sum grows too high -- only if we're\n * highest incoming edge?  Fix bug again here with saturating counts;\n * we can't ignore counts w/o violating kirchoff principle, so we need\n * to clone it.  Maybe start trying to clone early (before our counter\n * saturates) so we have a better chance of cloning on the high\n * incoming edge? XXX we don't track incoming edges.  XXX so just\n * clone when we visit.\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./MTFModel', './RangeCoder', './Stream', './Util'],function(MTFModel, RangeCoder, Stream, Util){\n\n// nm = no model cloning, MAX_TRANS_CNT=0xFF, MAX_MODEL_PROB=0xFFFF\n// nm2 = \"                            0xFFFF                 0xFFFF\n// nm3 = \"                             0xFFF                 0x0FFF\n// nm4 = \"                            0xFFFF                   0xFF\n// cl1 = model cloning, MAX_TRANS_CNT=0xFFFF  MAX_MODEL_PROB=0xFF\n// cl2 = model cloning, MAX_TRANS_CNT=  0xFF  MAX_MODEL_PROB=0xFF\n// cl3 = model cloning, MAX_TRANS_CNT=0xFFFF  MAX_MODEL_PROB=0xFFFF\nvar MAX_TRANS_CNT = 0xFFFF;\nvar DEFAULT_MIN_CNT1 = 8;\nvar DEFAULT_MIN_CNT2 = 128;\nvar MODEL_PROB_MAX = 0xFF00;\nvar MODEL_PROB_INCR= 0x0100;\nvar CLONE_MODELS=false;\nvar PRINT_STATS=false; // for quick benchmarking\n\n// XXX need to limit growth of model (throw away and retrain if model\n//     gets too large)\n\nvar Dmc = Object.create(null);\nDmc.MAGIC = 'dmc!';\n\nvar MarkovNode = function(coder, size, optModel) {\n  this.out = [];\n  this.model = optModel ? optModel.clone() :\n    new MTFModel(coder, size, MODEL_PROB_MAX, MODEL_PROB_INCR);\n  this.count = Util.makeU16Buffer(size);\n  this.sum = 0;\n};\nMarkovNode.prototype.clone = function(coder, size) {\n  var i;\n  var newNode = new MarkovNode(coder, size, CLONE_MODELS ? this.model : null);\n  for (i=0; i<size; i++) {\n    newNode.out[i] = this.out[i];\n  }\n  return newNode;\n};\n\nvar MarkovModel = function(coder, size, MIN_CNT1, MIN_CNT2) {\n  var i, j;\n  // initial model is 'size' states, completely linked.\n  this.coder = coder;\n  this.size = size;\n  this.MIN_CNT1 = MIN_CNT1 || DEFAULT_MIN_CNT1;\n  this.MIN_CNT2 = MIN_CNT2 || DEFAULT_MIN_CNT2;\n  this.nodes = [];\n  for (i=0; i<size; i++) {\n    this.nodes[i] = new MarkovNode(coder, size);\n  }\n  // now link nodes\n  for (i=0; i<size; i++) {\n    for (j=0; j<size; j++) {\n      this.nodes[i].out[j] = this.nodes[j];\n    }\n  }\n  // select an arbitrary node as the start state.\n  this.current = this.nodes[0];\n};\nMarkovModel.prototype.maybeSplit = function(from, symbol, to) {\n  var trans_cnt = from.count[symbol];\n  var next_cnt = to.sum;\n  var i;\n  if ( (trans_cnt <= this.MIN_CNT1) ||\n       (next_cnt - trans_cnt <= this.MIN_CNT2) ) {\n    return to; // no split\n  }\n\n  // split this guy!\n  var newNode = to.clone(this.coder, this.size);\n  this.nodes.push(newNode);\n  from.out[symbol] = newNode;\n  // distribute transition counts among new and cloned node\n  newNode.sum = to.sum = 0;\n  for (i=0; i<this.size; i++) {\n    newNode.count[i] = to.count[i] * trans_cnt / next_cnt;\n    newNode.sum += newNode.count[i];\n    to.count[i] -= newNode.count[i];\n    to.sum += to.count[i];\n  }\n\n  return newNode;\n};\nMarkovModel.prototype.encode = function(symbol) {\n  var from = this.current;\n  from.model.encode(symbol);\n  var to = from.out[symbol];\n  if (from.count[symbol] !== MAX_TRANS_CNT) {\n      from.count[symbol]++;\n      from.sum++;\n  }\n  this.current = this.maybeSplit(from, symbol, to);\n};\nMarkovModel.prototype.decode = function() {\n  var from = this.current;\n  var symbol = from.model.decode();\n  var to = from.out[symbol];\n  if (from.count[symbol] !== MAX_TRANS_CNT) {\n      from.count[symbol]++;\n      from.sum++;\n  }\n  this.current = this.maybeSplit(from, symbol, to);\n  return symbol;\n};\n\nDmc.compressFile = Util.compressFileHelper(Dmc.MAGIC, function(inStream, outStream, fileSize, props) {\n\n  props = props || {};\n  var MIN_CNT1 = (+props.m) || DEFAULT_MIN_CNT1;\n  var MIN_CNT2 = (+props.n) || DEFAULT_MIN_CNT2;\n  Util.writeUnsignedNumber(outStream, MIN_CNT1);\n  Util.writeUnsignedNumber(outStream, MIN_CNT2);\n\n  var range = new RangeCoder(outStream);\n  range.encodeStart(0xCA, 0);\n\n  var mm = new MarkovModel(range, (fileSize<0) ? 257 : 256,\n                           MIN_CNT1, MIN_CNT2);\n  var inSize = 0;\n  while (inSize !== fileSize) {\n    var ch = inStream.readByte();\n    if (ch===Stream.EOF) {\n      mm.encode(256); // end of stream\n      break;\n    }\n    mm.encode(ch);\n    inSize++;\n  }\n  var outSize = range.encodeFinish();\n  if (PRINT_STATS) {\n    console.log('M1', mm.MIN_CNT1, 'M2', mm.MIN_CNT2,\n                'states', mm.nodes.length, 'size', outSize);\n  }\n});\n\nDmc.decompressFile = Util.decompressFileHelper(Dmc.MAGIC, function(inStream, outStream, fileSize) {\n\n  var MIN_CNT1 = Util.readUnsignedNumber(inStream);\n  var MIN_CNT2 = Util.readUnsignedNumber(inStream);\n\n  var range = new RangeCoder(inStream);\n  range.decodeStart();\n\n  var mm = new MarkovModel(range, (fileSize<0) ? 257 : 256,\n                           MIN_CNT1, MIN_CNT2);\n  var outSize = 0;\n  while (outSize !== fileSize) {\n    var ch = mm.decode();\n    if (ch===256) {\n      break; // EOF\n    }\n    outStream.writeByte(ch);\n    outSize++;\n  }\n  range.decodeFinish();\n});\n\nreturn Dmc;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/Lzjb.js":"/* LZJB compression: http://en.wikipedia.org/wiki/LZJB */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./Stream','./Util'], function(Stream,Util) {\n/**\n$Id: Iuppiter.js 3026 2010-06-23 10:03:13Z Bear $\n\nCopyright (c) 2010 Nuwa Information Co., Ltd, and individual contributors.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n  1. Redistributions of source code must retain the above copyright notice,\n     this list of conditions and the following disclaimer.\n\n  2. Redistributions in binary form must reproduce the above copyright\n     notice, this list of conditions and the following disclaimer in the\n     documentation and/or other materials provided with the distribution.\n\n  3. Neither the name of Nuwa Information nor the names of its contributors\n     may be used to endorse or promote products derived from this software\n     without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n$Author: Bear $\n$Date: 2010-06-23 18:03:13 +0800 (, 23  2010) $\n$Revision: 3026 $\n*/\n\nvar Lzjb = Object.create(null);\nLzjb.MAGIC = 'lzjb';\n\n// Constants was used for compress/decompress function.\nvar NBBY = 8,\n    MATCH_BITS = 6,\n    MATCH_MIN = 3,\n    MATCH_MAX = ((1 << MATCH_BITS) + (MATCH_MIN - 1)),\n    OFFSET_MASK = ((1 << (16 - MATCH_BITS)) - 1),\n    LEMPEL_SIZE_BASE = 1024;\nvar EOF = Stream.EOF;\n\n// set C_COMPAT to true if you need to decompress with the (untweaked) C lzjb\n// implementation, which breaks if offset==0; the javascript\n// implementation uses 0 to indicate an offset of OFFSET_MASK+1.\nvar C_COMPAT = true;\n\n/**\n * Compress string or byte array using fast and efficient algorithm.\n *\n * Because of weak of javascript's natural, many compression algorithm\n * become useless in javascript implementation. The main problem is\n * performance, even the simple Huffman, LZ77/78 algorithm will take many\n * many time to operate. We use LZJB algorithm to do that, it suprisingly\n * fulfills our requirement to compress string fastly and efficiently.\n *\n * Our implementation is based on\n * http://src.opensolaris.org/source/raw/onnv/onnv-gate/usr/src/uts/common/fs/zfs/lzjb.c\n * and\n * http://src.opensolaris.org/source/raw/onnv/onnv-gate/usr/src/uts/common/os/compress.c\n * It is licensed under CDDL.\n *\n * @param {Array|Uint8Array|Buffer|stream} input The stream or byte array\n *        that you want to compress.\n * @param {stream} output Optional output stream.\n * @return {Array|Uint8Array|Buffer} Compressed byte array, or 'output'\n */\nLzjb.compressFile = Util.compressFileHelper(Lzjb.MAGIC, function(inStream, outStream, fileSize, props) {\n    var sstart, dstart = [], slen,\n        src = 0, dst = 0,\n        cpy, copymap,\n        mlen, offset,\n        hash, hp,\n        lempel,\n        i, j;\n    var retval;\n\n    // in an improvement over the original C implementation, we expand\n    // the hash table to track a number of potential matches, not just the\n    // most recent.  This doesn't require any changes to the decoder.\n    // Sample impact on compression size (on wikipedia data):\n    //  EXPAND  Time     Size      Option\n    //    1   0m20.321s  50185613    -1\n    //    2   0m22.437s  46503301    -2\n    //    3   0m23.773s  45744564    -3\n    //    4   0m25.666s  45199866    -4\n    //    5   0m35.810s  44821413    -5\n    //    6   0m40.947s  44666638    -6\n    //    8   0m49.639s  44413865    -7\n    //   12   0m49.927s  44124825    -8\n    //   16   1m01.180s  43972515    -9\n    //   32   1m30.530s  43554099\n    //   64   2m14.504s  43005530\n    //  128   3m43.570s  42361718\n    //  256   6m38.681s  41684853\n    var LEMPEL_SIZE = LEMPEL_SIZE_BASE;\n    var EXPAND = 1; // default to original C impl\n    if (typeof(props)==='number') {\n        LEMPEL_SIZE *= 2;\n        props = Math.max(1, Math.min(9, props)) - 1;\n        EXPAND = 1<<Math.floor(props/2);\n        if (props&1) EXPAND = Math.round(EXPAND * 1.5);\n        if (props >=2 && props <= 4) EXPAND++;\n    }\n\n    // use Uint16Array if available (zero-filled)\n    lempel = Util.makeU16Buffer(LEMPEL_SIZE * EXPAND);\n\n    var window = Util.makeU8Buffer(OFFSET_MASK+1);\n    var windowpos = 0;\n    var winput = function(_byte) {\n        window[windowpos++] = _byte;\n        if (windowpos >= window.length) {\n            windowpos = 0;\n        }\n        return _byte;\n    };\n\n    var outwindow = Util.makeU8Buffer(17);\n    var outpos = 0;\n    var dumpout = function() {\n        var i;\n        for (i=0; i<outpos; i++) {\n            outStream.writeByte(outwindow[i]);\n        }\n        outpos = 0;\n    };\n\n    var unbuffer = [];\n    var get = function() {\n        if (unbuffer.length)\n            return unbuffer.pop();\n        return inStream.readByte();\n    };\n    var unget = function(_byte) {\n        unbuffer.push(_byte);\n    };\n\n    var copymask = 1 << (NBBY - 1);\n    var matchpossibility = [];\n    while (true) {\n        var c1 = get();\n        if (c1 === EOF) break;\n\n        if ((copymask <<= 1) == (1 << NBBY)) {\n            dumpout();\n            copymask = 1;\n            outwindow[0] = 0;\n            outpos = 1;\n        }\n\n        var c2 = get();\n        if (c2 === EOF) {\n            outwindow[outpos++] = winput(c1);\n            break;\n        }\n        var c3 = get();\n        if (c3 === EOF) {\n            outwindow[outpos++] = winput(c1);\n            unget(c2);\n            continue;\n        }\n\n        hash = (c1 << 16) + (c2 << 8) + c3;\n        hash ^= (hash >> 9);\n        hash += (hash >> 5);\n        hash ^= c1;\n        hp = (hash & (LEMPEL_SIZE - 1)) * EXPAND;\n        matchpossibility.length = 0;\n        for (j=0; j<EXPAND; j++) {\n            offset = (windowpos - lempel[hp+j]) & OFFSET_MASK;\n            cpy = window.length + windowpos - offset;\n            var w1 = window[cpy & OFFSET_MASK];\n            var w2 = window[(cpy+1) & OFFSET_MASK];\n            var w3 = window[(cpy+2) & OFFSET_MASK];\n            // if offset is small, we might not have copied the tentative\n            // bytes into the window yet.  (Note that offset=0 really means\n            // offset=(OFFSET_MASK+1).)\n            if (C_COMPAT && offset===0) {\n                w1 = c1 ^ 1; // ensure match will fail\n            } else if (offset==1) { w2 = c1; w3 = c2; }\n            else if (offset==2) { w3 = c1; }\n            if (c1 === w1 && c2 === w2 && c3 === w3) {\n                matchpossibility.push(offset);\n            }\n        }\n        // store this location in the hash, move the others over to make room\n        // oldest match drops off\n        for (j=EXPAND-1; j>0; j--)\n            lempel[hp+j] = lempel[hp+j-1];\n        lempel[hp] = windowpos;\n        // did we find any matches?\n        if (matchpossibility.length === 0) {\n            outwindow[outpos++] = winput(c1);\n            unget(c3);\n            unget(c2);\n        } else {\n            // find the longest of the possible matches\n            outwindow[0] |= copymask;\n            winput(c1); winput(c2); winput(c3);\n            var c4 = get(), last = matchpossibility[0];\n            var base = window.length + windowpos;\n            for (mlen = MATCH_MIN; mlen < MATCH_MAX; mlen++, base++) {\n                if (c4 === EOF) break;\n                for (j=0; j < matchpossibility.length; ) {\n                    var w4 = window[(base - matchpossibility[j]) & OFFSET_MASK];\n                    if (c4 !== w4) {\n                        last = matchpossibility[j];\n                        matchpossibility.splice(j, 1);\n                    } else {\n                        j++;\n                    }\n                }\n                if (matchpossibility.length===0) break; // no more matches\n                winput(c4);\n                c4 = get();\n            }\n            if (matchpossibility.length !== 0) {\n                // maximum length match, rock on!\n                last = matchpossibility[0];\n            }\n            unget(c4);\n\n            outwindow[outpos++] = ((mlen - MATCH_MIN) << (NBBY - MATCH_BITS)) |\n                (last >> NBBY);\n            outwindow[outpos++] = last & 0xFF;\n        }\n    }\n    dumpout();\n});\n\n/**\n * Decompress string or byte array using fast and efficient algorithm.\n *\n * Our implementation is based on\n * http://src.opensolaris.org/source/raw/onnv/onnv-gate/usr/src/uts/common/fs/zfs/lzjb.c\n * and\n * http://src.opensolaris.org/source/raw/onnv/onnv-gate/usr/src/uts/common/os/compress.c\n * It is licensed under CDDL.\n *\n * @param {Array|Uint8Array|Buffer|stream} input The stream or byte array\n *        that you want to decompress.\n * @param {stream} output Optional output stream.\n * @return {Array|Uint8Array|Buffer} Decompressed byte array, or 'output'\n */\nLzjb.decompressFile = Util.decompressFileHelper(Lzjb.MAGIC, function(inStream, outStream, outSize) {\n    var sstart, dstart = [], slen,\n        src = 0, dst = 0,\n        cpy, copymap,\n        mlen, offset,\n        i, c;\n    var retval;\n\n    var window = Util.makeU8Buffer(OFFSET_MASK+1);\n    var windowpos = 0;\n\n    var copymask = 1 << (NBBY - 1);\n\n    while (outSize !== 0) {\n        c = inStream.readByte();\n        if (c === EOF) break;\n\n        if ((copymask <<= 1) == (1 << NBBY)) {\n            copymask = 1;\n            copymap = c;\n            c = inStream.readByte();\n        }\n        if (copymap & copymask) {\n            mlen = (c >> (NBBY - MATCH_BITS)) + MATCH_MIN;\n            offset = ((c << NBBY) | inStream.readByte()) & OFFSET_MASK;\n            cpy = windowpos - offset;\n            if (cpy < 0) cpy += window.length;\n            if (outSize >= 0) outSize -= mlen;\n            while (--mlen >= 0) {\n                c = window[windowpos++] = window[cpy++];\n                outStream.writeByte(c);\n                if (windowpos >= window.length) { windowpos=0; }\n                if (cpy >= window.length) { cpy = 0; }\n            }\n        } else {\n            outStream.writeByte(c);\n            window[windowpos++] = c;\n            if (windowpos >= window.length) { windowpos=0; }\n            if (outSize >= 0) outSize--;\n        }\n    }\n});\n\n\nreturn Lzjb;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/LzjbR.js":"/* Tweaked version of LZJB, using range coder. */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./Context1Model','./FenwickModel','./LogDistanceModel','./NoModel','./RangeCoder','./Stream','./Util'],function(Context1Model,FenwickModel,LogDistanceModel,NoModel,RangeCoder,Stream,Util){\n\nvar LzjbR = Object.create(null);\nLzjbR.MAGIC = 'lzjR';\n\n// Constants was used for compress/decompress function.\nvar NBBY = 8,\n    MATCH_BITS = 6,\n    MATCH_MIN = 3,\n    MATCH_MAX = ((1 << MATCH_BITS) + (MATCH_MIN - 1)),\n    OFFSET_MASK = ((1 << (16 - MATCH_BITS)) - 1),\n    LEMPEL_SIZE_BASE = 1024;\nvar LENGTH_MODEL_CUTOFF = 32;\n\n\n/**\n * Compress using modified LZJB algorithm.  Instead of using the simple\n * 9-bit literal / 17-bit match format of the original, use a range\n * coder for the literal/match bit and for the offset and length.\n */\nLzjbR.compressFile = Util.compressFileHelper(LzjbR.MAGIC, function(inStream, outStream, fileSize, props, finalByte) {\n    var sstart, dstart = [], slen,\n        src = 0, dst = 0,\n        cpy, copymap,\n        mlen, offset,\n        hash, hp,\n        lempel,\n        i, j;\n\n    // in an improvement over the original C implementation of LZJB, we expand\n    // the hash table to track a number of potential matches, not just the\n    // most recent.  This doesn't require any changes to the decoder.\n    var LEMPEL_SIZE = LEMPEL_SIZE_BASE;\n    var EXPAND = 1; // default to original C impl\n    if (typeof(props)==='number') {\n        LEMPEL_SIZE *= 2;\n        props = Math.max(1, Math.min(9, props)) - 1;\n        EXPAND = 1<<Math.floor(props/2);\n        if (props&1) EXPAND = Math.round(EXPAND * 1.5);\n        if (props >=2 && props <= 4) EXPAND++;\n    }\n\n    var encoder = new RangeCoder(outStream);\n    encoder.encodeStart(finalByte, 1);\n\n    // use Uint16Array if available (zero-filled)\n    lempel = Util.makeU16Buffer(LEMPEL_SIZE * EXPAND);\n\n    var window = Util.makeU8Buffer(OFFSET_MASK+1);\n    var windowpos = 0;\n    var winput = function(_byte) {\n        window[windowpos++] = _byte;\n        if (windowpos >= window.length) {\n            windowpos = 0;\n        }\n        return _byte;\n    };\n\n    var unbuffer = [];\n    var get = function() {\n        if (unbuffer.length)\n            return unbuffer.pop();\n        return inStream.readByte();\n    };\n    var unget = function(_byte) {\n        unbuffer.push(_byte);\n    };\n\n    var matchpossibility = [];\n    var MATCH = 256;\n    var EOF_SYM = 257;\n    var noModelFactory = NoModel.factory(encoder);\n    var modelFactory = FenwickModel.factory(encoder, 0xFF00, 0x100);\n    var literalModel = new Context1Model(modelFactory, 256,\n                                         ((fileSize<0) ? EOF_SYM : MATCH) + 1);\n    var sparseModelFactory = function(size) {\n        if (size <= LENGTH_MODEL_CUTOFF) { return modelFactory(size); }\n        return noModelFactory(size);\n    };\n    var lenModel = new LogDistanceModel((MATCH_MAX-MATCH_MIN)+1, 0,\n                                        modelFactory, sparseModelFactory);\n    var posModel = new LogDistanceModel(OFFSET_MASK+1, 1,\n                                        modelFactory, sparseModelFactory);\n    var lastChar = 0x20, lastOffset = 0;\n    while (true) {\n        var initialPos = windowpos;\n        var c1 = get();\n        if (c1 === Stream.EOF) break;\n\n        var c2 = get();\n        if (c2 === Stream.EOF) {\n            literalModel.encode(winput(c1), lastChar); // literal, not a match\n            break;\n        }\n        var c3 = get();\n        if (c3 === Stream.EOF) {\n            literalModel.encode(winput(c1), lastChar); // literal, not a match\n            unget(c2); lastChar = c1;\n            continue;\n        }\n\n        hash = (c1 << 16) + (c2 << 8) + c3;\n        hash ^= (hash >> 9);\n        hash += (hash >> 5);\n        hash ^= c1;\n        hp = (hash & (LEMPEL_SIZE - 1)) * EXPAND;\n        matchpossibility.length = 0;\n        for (j=0; j<EXPAND; j++) {\n            offset = (windowpos - lempel[hp+j]) & OFFSET_MASK;\n            cpy = window.length + windowpos - offset;\n            var w1 = window[cpy & OFFSET_MASK];\n            var w2 = window[(cpy+1) & OFFSET_MASK];\n            var w3 = window[(cpy+2) & OFFSET_MASK];\n            // if offset is small, we might not have copied the tentative\n            // bytes into the window yet.  (Note that offset=0 really means\n            // offset=(OFFSET_MASK+1).)\n            if (offset==1) { w2 = c1; w3 = c2; }\n            else if (offset==2) { w3 = c1; }\n            if (c1 === w1 && c2 === w2 && c3 === w3) {\n                matchpossibility.push(offset);\n            }\n        }\n        // store this location in the hash, move the others over to make room\n        // oldest match drops off\n        for (j=EXPAND-1; j>0; j--)\n            lempel[hp+j] = lempel[hp+j-1];\n        lempel[hp] = windowpos;\n        // did we find any matches?\n        if (matchpossibility.length === 0) {\n            literalModel.encode(winput(c1), lastChar); // literal, not a match\n            unget(c3);\n            unget(c2);\n            lastChar = c1;\n        } else {\n            literalModel.encode(MATCH, lastChar); // a match!\n            // find the longest of the possible matches\n            winput(c1); winput(c2); winput(c3); lastChar = c3;\n            var c4 = get(), last = matchpossibility[0];\n            var base = window.length + windowpos;\n            for (mlen = MATCH_MIN; mlen < MATCH_MAX; mlen++, base++) {\n                if (c4 === Stream.EOF) break;\n                for (j=0; j < matchpossibility.length; ) {\n                    var w4 = window[(base - matchpossibility[j]) & OFFSET_MASK];\n                    if (c4 !== w4) {\n                        last = matchpossibility[j];\n                        matchpossibility.splice(j, 1);\n                    } else {\n                        j++;\n                    }\n                }\n                if (matchpossibility.length===0) break; // no more matches\n                winput(c4); lastChar = c4;\n                c4 = get();\n            }\n            if (matchpossibility.length !== 0) {\n                // maximum length match, rock on!\n                last = matchpossibility[0];\n            }\n            unget(c4);\n\n            // encode match length\n            // XXX we could get a bit more compression if we allowed\n            // the length to predict the offset (or vice-versa)\n            lenModel.encode(mlen - MATCH_MIN);\n            offset = (initialPos - last) & OFFSET_MASK;\n            if (offset === lastOffset) {\n                posModel.encode(-1); // common case!\n            } else {\n                posModel.encode(offset);\n                lastOffset = offset;\n            }\n        }\n    }\n    if (fileSize < 0) {\n        literalModel.encode(EOF_SYM, lastChar); // end of file (streaming)\n    }\n    encoder.encodeFinish();\n}, true);\n\n/**\n * Decompress using modified LZJB algorithm.\n */\nLzjbR.decompressFile = Util.decompressFileHelper(LzjbR.MAGIC, function(inStream, outStream, outSize) {\n    var sstart, dstart = [], slen,\n        src = 0, dst = 0,\n        cpy, copymap,\n        mlen, offset,\n        i, c;\n\n    var window = Util.makeU8Buffer(OFFSET_MASK+1);\n    var windowpos = 0;\n\n    var decoder = new RangeCoder(inStream);\n    decoder.decodeStart(true/* we already read the 'free' byte*/);\n\n    var MATCH = 256;\n    var EOF_SYM = 257;\n    var noModelFactory = NoModel.factory(decoder);\n    var modelFactory = FenwickModel.factory(decoder, 0xFF00, 0x100);\n    var literalModel = new Context1Model(modelFactory, 256,\n                                         ((outSize<0) ? EOF_SYM : MATCH) + 1);\n    var sparseModelFactory = function(size) {\n        if (size <= LENGTH_MODEL_CUTOFF) { return modelFactory(size); }\n        return noModelFactory(size);\n    };\n    var lenModel = new LogDistanceModel((MATCH_MAX-MATCH_MIN)+1, 0,\n                                        modelFactory, sparseModelFactory);\n    var posModel = new LogDistanceModel(OFFSET_MASK+1, 1,\n                                        modelFactory, sparseModelFactory);\n    var lastChar = 0x20, lastOffset = 0;\n    while (outSize !== 0) {\n        c = literalModel.decode(lastChar);\n        if (c === EOF_SYM) {\n            break;\n        } else if (c === MATCH) {\n            mlen = lenModel.decode() + MATCH_MIN;\n            cpy = posModel.decode();\n            if (cpy<0) { cpy = lastOffset; }\n            else       { lastOffset = cpy; }\n            if (outSize >= 0) outSize -= mlen;\n            while (--mlen >= 0) {\n                c = lastChar = window[windowpos++] = window[cpy++];\n                outStream.writeByte(c);\n                if (windowpos >= window.length) { windowpos=0; }\n                if (cpy >= window.length) { cpy = 0; }\n            }\n        } else {\n            outStream.writeByte(c);\n            window[windowpos++] = lastChar = c;\n            if (windowpos >= window.length) { windowpos=0; }\n            if (outSize >= 0) outSize--;\n        }\n    }\n    decoder.decodeFinish();\n});\n\n\nreturn LzjbR;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/Lzp3.js":"/* Implementation of LZP3(ish), with an adaptive Huffman code or a range\n * coder (instead of LZP3's original static Huffman code).\n * See: http://www.cbloom.com/papers/lzp.pdf\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./BitStream', './Context1Model', './DefSumModel', './FenwickModel', './Huffman', './LogDistanceModel', './NoModel', './RangeCoder', './Stream', './Util'],function(BitStream, Context1Model, DefSumModel, FenwickModel, Huffman, LogDistanceModel, NoModel, RangeCoder, Stream, Util){\n\nvar Lzp3 = Object.create(null);\nLzp3.MAGIC = 'lzp3';\n\n// use Huffman coder (fast) or else use range coder (slow)\nvar USE_HUFFMAN_CODE = false;\n// use deferred-sum model, which is supposed to be faster (but compresses worse)\nvar USE_DEFSUM = false;\n// when to give up attempting to model the length\nvar LENGTH_MODEL_CUTOFF = 256;\nvar MODEL_MAX_PROB = 0xFF00;\nvar MODEL_INCREMENT = 0x100;\n\n// Constants was used for compress/decompress function.\nvar CTXT4_TABLE_SIZE = 1 << 16;\nvar CTXT3_TABLE_SIZE = 1 << 12;\nvar CTXT2_TABLE_SIZE = 1 << 16;\nvar CONTEXT_LEN = 4;\nvar LOG_WINDOW_SIZE = 20;\nvar WINDOW_SIZE = 1 << LOG_WINDOW_SIZE;\nvar MAX_MATCH_LEN = WINDOW_SIZE-1;\nvar MATCH_LEN_CONTEXTS = 16;\n\nvar MAX32 = 0xFFFFFFFF;\nvar MAX24 = 0x00FFFFFF;\nvar MAX16 = 0x0000FFFF;\nvar MAX8  = 0x000000FF;\n\n\nvar Window = function(maxSize) {\n  this.buffer = Util.makeU8Buffer(Math.min(maxSize+4, WINDOW_SIZE));\n  this.pos = 0;\n  // context-4 hash table.\n  this.ctxt4 = Util.makeU32Buffer(CTXT4_TABLE_SIZE);\n  // context-3 hash table\n  this.ctxt3 = Util.makeU32Buffer(CTXT3_TABLE_SIZE);\n  // context-2 table (not really a hash any more)\n  this.ctxt2 = Util.makeU32Buffer(CTXT2_TABLE_SIZE);\n  // initial context\n  this.put(0x63); this.put(0x53); this.put(0x61); this.put(0x20);\n};\nWindow.prototype.put = function(_byte) {\n  this.buffer[this.pos++] = _byte;\n  if (this.pos >= WINDOW_SIZE) { this.pos = 0; }\n  return _byte;\n};\nWindow.prototype.get = function(pos) {\n  return this.buffer[pos & (WINDOW_SIZE-1)];\n};\nWindow.prototype.context = function(pos, n) {\n  var c = 0, i;\n  pos = (pos - n) & (WINDOW_SIZE-1);\n  for (i=0; i<n; i++) {\n    c = (c << 8) | this.buffer[pos++];\n    if (pos >= WINDOW_SIZE) { pos = 0; }\n  }\n  return c;\n};\n// if matchLen !== 0, update the index; otherwise get index value.\nWindow.prototype.getIndex = function(s, matchLen) {\n  var c = this.context(s, 4);\n  // compute context hashes\n  var h4 = ((c>>>15) ^ c) & (CTXT4_TABLE_SIZE-1);\n  var h3 = ((c>>>11) ^ c) & (CTXT3_TABLE_SIZE-1);\n  var h2 = c & MAX16;\n  // check order-4 context\n  var p = 0, checkc;\n  // only do context confirmation if matchLen==0 (that is, if we're not just\n  // doing an update)\n  if (matchLen===0) {\n    p = this.ctxt4[h4];\n    if (p !== 0 && c !== this.context(p-1, 4)) {\n      p = 0; // context confirmation failed\n    }\n    if (p === 0) {\n      // check order-3 context\n      p = this.ctxt3[h3];\n      if (p !== 0 && (c & MAX24) !== this.context(p-1, 3)) {\n        p = 0; // context confirmation failed\n      }\n      if (p === 0) {\n        // check order-2 context\n        p = this.ctxt2[h2];\n        if (p !== 0 && (c && MAX16) !== this.context(p-1, 2)) {\n          p = 0; // context confirmation failed\n        }\n      }\n    }\n  }\n  // update context index\n  if (matchLen) { matchLen--; }\n  this.ctxt4[h4] = this.ctxt3[h3] = this.ctxt2[h2] =\n    (s | (matchLen << LOG_WINDOW_SIZE)) + 1;\n  // return lookup result.\n  return p;\n};\n\n/**\n * Compress using modified LZP3 algorithm.  Instead of using static\n * Huffman coding, we use an adaptive Huffman code or range encoding.\n */\nLzp3.compressFile = Util.compressFileHelper(Lzp3.MAGIC, function(inStream, outStream, fileSize, props) {\n  // sliding window & hash table\n  var window = new Window( (fileSize>=0) ? fileSize : WINDOW_SIZE );\n\n  var coderFactory, sparseCoderFactory, flush;\n\n  if (USE_HUFFMAN_CODE) {\n    // Huffman contexts\n    outStream.writeByte(0x80); // mark that this is Huffman coded.\n    var bitstream = new BitStream(outStream);\n    flush = bitstream.flush.bind(bitstream);\n    coderFactory = Huffman.factory(bitstream, MAX16);\n    sparseCoderFactory = NoModel.factory(bitstream);\n\n  } else { // range encoder\n    var range = new RangeCoder(outStream);\n    range.encodeStart(0x00, 0); // 0x00 == range encoded\n\n    coderFactory = FenwickModel.factory(range, MODEL_MAX_PROB, MODEL_INCREMENT);\n    if (USE_DEFSUM) {\n      coderFactory = DefSumModel.factory(range, false /* encoder */);\n    }\n    // switch sparseCoderFactory to a NoModel when size > cutoff\n    var noCoderFactory = NoModel.factory(range);\n    sparseCoderFactory = function(size) {\n      if (size > LENGTH_MODEL_CUTOFF) {\n        return noCoderFactory(size);\n      }\n      return coderFactory(size);\n    };\n    flush = function() { range.encodeFinish(); };\n  }\n\n  var huffLiteral= new Context1Model(coderFactory, 256,\n                                     (fileSize<0) ? 257 : 256);\n  var huffLen = [], i;\n  for (i=0; i<MATCH_LEN_CONTEXTS; i++) {\n    huffLen[i] = new LogDistanceModel(MAX_MATCH_LEN+1, 1,\n                                      coderFactory, sparseCoderFactory);\n  }\n\n  var inSize = 0, s, matchContext = 0;\n  while (inSize !== fileSize) {\n    var ch = inStream.readByte();\n    s = window.pos;\n    var p = window.getIndex(s, 0);\n    if (p !== 0) {\n      // great, a match! how long is it?\n      p--; // p=0 is used for 'not here'. p=1 really means WINDOW_SIZE\n      var prevMatchLen = (p >>> LOG_WINDOW_SIZE) + 1;\n      var matchLen = 0;\n      while (window.get(p + matchLen) === ch && matchLen < MAX_MATCH_LEN) {\n        matchLen++;\n        window.put(ch);\n        ch = inStream.readByte();\n      }\n      // code match length; match len = 0 means \"literal\"\n      // use \"extra state\" -1 to mean \"same as previous match length\"\n      if (prevMatchLen===matchLen) {\n        huffLen[matchContext&(MATCH_LEN_CONTEXTS-1)].encode(-1);\n      } else {\n        huffLen[matchContext&(MATCH_LEN_CONTEXTS-1)].encode(matchLen);\n      }\n      // update hash with this match\n      window.getIndex(s, matchLen);\n      inSize += matchLen;\n      matchContext <<= 1;\n      if (matchLen > 0) { matchContext |= 1; }\n      // XXX: LZMA uses a special \"delta match\" context here if matchLen==0\n      // XXX: it also uses the offset as context for the length (or vice-versa)\n    }\n    // always encode a literal after a match\n    var context1 = window.get(window.pos-1);\n    if (ch===Stream.EOF) {\n      if (fileSize < 0) {\n        huffLiteral.encode(256, context1);\n      }\n      break;\n    }\n    huffLiteral.encode(ch, context1);\n    window.put(ch);\n    inSize++;\n  }\n  if (flush) flush();\n});\n\n/**\n * Decompress using modified LZP3 algorithm.\n */\nLzp3.decompressFile = Util.decompressFileHelper(Lzp3.MAGIC, function(inStream, outStream, fileSize) {\n  var flags = inStream.readByte();\n  var use_huffman_code = !!(flags & 0x80);\n\n  // sliding window & hash table\n  var window = new Window( (fileSize>=0) ? fileSize : WINDOW_SIZE );\n\n  var coderFactory, sparseCoderFactory, finish;\n\n  if (use_huffman_code) {\n    // Huffman contexts\n    var bitstream = new BitStream(inStream);\n    coderFactory = Huffman.factory(bitstream, MAX16);\n    sparseCoderFactory = NoModel.factory(bitstream);\n  } else { // range encoder\n    var range = new RangeCoder(inStream);\n    range.decodeStart(true/* skip initial read */);\n    coderFactory = FenwickModel.factory(range, MODEL_MAX_PROB, MODEL_INCREMENT);\n    if (USE_DEFSUM) {\n      coderFactory = DefSumModel.factory(range, true /* decoder */);\n    }\n    // switch sparseCoderFactory to a NoModel when size > cutoff\n    var noCoderFactory = NoModel.factory(range);\n    sparseCoderFactory = function(size) {\n      if (size > LENGTH_MODEL_CUTOFF) {\n        return noCoderFactory(size);\n      }\n      return coderFactory(size);\n    };\n    finish = function() { range.decodeFinish(); };\n  }\n\n  var huffLiteral= new Context1Model(coderFactory, 256,\n                                     (fileSize<0) ? 257 : 256);\n  var huffLen = [], i;\n  for (i=0; i<MATCH_LEN_CONTEXTS; i++) {\n    huffLen[i] = new LogDistanceModel(MAX_MATCH_LEN+1, 1,\n                                      coderFactory, sparseCoderFactory);\n  }\n\n  var s, ch, outSize = 0, matchContext = 0;\n  while (outSize !== fileSize) {\n    s = window.pos;\n    var p = window.getIndex(s, 0);\n    if (p !== 0) {\n      p--; // p=0 is used for 'not here'. p=1 really means WINDOW_SIZE\n      var prevMatchLen = (p >>> LOG_WINDOW_SIZE) + 1;\n      var matchLen = huffLen[matchContext&(MATCH_LEN_CONTEXTS-1)].decode();\n      if (matchLen < 0) { matchLen = prevMatchLen; }\n      // copy characters!\n      for (i=0; i<matchLen; i++) {\n        ch = window.get(p + i);\n        outStream.writeByte(window.put(ch));\n      }\n      window.getIndex(s, matchLen);\n      outSize += matchLen;\n      matchContext <<= 1;\n      if (matchLen > 0) matchContext |= 1;\n    }\n    // literal always follows match (or failed match)\n    if (outSize === fileSize) {\n      break; // EOF\n    }\n    var context1 = window.get(window.pos-1);\n    ch = huffLiteral.decode(context1);\n    if (ch === 256) {\n      break; // EOF\n    }\n    outStream.writeByte(window.put(ch));\n    outSize++;\n  }\n  if (finish) finish();\n});\n\n\nreturn Lzp3;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/PPM.js":"/** Particularly simple-minded implementation of PPM compression. */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./RangeCoder','./Util'], function(RangeCoder,Util) {\n\n  var MAX_CONTEXT = 5;\n  var LOG_WINDOW_SIZE = 18;\n  var WINDOW_SIZE = 1 << LOG_WINDOW_SIZE;\n\n  var Window = function() {\n    this.buffer = Util.makeU8Buffer(WINDOW_SIZE);\n    this.pos = 0;\n    this.firstPass = true;\n    for (var i=0; i<MAX_CONTEXT; i++) {\n      this.put('cSaCsA'.charCodeAt(i%6));\n    }\n  };\n  Window.prototype.put = function(_byte) {\n    this.buffer[this.pos++] = _byte;\n    if (this.pos >= WINDOW_SIZE) { this.pos = 0; this.firstPass = false; }\n    return _byte;\n  };\n  Window.prototype.get = function(pos) {\n    return this.buffer[pos & (WINDOW_SIZE-1)];\n  };\n  // the context ending just before 'pos'\n  Window.prototype.context = function(pos, n) {\n    var c = [], i;\n    pos = (pos - n) & (WINDOW_SIZE-1);\n    for (i=0; i<n; i++) {\n      c.push(this.buffer[pos++]);\n      if (pos >= WINDOW_SIZE) { pos = 0; }\n    }\n    return String.fromCharCode.apply(String, c);\n  };\n\n  var DMM_INCREMENT = 0x100, DMM_MAX_PROB = 0xFF00;\n\n  var PPM = function(coder, size) {\n    this.window = new Window();\n    this.contexts = Object.create(null);\n    // brain-dead '-1' context, using full exclusion\n    var Cm1Context = function() { };\n    Cm1Context.prototype.encode = function(symbol, exclude) {\n      var i, lt_f = 0;\n      for (i=0; i<symbol; i++) {\n        if (!exclude[i]) {\n          lt_f++;\n        }\n      }\n      var tot_f = size - exclude.total;\n      coder.encodeFreq(1, lt_f, tot_f);\n    };\n    Cm1Context.prototype.decode = function(exclude) {\n      var i, symbol, lt_f;\n      var tot_f = size - exclude.total;\n      symbol = lt_f = coder.decodeCulFreq(tot_f);\n      for (i=0; i<=symbol; i++) {\n        if (exclude[i]) {\n          symbol++;\n        }\n      }\n      coder.decodeUpdate(1, lt_f, tot_f);\n      return symbol;\n    };\n    this.cm1coder = new Cm1Context();\n\n    var DenseMTFModel = function() {\n      this.sym = [size];\n      this.prob= [0, DMM_INCREMENT];\n      this.refcount = 0;\n    };\n    DenseMTFModel.prototype._rescale = function() {\n      var seenSyms = this.sym.length;\n      var i, j, total=0;\n      var noEscape = true;\n      for(i=0, j=0; i<seenSyms; i++) {\n        var sym = this.sym[i];\n        var sy_f = this.prob[i+1] - this.prob[i];\n        sy_f >>>= 1;\n        if (sy_f > 0) {\n          if (sym === size) {\n            noEscape = false;\n          }\n          this.sym[j] = sym;\n          this.prob[j++] = total;\n          total += sy_f;\n        }\n      }\n      this.prob[j] = total;\n      seenSyms = this.sym.length = j;\n      this.prob.length = seenSyms + 1;\n      // don't allow escape to go to zero prob if we still need it\n      if (noEscape && seenSyms < size) {\n        total = this._update(size/*escape*/, seenSyms/*at end*/, 0, 1);\n      }\n      return total;\n    };\n    DenseMTFModel.prototype.update = function(symbol, incr) {\n      // find symbol\n      var i=0;\n      for (i=0; i<this.sym.length; i++) {\n        if (this.sym[i] === symbol) {\n          return this._update(symbol, i, this.prob[i+1] - this.prob[i], incr);\n        }\n      }\n      // symbol escaped\n      return this._update(symbol, i, 0, incr);\n    };\n    DenseMTFModel.prototype._update = function(symbol, index, sy_f, incr) {\n      var seenSyms = this.sym.length;\n      var i, j, tot_f;\n      // move this symbol to the end\n      for (j=index; j<seenSyms-1; j++) {\n        this.sym[j] = this.sym[j+1];\n        this.prob[j] = this.prob[j+1] - sy_f;\n      }\n      // \"method D\" -- if we add a new escaped symbol, escape & the symbol\n      // both increase by 1/2.\n      if (index < seenSyms) {\n        this.sym[j] = symbol;\n        this.prob[j] = this.prob[j+1] - sy_f;\n        // increase frequency for this symbol, and total freq at same time\n        this.prob[seenSyms] = tot_f =\n          this.prob[seenSyms] + incr;\n      } else { // add to the end\n        tot_f = this.prob[seenSyms];\n        this.sym[index] = symbol;\n        this.prob[index] = tot_f;\n        tot_f += incr;\n        this.prob[++seenSyms] = tot_f;\n        // remove probability of escape if table just filled up\n        if (this.sym.length > size) {\n          for (i=0; i<seenSyms; i++) {\n            if (size === this.sym[i]) {\n              // found it.\n              this._update(size, i, this.prob[i+1] - this.prob[i], -1);\n              this.sym.length--;\n              this.prob.length--;\n              tot_f = this.prob[this.prob.length-1];\n            }\n          }\n        }\n      }\n      if (tot_f >= DMM_MAX_PROB) { tot_f = this._rescale(); }\n      return tot_f;\n    };\n    DenseMTFModel.prototype.encode = function(symbol, exclude) {\n      // look for symbol, from most-recent to oldest\n      var i, j, sy_f, lt_f, tot_f, seenSyms = this.sym.length;\n      var ex_seen = 0, ex_lt_f = 0, ex_tot_f = 0, ex_sy_f;\n      for (i=seenSyms-1; i>=0; i--) {\n        lt_f = this.prob[i];\n        sy_f = this.prob[i + 1] - lt_f;\n        if (symbol === this.sym[i]) {\n          // ok, found it.\n          // count up the rest of the probabilities\n          for (j=i-1; j>=0 && ex_seen < exclude.total; j--) {\n            if (exclude[this.sym[j]]) {\n              ex_seen += 1;\n              ex_sy_f = this.prob[j+1] - this.prob[j];\n              ex_lt_f += ex_sy_f;\n              ex_tot_f += ex_sy_f;\n            }\n          }\n          tot_f = this.prob[seenSyms];\n          // adjust by excluded symbols\n          lt_f -= ex_lt_f;\n          tot_f -= ex_tot_f;\n          coder.encodeFreq(sy_f, lt_f, tot_f);\n          if (symbol === size) { // only update table for escapes\n            this._update(symbol, i, sy_f, DMM_INCREMENT/2);\n            return false; // escape.\n          } // otherwise we'll do update later\n          return true; // encoded character!\n        } else if (exclude[this.sym[i]]) {\n          ex_seen += 1;\n          ex_tot_f += sy_f;\n        }\n      }\n      // couldn't find this symbol.  encode as escape.\n      this.encode(size, exclude);\n      // add symbols to exclusion table\n      console.assert(this.sym[this.sym.length-1] === size);//escape\n      for (i=0; i<this.sym.length-1; i++) {\n        if (!exclude[this.sym[i]]) {\n          exclude[this.sym[i]] = true;\n          exclude.total++;\n        }\n      }\n    };\n    DenseMTFModel.prototype.decode = function(exclude) {\n      var seenSyms = this.sym.length;\n      var tot_f = this.prob[seenSyms];\n      var ex_seen = 0, ex_lt_f = 0, ex_tot_f = 0, ex_sy_f;\n      var i;\n      for (i=seenSyms-1; i>=0 && ex_seen < exclude.total; i--) {\n        if (exclude[this.sym[i]]) {\n          ex_seen += 1;\n          ex_tot_f += this.prob[i+1] - this.prob[i];\n        }\n      }\n      var prob = coder.decodeCulFreq(tot_f - ex_tot_f) + ex_tot_f;\n      // we're expecting to find the probability near the \"most recent\" side\n      // of our array\n      ex_lt_f = ex_tot_f;\n      for (i=seenSyms-1; i>=0; i--) {\n        if (exclude[this.sym[i]]) {\n          ex_sy_f = this.prob[i+1] - this.prob[i];\n          ex_lt_f -= ex_sy_f;\n          prob -= ex_sy_f;\n        } else if (this.prob[i] <= prob /*&& prob < this.prob[i+1]*/)\n          break;\n      }\n      console.assert(i>=0);\n      var symbol = this.sym[i];\n      var lt_f = this.prob[i];\n      var sy_f = this.prob[i + 1] - lt_f;\n      coder.decodeUpdate(sy_f, lt_f - ex_lt_f, tot_f - ex_tot_f);\n      // defer update\n      if (symbol < size) { return symbol; }\n      // an escape\n      this._update(symbol, i, sy_f, DMM_INCREMENT/2);\n      // add symbols to exclusion table\n      console.assert(this.sym[this.sym.length-1] === size);//escape\n      for (i=0; i<this.sym.length-1; i++) {\n        if (!exclude[this.sym[i]]) {\n          exclude[this.sym[i]] = true;\n          exclude.total++;\n        }\n      }\n      return -1;\n    };\n    this.newContext = function(initialSymbol) {\n      return new DenseMTFModel();\n    };\n    this.newExclude = function() {\n      var result = Object.create(null);\n      result.total = 0; // no excluded symbols (yet)\n      return result;\n    };\n    // set up some initial contexts\n    (function() {\n      var i, j;\n      for (i=0; i<MAX_CONTEXT; i++) {\n        for (j=0; j<=i; j++) {\n          var cc = this.window.context(j+((MAX_CONTEXT-1)-i), j);\n          if (!this.contexts[cc]) { this.contexts[cc] = this.newContext(); }\n          this.contexts[cc].refcount++;\n        }\n      }\n    }).call(this);\n  };\n  PPM.prototype.update = function(symbol, contextString, matchLevel) {\n    // slide up the contexts, updating them\n    var model, c, cc;\n    for (c=0; c <= MAX_CONTEXT; c++) {\n      cc = contextString.slice(MAX_CONTEXT - c);\n      model = this.contexts[cc];\n      if (!model) {\n        model = this.contexts[cc] = this.newContext();\n      }\n      if (c >= matchLevel) {\n        // only update useful contexts\n        model.update(symbol, DMM_INCREMENT / 2);\n      }\n      // refcount all contexts, whether used/updated or not\n      model.refcount++;\n    }\n    // now garbage-collect old contexts\n    contextString = this.window.context(this.window.pos + MAX_CONTEXT,\n                                        MAX_CONTEXT);\n    var firstPass = this.window.firstPass;\n    for (c=MAX_CONTEXT; c>=0 && !firstPass; c--) {\n      cc = contextString.slice(0, c);\n      model = this.contexts[cc];\n      console.assert(model);\n      if ((--model.refcount) <= 0) {\n        console.assert(cc !== ''); // don't allow context-0 to be gc'ed!\n        delete this.contexts[cc];\n      }\n    }\n    // ok, advance window.\n    this.window.put(symbol);\n  };\n  PPM.prototype.decode = function() {\n    var contextString = this.window.context(this.window.pos, MAX_CONTEXT);\n    var exclude = this.newExclude();\n    var model, c, cc, symbol;\n    for (c=MAX_CONTEXT; c>=0; c--) {\n      cc = contextString.slice(MAX_CONTEXT - c);\n      model = this.contexts[cc];\n      if (model) {\n        symbol = model.decode(exclude);\n        if (symbol >= 0) {\n          this.update(symbol, contextString, c);\n          return symbol;\n        }\n      }\n    }\n    // still no match, fall back to context -1\n    symbol = this.cm1coder.decode(exclude);\n    this.update(symbol, contextString, c);\n    return symbol;\n  };\n  PPM.prototype.encode = function(symbol) {\n    var contextString = this.window.context(this.window.pos, MAX_CONTEXT);\n    var exclude = this.newExclude();\n    var c;\n    for (c=MAX_CONTEXT; c>=0; c--) {\n      var cc = contextString.slice(MAX_CONTEXT - c);\n      var model = this.contexts[cc];\n      if (model) {\n        var success = model.encode(symbol, exclude);\n        if (success) {\n          this.update(symbol, contextString, c);\n          return;\n        }\n      }\n    }\n    // fall back to context -1 (but still use exclusion table)\n    this.cm1coder.encode(symbol, exclude);\n    this.update(symbol, contextString, c);\n    return;\n  };\n\n  PPM.MAGIC = 'ppm2';\n  PPM.compressFile = Util.compressFileHelper(PPM.MAGIC, function(inStream, outStream, fileSize, props, finalByte) {\n    var range = new RangeCoder(outStream);\n    range.encodeStart(finalByte, 1);\n    var model = new PPM(range, (fileSize<0) ? 257 : 256);\n    Util.compressWithModel(inStream, fileSize, model);\n    range.encodeFinish();\n  }, true);\n  PPM.decompressFile = Util.decompressFileHelper(PPM.MAGIC, function(inStream, outStream, fileSize) {\n    var range = new RangeCoder(inStream);\n    range.decodeStart(true/*we already read the 'free' byte*/);\n    var model = new PPM(range, (fileSize<0) ? 257 : 256);\n    Util.decompressWithModel(outStream, fileSize, model);\n    range.decodeFinish();\n  });\n\n  return PPM;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/Simple.js":"/* *Very* simple de/compression utility, based on simple_c and simple_d from\n * rngcod13.zip at http://www.compressconsult.com/rangecoder/\n * Really just a demonstration/test of the rangecoder.\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./RangeCoder','./Stream','./Util'],function(RangeCoder,Stream,Util){\n    var MAX_BLOCK_SIZE = 1<<17;\n\n    var Simple = Object.create(null);\n    Simple.MAGIC = 'smpl';\n    Simple.compressFile = Util.compressFileHelper(Simple.MAGIC, function(input, output, size, props, finalByte) {\n        var encoder = new RangeCoder(output);\n        encoder.encodeStart(finalByte, 1);\n\n        // read a block\n        var block = Util.makeU8Buffer(MAX_BLOCK_SIZE);\n        var counts = [];\n        var blockLength = 0, sawEOF = false;\n\n        var readBlock = function() {\n            var pos = 0;\n            // initialize counts\n            for (pos=0; pos < 256; pos++) {\n                counts[pos] = 0;\n            }\n            if (sawEOF) {\n                blockLength = 0;\n                return;\n            }\n            for (pos=0; pos < MAX_BLOCK_SIZE; ) {\n                var c = input.readByte();\n                if (c===Stream.EOF) {\n                    sawEOF = true;\n                    break;\n                }\n                block[pos++] = c;\n                counts[c]++;\n                // bail if some count reaches maximum\n                if (counts[c]===0xFFFF) {\n                    break;\n                }\n            }\n            blockLength = pos;\n        };\n\n        while (true) {\n            var i;\n            readBlock();\n            if (sawEOF && blockLength===0) {\n                break;\n            }\n            // indicate that there's another block comin'\n            encoder.encodeBit(true);\n            // write all the statistics\n            for (i=0; i<256; i++) {\n                encoder.encodeShort(counts[i]);\n            }\n            // convert counts to cumulative counts\n            counts[256] = blockLength;\n            for (i=256; i; i--) {\n                counts[i-1] = counts[i] - counts[i-1];\n            }\n            // encode the symbols using the probability table.\n            for (i=0; i<blockLength; i++) {\n                var ch = block[i];\n                encoder.encodeFreq(counts[ch+1]-counts[ch], counts[ch],\n                                   counts[256]);\n            }\n        }\n        // write a stop bit\n        encoder.encodeBit(false);\n        // done!\n        encoder.encodeFinish();\n    }, true);\n    Simple.decompressFile = Util.decompressFileHelper(Simple.MAGIC, function(input, output, size) {\n        var decoder = new RangeCoder(input);\n        decoder.decodeStart(true/*we already read the 'free' byte*/);\n        while (decoder.decodeBit()) {\n            var i, counts = [];\n            // read all the statistics\n            for (i=0; i<256; i++) {\n                counts[i] = decoder.decodeShort();\n            }\n            // compute cumulative stats & total block size\n            var blocksize = 0;\n            for (i=0; i<256; i++) {\n                var tmp = counts[i];\n                counts[i] = blocksize;\n                blocksize += tmp;\n            }\n            counts[256] = blocksize;\n\n            for (i=0; i<blocksize; i++) {\n                var cf = decoder.decodeCulFreq(blocksize);\n                // inefficient way to look up the symbol.\n                var symbol;\n                for (symbol=0; symbol<256; symbol++)\n                    // careful, there are length-0 ranges\n                    // (where counts[symbol]===counts[symbol+1])\n                    if (counts[symbol]<=cf && cf < counts[symbol+1])\n                        break;\n                var ch = symbol;\n                decoder.decodeUpdate(counts[symbol+1] - counts[symbol],\n                                     counts[symbol], blocksize);\n                output.writeByte(symbol);\n            }\n        }\n        decoder.decodeFinish();\n    });\n    return Simple;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/DeflateDistanceModel.js":"/** Distance model used by gzip/deflate.\n *  Encodes distances starting at 0 (for deflate compatibility, subtract\n *  one from distance to encode).\n *  Uses ~32-entry model to predict ln2(distance) (more-or-less) and then\n *  encodes a few more bits for the actual distance. */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./Util'],function(Util){\n\n    // lengthBitsModelFactory will be called with arguments 2, 4, 8, 16, etc\n    // and must return an appropriate model or coder.\n    var DeflateDistanceModel = function(size, extraStates,\n                                        lgDistanceModelFactory,\n                                        lengthBitsModelFactory) {\n        var i;\n        var bits = Util.fls(size-1);\n        this.extraStates = +extraStates || 0;\n        this.lgDistanceModel = lgDistanceModelFactory(2*bits + extraStates);\n        // this.distanceModel[n] used for distances which are n-bits long,\n        // but only n-2 bits are encoded: the top bit is known to be one,\n        // and the next bit is encoded by the lgDistanceModel.\n        this.distanceModel = [];\n        for (i=3 ; i <= bits; i++) {\n            var numBits = i - 2;\n            this.distanceModel[i] = lengthBitsModelFactory(1<<numBits);\n        }\n    };\n    /* you can give this model arguments between 0 and (size-1), or else\n       a negative argument which is one of the 'extra states'. */\n    DeflateDistanceModel.prototype.encode = function(distance) {\n        if (distance < 4) { // small distance or an 'extra state'\n            this.lgDistanceModel.encode(distance + this.extraStates);\n            return;\n        }\n        var lgDistance = Util.fls(distance);\n        console.assert(distance & (1<<(lgDistance-1))); // top bit is set\n        console.assert(lgDistance >= 3);\n        var nextBit = (distance & (1 << (lgDistance-2))) ? 1 : 0;\n        var l = 4 + ((lgDistance-3)*2) + nextBit;\n        this.lgDistanceModel.encode(l + this.extraStates);\n        // now encode the rest of the bits.\n        var rest = distance & ((1 << (lgDistance-2)) - 1);\n        this.distanceModel[lgDistance].encode(rest);\n    };\n    DeflateDistanceModel.prototype.decode = function() {\n        var l = this.lgDistanceModel.decode() - this.extraStates;\n        if (l < 4) {\n            return l; // this is a small distance or an 'extra state'\n        }\n        var nextBit = (l&1);\n        var lgDistance = ((l-4) >>> 1) + 3;\n        var rest = this.distanceModel[lgDistance].decode();\n        return ((2+nextBit) << (lgDistance-2)) + rest;\n    };\n    return DeflateDistanceModel;\n});\n","/home/travis/build/npmtest/node-npmtest-compressjs/node_modules/compressjs/lib/DummyRangeCoder.js":"/* Dummy Range Coder, for debugging.\n * This has the same interface as RangeCoder, but just dumps the frequency\n * parameters given to the file.  This helps debug problems with the model\n * driving the range coder.\n */\nif (typeof define !== 'function') { var define = require('amdefine')(module); }\ndefine(['./RangeCoder','./Util'],function(RangeCoder,Util){\n    var Dummy = function(stream) {\n        RangeCoder.call(this, stream);\n    };\n    Dummy.prototype = Object.create(RangeCoder.prototype);\n    Dummy.prototype._write8 = function(b) {\n        Util.writeUnsignedNumber(this.stream, b);\n        this.stream.writeByte(b);\n    };\n    Dummy.prototype._write16 = function(s) {\n        this.stream.writeByte((s >>> 8) & 0xFF);\n        this.stream.writeByte(s & 0xFF);\n    };\n    Dummy.prototype._read8 = function() {\n        return this.stream.readByte();\n    };\n    Dummy.prototype._read16 = function() {\n        var hi = this.stream.readByte();\n        var lo = this.stream.readByte();\n        return (hi<<8) | lo;\n    };\n    Dummy.prototype.encodeStart = function(c, initlength) {\n        this.stream.writeByte(c);\n    };\n    Dummy.prototype.encodeFreq = function(sy_f, lt_f, tot_f) {\n        console.assert(sy_f > 0);\n        console.assert(tot_f > 0);\n        console.assert(tot_f <= (1<<23));\n        if ((sy_f + lt_f) > tot_f) {\n            console.error('dummy coder: lt_f + sy_f > tot_f',\n                          sy_f, lt_f, tot_f);\n        }\n        Util.writeUnsignedNumber(this.stream, sy_f);\n        Util.writeUnsignedNumber(this.stream, lt_f);\n        Util.writeUnsignedNumber(this.stream, tot_f);\n    };\n    Dummy.prototype.encodeShift = function(sy_f, lt_f, shift) {\n        this.encodeFreq(sy_f, lt_f, 1 << shift);\n    };\n    Dummy.prototype.encodeFinish = function() {\n        return 0;\n    };\n    Dummy.prototype.decodeStart = function(skipInitialRead) {\n        return skipInitialRead ? 0 : this.stream.readByte();\n    };\n    Dummy.prototype.decodeCulFreq = function(tot_f) {\n        console.assert(tot_f > 0);\n        this.sy_f = Util.readUnsignedNumber(this.stream);\n        this.lt_f = Util.readUnsignedNumber(this.stream);\n        this.tot_f= Util.readUnsignedNumber(this.stream);\n        if (tot_f !== this.tot_f) {\n            console.error('decodeCul* wrong total: got', tot_f,\n                          'expected', this.tot_f);\n        }\n        return (this.sy_f>>>1) + this.lt_f;\n    };\n    Dummy.prototype.decodeCulShift = function(shift) {\n        return this.decodeCulFreq(1<<shift);\n    };\n    Dummy.prototype.decodeUpdate = function(sy_f, lt_f, tot_f) {\n        console.assert(sy_f > 0);\n        console.assert(tot_f > 0);\n        if (sy_f !== this.sy_f ||\n            lt_f !== this.lt_f ||\n            tot_f!== this.tot_f) {\n            console.error('decodeUpdate wrong parameters; got',\n                          sy_f, lt_f, tot_f, 'expected',\n                          this.sy_f, this.lt_f, this.tot_f);\n        }\n    };\n    Dummy.prototype.decodeFinish = function() {\n    };\n\n    return Dummy;\n});\n"}